// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/internal/utils"
)

type CredentialType string

const (
	CredentialTypeHmacKey CredentialType = "HMAC_KEY"
)

func (e CredentialType) ToPointer() *CredentialType {
	return &e
}
func (e *CredentialType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "HMAC_KEY":
		*e = CredentialType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CredentialType: %v", v)
	}
}

type HMACKey struct {
	CredentialType *CredentialType `default:"HMAC_KEY" json:"credential_type"`
	// When linked to a service account, this ID is 61 characters long; when linked to a user account, it is 24 characters long. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys#overview">here</a>.
	HmacKeyAccessID string `json:"hmac_key_access_id"`
	// The corresponding secret for the access ID. It is a 40-character base-64 encoded string.  Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys#secrets">here</a>.
	HmacKeySecret string `json:"hmac_key_secret"`
}

func (h HMACKey) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HMACKey) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *HMACKey) GetCredentialType() *CredentialType {
	if o == nil {
		return nil
	}
	return o.CredentialType
}

func (o *HMACKey) GetHmacKeyAccessID() string {
	if o == nil {
		return ""
	}
	return o.HmacKeyAccessID
}

func (o *HMACKey) GetHmacKeySecret() string {
	if o == nil {
		return ""
	}
	return o.HmacKeySecret
}

type DestinationGcsUpdateAuthenticationType string

const (
	DestinationGcsUpdateAuthenticationTypeHMACKey DestinationGcsUpdateAuthenticationType = "HMAC Key"
)

// DestinationGcsUpdateAuthentication - An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys">here</a>.
type DestinationGcsUpdateAuthentication struct {
	HMACKey *HMACKey

	Type DestinationGcsUpdateAuthenticationType
}

func CreateDestinationGcsUpdateAuthenticationHMACKey(hmacKey HMACKey) DestinationGcsUpdateAuthentication {
	typ := DestinationGcsUpdateAuthenticationTypeHMACKey

	return DestinationGcsUpdateAuthentication{
		HMACKey: &hmacKey,
		Type:    typ,
	}
}

func (u *DestinationGcsUpdateAuthentication) UnmarshalJSON(data []byte) error {

	var hmacKey HMACKey = HMACKey{}
	if err := utils.UnmarshalJSON(data, &hmacKey, "", true, true); err == nil {
		u.HMACKey = &hmacKey
		u.Type = DestinationGcsUpdateAuthenticationTypeHMACKey
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsUpdateAuthentication", string(data))
}

func (u DestinationGcsUpdateAuthentication) MarshalJSON() ([]byte, error) {
	if u.HMACKey != nil {
		return utils.MarshalJSON(u.HMACKey, "", true)
	}

	return nil, errors.New("could not marshal union type DestinationGcsUpdateAuthentication: all fields are null")
}

// DestinationGcsUpdateCompressionCodec - The compression algorithm used to compress data pages.
type DestinationGcsUpdateCompressionCodec string

const (
	DestinationGcsUpdateCompressionCodecUncompressed DestinationGcsUpdateCompressionCodec = "UNCOMPRESSED"
	DestinationGcsUpdateCompressionCodecSnappy       DestinationGcsUpdateCompressionCodec = "SNAPPY"
	DestinationGcsUpdateCompressionCodecGzip         DestinationGcsUpdateCompressionCodec = "GZIP"
	DestinationGcsUpdateCompressionCodecLzo          DestinationGcsUpdateCompressionCodec = "LZO"
	DestinationGcsUpdateCompressionCodecBrotli       DestinationGcsUpdateCompressionCodec = "BROTLI"
	DestinationGcsUpdateCompressionCodecLz4          DestinationGcsUpdateCompressionCodec = "LZ4"
	DestinationGcsUpdateCompressionCodecZstd         DestinationGcsUpdateCompressionCodec = "ZSTD"
)

func (e DestinationGcsUpdateCompressionCodec) ToPointer() *DestinationGcsUpdateCompressionCodec {
	return &e
}
func (e *DestinationGcsUpdateCompressionCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "UNCOMPRESSED":
		fallthrough
	case "SNAPPY":
		fallthrough
	case "GZIP":
		fallthrough
	case "LZO":
		fallthrough
	case "BROTLI":
		fallthrough
	case "LZ4":
		fallthrough
	case "ZSTD":
		*e = DestinationGcsUpdateCompressionCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateCompressionCodec: %v", v)
	}
}

type DestinationGcsUpdateSchemasFormatOutputFormatFormatType string

const (
	DestinationGcsUpdateSchemasFormatOutputFormatFormatTypeParquet DestinationGcsUpdateSchemasFormatOutputFormatFormatType = "Parquet"
)

func (e DestinationGcsUpdateSchemasFormatOutputFormatFormatType) ToPointer() *DestinationGcsUpdateSchemasFormatOutputFormatFormatType {
	return &e
}
func (e *DestinationGcsUpdateSchemasFormatOutputFormatFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Parquet":
		*e = DestinationGcsUpdateSchemasFormatOutputFormatFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateSchemasFormatOutputFormatFormatType: %v", v)
	}
}

type DestinationGcsUpdateParquetColumnarStorage struct {
	// This is the size of a row group being buffered in memory. It limits the memory usage when writing. Larger values will improve the IO when reading, but consume more memory when writing. Default: 128 MB.
	BlockSizeMb *int64 `default:"128" json:"block_size_mb"`
	// The compression algorithm used to compress data pages.
	CompressionCodec *DestinationGcsUpdateCompressionCodec `default:"UNCOMPRESSED" json:"compression_codec"`
	// Default: true.
	DictionaryEncoding *bool `default:"true" json:"dictionary_encoding"`
	// There is one dictionary page per column per row group when dictionary encoding is used. The dictionary page size works like the page size but for dictionary. Default: 1024 KB.
	DictionaryPageSizeKb *int64                                                   `default:"1024" json:"dictionary_page_size_kb"`
	FormatType           *DestinationGcsUpdateSchemasFormatOutputFormatFormatType `default:"Parquet" json:"format_type"`
	// Maximum size allowed as padding to align row groups. This is also the minimum size of a row group. Default: 8 MB.
	MaxPaddingSizeMb *int64 `default:"8" json:"max_padding_size_mb"`
	// The page size is for compression. A block is composed of pages. A page is the smallest unit that must be read fully to access a single record. If this value is too small, the compression will deteriorate. Default: 1024 KB.
	PageSizeKb *int64 `default:"1024" json:"page_size_kb"`
}

func (d DestinationGcsUpdateParquetColumnarStorage) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsUpdateParquetColumnarStorage) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationGcsUpdateParquetColumnarStorage) GetBlockSizeMb() *int64 {
	if o == nil {
		return nil
	}
	return o.BlockSizeMb
}

func (o *DestinationGcsUpdateParquetColumnarStorage) GetCompressionCodec() *DestinationGcsUpdateCompressionCodec {
	if o == nil {
		return nil
	}
	return o.CompressionCodec
}

func (o *DestinationGcsUpdateParquetColumnarStorage) GetDictionaryEncoding() *bool {
	if o == nil {
		return nil
	}
	return o.DictionaryEncoding
}

func (o *DestinationGcsUpdateParquetColumnarStorage) GetDictionaryPageSizeKb() *int64 {
	if o == nil {
		return nil
	}
	return o.DictionaryPageSizeKb
}

func (o *DestinationGcsUpdateParquetColumnarStorage) GetFormatType() *DestinationGcsUpdateSchemasFormatOutputFormatFormatType {
	if o == nil {
		return nil
	}
	return o.FormatType
}

func (o *DestinationGcsUpdateParquetColumnarStorage) GetMaxPaddingSizeMb() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxPaddingSizeMb
}

func (o *DestinationGcsUpdateParquetColumnarStorage) GetPageSizeKb() *int64 {
	if o == nil {
		return nil
	}
	return o.PageSizeKb
}

type DestinationGcsUpdateSchemasFormatCompressionType string

const (
	DestinationGcsUpdateSchemasFormatCompressionTypeGzip DestinationGcsUpdateSchemasFormatCompressionType = "GZIP"
)

func (e DestinationGcsUpdateSchemasFormatCompressionType) ToPointer() *DestinationGcsUpdateSchemasFormatCompressionType {
	return &e
}
func (e *DestinationGcsUpdateSchemasFormatCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GZIP":
		*e = DestinationGcsUpdateSchemasFormatCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateSchemasFormatCompressionType: %v", v)
	}
}

type DestinationGcsUpdateGZIP struct {
	CompressionType *DestinationGcsUpdateSchemasFormatCompressionType `default:"GZIP" json:"compression_type"`
}

func (d DestinationGcsUpdateGZIP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsUpdateGZIP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationGcsUpdateGZIP) GetCompressionType() *DestinationGcsUpdateSchemasFormatCompressionType {
	if o == nil {
		return nil
	}
	return o.CompressionType
}

type DestinationGcsUpdateSchemasCompressionType string

const (
	DestinationGcsUpdateSchemasCompressionTypeNoCompression DestinationGcsUpdateSchemasCompressionType = "No Compression"
)

func (e DestinationGcsUpdateSchemasCompressionType) ToPointer() *DestinationGcsUpdateSchemasCompressionType {
	return &e
}
func (e *DestinationGcsUpdateSchemasCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No Compression":
		*e = DestinationGcsUpdateSchemasCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateSchemasCompressionType: %v", v)
	}
}

type DestinationGcsUpdateSchemasNoCompression struct {
	CompressionType *DestinationGcsUpdateSchemasCompressionType `default:"No Compression" json:"compression_type"`
}

func (d DestinationGcsUpdateSchemasNoCompression) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsUpdateSchemasNoCompression) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationGcsUpdateSchemasNoCompression) GetCompressionType() *DestinationGcsUpdateSchemasCompressionType {
	if o == nil {
		return nil
	}
	return o.CompressionType
}

type DestinationGcsUpdateCompressionUnionType string

const (
	DestinationGcsUpdateCompressionUnionTypeDestinationGcsUpdateSchemasNoCompression DestinationGcsUpdateCompressionUnionType = "destination-gcs-update_Schemas_No Compression"
	DestinationGcsUpdateCompressionUnionTypeDestinationGcsUpdateGZIP                 DestinationGcsUpdateCompressionUnionType = "destination-gcs-update_GZIP"
)

// DestinationGcsUpdateCompression - Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".jsonl.gz").
type DestinationGcsUpdateCompression struct {
	DestinationGcsUpdateSchemasNoCompression *DestinationGcsUpdateSchemasNoCompression
	DestinationGcsUpdateGZIP                 *DestinationGcsUpdateGZIP

	Type DestinationGcsUpdateCompressionUnionType
}

func CreateDestinationGcsUpdateCompressionDestinationGcsUpdateSchemasNoCompression(destinationGcsUpdateSchemasNoCompression DestinationGcsUpdateSchemasNoCompression) DestinationGcsUpdateCompression {
	typ := DestinationGcsUpdateCompressionUnionTypeDestinationGcsUpdateSchemasNoCompression

	return DestinationGcsUpdateCompression{
		DestinationGcsUpdateSchemasNoCompression: &destinationGcsUpdateSchemasNoCompression,
		Type:                                     typ,
	}
}

func CreateDestinationGcsUpdateCompressionDestinationGcsUpdateGZIP(destinationGcsUpdateGZIP DestinationGcsUpdateGZIP) DestinationGcsUpdateCompression {
	typ := DestinationGcsUpdateCompressionUnionTypeDestinationGcsUpdateGZIP

	return DestinationGcsUpdateCompression{
		DestinationGcsUpdateGZIP: &destinationGcsUpdateGZIP,
		Type:                     typ,
	}
}

func (u *DestinationGcsUpdateCompression) UnmarshalJSON(data []byte) error {

	var destinationGcsUpdateSchemasNoCompression DestinationGcsUpdateSchemasNoCompression = DestinationGcsUpdateSchemasNoCompression{}
	if err := utils.UnmarshalJSON(data, &destinationGcsUpdateSchemasNoCompression, "", true, true); err == nil {
		u.DestinationGcsUpdateSchemasNoCompression = &destinationGcsUpdateSchemasNoCompression
		u.Type = DestinationGcsUpdateCompressionUnionTypeDestinationGcsUpdateSchemasNoCompression
		return nil
	}

	var destinationGcsUpdateGZIP DestinationGcsUpdateGZIP = DestinationGcsUpdateGZIP{}
	if err := utils.UnmarshalJSON(data, &destinationGcsUpdateGZIP, "", true, true); err == nil {
		u.DestinationGcsUpdateGZIP = &destinationGcsUpdateGZIP
		u.Type = DestinationGcsUpdateCompressionUnionTypeDestinationGcsUpdateGZIP
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsUpdateCompression", string(data))
}

func (u DestinationGcsUpdateCompression) MarshalJSON() ([]byte, error) {
	if u.DestinationGcsUpdateSchemasNoCompression != nil {
		return utils.MarshalJSON(u.DestinationGcsUpdateSchemasNoCompression, "", true)
	}

	if u.DestinationGcsUpdateGZIP != nil {
		return utils.MarshalJSON(u.DestinationGcsUpdateGZIP, "", true)
	}

	return nil, errors.New("could not marshal union type DestinationGcsUpdateCompression: all fields are null")
}

type DestinationGcsUpdateSchemasFormatFormatType string

const (
	DestinationGcsUpdateSchemasFormatFormatTypeJsonl DestinationGcsUpdateSchemasFormatFormatType = "JSONL"
)

func (e DestinationGcsUpdateSchemasFormatFormatType) ToPointer() *DestinationGcsUpdateSchemasFormatFormatType {
	return &e
}
func (e *DestinationGcsUpdateSchemasFormatFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "JSONL":
		*e = DestinationGcsUpdateSchemasFormatFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateSchemasFormatFormatType: %v", v)
	}
}

type DestinationGcsUpdateJSONLinesNewlineDelimitedJSON struct {
	// Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".jsonl.gz").
	Compression *DestinationGcsUpdateCompression             `json:"compression,omitempty"`
	FormatType  *DestinationGcsUpdateSchemasFormatFormatType `default:"JSONL" json:"format_type"`
}

func (d DestinationGcsUpdateJSONLinesNewlineDelimitedJSON) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsUpdateJSONLinesNewlineDelimitedJSON) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationGcsUpdateJSONLinesNewlineDelimitedJSON) GetCompression() *DestinationGcsUpdateCompression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *DestinationGcsUpdateJSONLinesNewlineDelimitedJSON) GetFormatType() *DestinationGcsUpdateSchemasFormatFormatType {
	if o == nil {
		return nil
	}
	return o.FormatType
}

type DestinationGcsUpdateCompressionType string

const (
	DestinationGcsUpdateCompressionTypeGzip DestinationGcsUpdateCompressionType = "GZIP"
)

func (e DestinationGcsUpdateCompressionType) ToPointer() *DestinationGcsUpdateCompressionType {
	return &e
}
func (e *DestinationGcsUpdateCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GZIP":
		*e = DestinationGcsUpdateCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateCompressionType: %v", v)
	}
}

type Gzip struct {
	CompressionType *DestinationGcsUpdateCompressionType `default:"GZIP" json:"compression_type"`
}

func (g Gzip) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(g, "", false)
}

func (g *Gzip) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &g, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *Gzip) GetCompressionType() *DestinationGcsUpdateCompressionType {
	if o == nil {
		return nil
	}
	return o.CompressionType
}

type CompressionType string

const (
	CompressionTypeNoCompression CompressionType = "No Compression"
)

func (e CompressionType) ToPointer() *CompressionType {
	return &e
}
func (e *CompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No Compression":
		*e = CompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionType: %v", v)
	}
}

type DestinationGcsUpdateNoCompression struct {
	CompressionType *CompressionType `default:"No Compression" json:"compression_type"`
}

func (d DestinationGcsUpdateNoCompression) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsUpdateNoCompression) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationGcsUpdateNoCompression) GetCompressionType() *CompressionType {
	if o == nil {
		return nil
	}
	return o.CompressionType
}

type CompressionUnionType string

const (
	CompressionUnionTypeDestinationGcsUpdateNoCompression CompressionUnionType = "destination-gcs-update_No Compression"
	CompressionUnionTypeGzip                              CompressionUnionType = "GZIP"
)

// Compression - Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".csv.gz").
type Compression struct {
	DestinationGcsUpdateNoCompression *DestinationGcsUpdateNoCompression
	Gzip                              *Gzip

	Type CompressionUnionType
}

func CreateCompressionDestinationGcsUpdateNoCompression(destinationGcsUpdateNoCompression DestinationGcsUpdateNoCompression) Compression {
	typ := CompressionUnionTypeDestinationGcsUpdateNoCompression

	return Compression{
		DestinationGcsUpdateNoCompression: &destinationGcsUpdateNoCompression,
		Type:                              typ,
	}
}

func CreateCompressionGzip(gzip Gzip) Compression {
	typ := CompressionUnionTypeGzip

	return Compression{
		Gzip: &gzip,
		Type: typ,
	}
}

func (u *Compression) UnmarshalJSON(data []byte) error {

	var destinationGcsUpdateNoCompression DestinationGcsUpdateNoCompression = DestinationGcsUpdateNoCompression{}
	if err := utils.UnmarshalJSON(data, &destinationGcsUpdateNoCompression, "", true, true); err == nil {
		u.DestinationGcsUpdateNoCompression = &destinationGcsUpdateNoCompression
		u.Type = CompressionUnionTypeDestinationGcsUpdateNoCompression
		return nil
	}

	var gzip Gzip = Gzip{}
	if err := utils.UnmarshalJSON(data, &gzip, "", true, true); err == nil {
		u.Gzip = &gzip
		u.Type = CompressionUnionTypeGzip
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for Compression", string(data))
}

func (u Compression) MarshalJSON() ([]byte, error) {
	if u.DestinationGcsUpdateNoCompression != nil {
		return utils.MarshalJSON(u.DestinationGcsUpdateNoCompression, "", true)
	}

	if u.Gzip != nil {
		return utils.MarshalJSON(u.Gzip, "", true)
	}

	return nil, errors.New("could not marshal union type Compression: all fields are null")
}

// Normalization - Whether the input JSON data should be normalized (flattened) in the output CSV. Please refer to docs for details.
type Normalization string

const (
	NormalizationNoFlattening        Normalization = "No flattening"
	NormalizationRootLevelFlattening Normalization = "Root level flattening"
)

func (e Normalization) ToPointer() *Normalization {
	return &e
}
func (e *Normalization) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No flattening":
		fallthrough
	case "Root level flattening":
		*e = Normalization(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Normalization: %v", v)
	}
}

type DestinationGcsUpdateSchemasFormatType string

const (
	DestinationGcsUpdateSchemasFormatTypeCsv DestinationGcsUpdateSchemasFormatType = "CSV"
)

func (e DestinationGcsUpdateSchemasFormatType) ToPointer() *DestinationGcsUpdateSchemasFormatType {
	return &e
}
func (e *DestinationGcsUpdateSchemasFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "CSV":
		*e = DestinationGcsUpdateSchemasFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateSchemasFormatType: %v", v)
	}
}

type DestinationGcsUpdateCSVCommaSeparatedValues struct {
	// Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".csv.gz").
	Compression *Compression `json:"compression,omitempty"`
	// Whether the input JSON data should be normalized (flattened) in the output CSV. Please refer to docs for details.
	Flattening *Normalization                         `default:"No flattening" json:"flattening"`
	FormatType *DestinationGcsUpdateSchemasFormatType `default:"CSV" json:"format_type"`
}

func (d DestinationGcsUpdateCSVCommaSeparatedValues) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsUpdateCSVCommaSeparatedValues) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationGcsUpdateCSVCommaSeparatedValues) GetCompression() *Compression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *DestinationGcsUpdateCSVCommaSeparatedValues) GetFlattening() *Normalization {
	if o == nil {
		return nil
	}
	return o.Flattening
}

func (o *DestinationGcsUpdateCSVCommaSeparatedValues) GetFormatType() *DestinationGcsUpdateSchemasFormatType {
	if o == nil {
		return nil
	}
	return o.FormatType
}

type DestinationGcsUpdateSchemasFormatOutputFormat1Codec string

const (
	DestinationGcsUpdateSchemasFormatOutputFormat1CodecSnappy DestinationGcsUpdateSchemasFormatOutputFormat1Codec = "snappy"
)

func (e DestinationGcsUpdateSchemasFormatOutputFormat1Codec) ToPointer() *DestinationGcsUpdateSchemasFormatOutputFormat1Codec {
	return &e
}
func (e *DestinationGcsUpdateSchemasFormatOutputFormat1Codec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snappy":
		*e = DestinationGcsUpdateSchemasFormatOutputFormat1Codec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateSchemasFormatOutputFormat1Codec: %v", v)
	}
}

type Snappy struct {
	Codec *DestinationGcsUpdateSchemasFormatOutputFormat1Codec `default:"snappy" json:"codec"`
}

func (s Snappy) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Snappy) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *Snappy) GetCodec() *DestinationGcsUpdateSchemasFormatOutputFormat1Codec {
	if o == nil {
		return nil
	}
	return o.Codec
}

type DestinationGcsUpdateSchemasFormatOutputFormatCodec string

const (
	DestinationGcsUpdateSchemasFormatOutputFormatCodecZstandard DestinationGcsUpdateSchemasFormatOutputFormatCodec = "zstandard"
)

func (e DestinationGcsUpdateSchemasFormatOutputFormatCodec) ToPointer() *DestinationGcsUpdateSchemasFormatOutputFormatCodec {
	return &e
}
func (e *DestinationGcsUpdateSchemasFormatOutputFormatCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "zstandard":
		*e = DestinationGcsUpdateSchemasFormatOutputFormatCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateSchemasFormatOutputFormatCodec: %v", v)
	}
}

type Zstandard struct {
	Codec *DestinationGcsUpdateSchemasFormatOutputFormatCodec `default:"zstandard" json:"codec"`
	// Negative levels are 'fast' modes akin to lz4 or snappy, levels above 9 are generally for archival purposes, and levels above 18 use a lot of memory.
	CompressionLevel *int64 `default:"3" json:"compression_level"`
	// If true, include a checksum with each data block.
	IncludeChecksum *bool `default:"false" json:"include_checksum"`
}

func (z Zstandard) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(z, "", false)
}

func (z *Zstandard) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &z, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *Zstandard) GetCodec() *DestinationGcsUpdateSchemasFormatOutputFormatCodec {
	if o == nil {
		return nil
	}
	return o.Codec
}

func (o *Zstandard) GetCompressionLevel() *int64 {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *Zstandard) GetIncludeChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.IncludeChecksum
}

type DestinationGcsUpdateSchemasFormatCodec string

const (
	DestinationGcsUpdateSchemasFormatCodecXz DestinationGcsUpdateSchemasFormatCodec = "xz"
)

func (e DestinationGcsUpdateSchemasFormatCodec) ToPointer() *DestinationGcsUpdateSchemasFormatCodec {
	return &e
}
func (e *DestinationGcsUpdateSchemasFormatCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "xz":
		*e = DestinationGcsUpdateSchemasFormatCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateSchemasFormatCodec: %v", v)
	}
}

type Xz struct {
	Codec *DestinationGcsUpdateSchemasFormatCodec `default:"xz" json:"codec"`
	// The presets 0-3 are fast presets with medium compression. The presets 4-6 are fairly slow presets with high compression. The default preset is 6. The presets 7-9 are like the preset 6 but use bigger dictionaries and have higher compressor and decompressor memory requirements. Unless the uncompressed size of the file exceeds 8 MiB, 16 MiB, or 32 MiB, it is waste of memory to use the presets 7, 8, or 9, respectively. Read more <a href="https://commons.apache.org/proper/commons-compress/apidocs/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.html#XZCompressorOutputStream-java.io.OutputStream-int-">here</a> for details.
	CompressionLevel *int64 `default:"6" json:"compression_level"`
}

func (x Xz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(x, "", false)
}

func (x *Xz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &x, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *Xz) GetCodec() *DestinationGcsUpdateSchemasFormatCodec {
	if o == nil {
		return nil
	}
	return o.Codec
}

func (o *Xz) GetCompressionLevel() *int64 {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

type DestinationGcsUpdateSchemasCodec string

const (
	DestinationGcsUpdateSchemasCodecBzip2 DestinationGcsUpdateSchemasCodec = "bzip2"
)

func (e DestinationGcsUpdateSchemasCodec) ToPointer() *DestinationGcsUpdateSchemasCodec {
	return &e
}
func (e *DestinationGcsUpdateSchemasCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "bzip2":
		*e = DestinationGcsUpdateSchemasCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateSchemasCodec: %v", v)
	}
}

type Bzip2 struct {
	Codec *DestinationGcsUpdateSchemasCodec `default:"bzip2" json:"codec"`
}

func (b Bzip2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(b, "", false)
}

func (b *Bzip2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &b, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *Bzip2) GetCodec() *DestinationGcsUpdateSchemasCodec {
	if o == nil {
		return nil
	}
	return o.Codec
}

type DestinationGcsUpdateCodec string

const (
	DestinationGcsUpdateCodecDeflate DestinationGcsUpdateCodec = "Deflate"
)

func (e DestinationGcsUpdateCodec) ToPointer() *DestinationGcsUpdateCodec {
	return &e
}
func (e *DestinationGcsUpdateCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Deflate":
		*e = DestinationGcsUpdateCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateCodec: %v", v)
	}
}

type Deflate struct {
	Codec *DestinationGcsUpdateCodec `default:"Deflate" json:"codec"`
	// 0: no compression & fastest, 9: best compression & slowest.
	CompressionLevel *int64 `default:"0" json:"compression_level"`
}

func (d Deflate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *Deflate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *Deflate) GetCodec() *DestinationGcsUpdateCodec {
	if o == nil {
		return nil
	}
	return o.Codec
}

func (o *Deflate) GetCompressionLevel() *int64 {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

type Codec string

const (
	CodecNoCompression Codec = "no compression"
)

func (e Codec) ToPointer() *Codec {
	return &e
}
func (e *Codec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "no compression":
		*e = Codec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Codec: %v", v)
	}
}

type NoCompression struct {
	Codec *Codec `default:"no compression" json:"codec"`
}

func (n NoCompression) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(n, "", false)
}

func (n *NoCompression) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &n, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *NoCompression) GetCodec() *Codec {
	if o == nil {
		return nil
	}
	return o.Codec
}

type CompressionCodecType string

const (
	CompressionCodecTypeNoCompression CompressionCodecType = "No Compression"
	CompressionCodecTypeDeflate       CompressionCodecType = "Deflate"
	CompressionCodecTypeBzip2         CompressionCodecType = "bzip2"
	CompressionCodecTypeXz            CompressionCodecType = "xz"
	CompressionCodecTypeZstandard     CompressionCodecType = "zstandard"
	CompressionCodecTypeSnappy        CompressionCodecType = "snappy"
)

// CompressionCodec - The compression algorithm used to compress data. Default to no compression.
type CompressionCodec struct {
	NoCompression *NoCompression
	Deflate       *Deflate
	Bzip2         *Bzip2
	Xz            *Xz
	Zstandard     *Zstandard
	Snappy        *Snappy

	Type CompressionCodecType
}

func CreateCompressionCodecNoCompression(noCompression NoCompression) CompressionCodec {
	typ := CompressionCodecTypeNoCompression

	return CompressionCodec{
		NoCompression: &noCompression,
		Type:          typ,
	}
}

func CreateCompressionCodecDeflate(deflate Deflate) CompressionCodec {
	typ := CompressionCodecTypeDeflate

	return CompressionCodec{
		Deflate: &deflate,
		Type:    typ,
	}
}

func CreateCompressionCodecBzip2(bzip2 Bzip2) CompressionCodec {
	typ := CompressionCodecTypeBzip2

	return CompressionCodec{
		Bzip2: &bzip2,
		Type:  typ,
	}
}

func CreateCompressionCodecXz(xz Xz) CompressionCodec {
	typ := CompressionCodecTypeXz

	return CompressionCodec{
		Xz:   &xz,
		Type: typ,
	}
}

func CreateCompressionCodecZstandard(zstandard Zstandard) CompressionCodec {
	typ := CompressionCodecTypeZstandard

	return CompressionCodec{
		Zstandard: &zstandard,
		Type:      typ,
	}
}

func CreateCompressionCodecSnappy(snappy Snappy) CompressionCodec {
	typ := CompressionCodecTypeSnappy

	return CompressionCodec{
		Snappy: &snappy,
		Type:   typ,
	}
}

func (u *CompressionCodec) UnmarshalJSON(data []byte) error {

	var noCompression NoCompression = NoCompression{}
	if err := utils.UnmarshalJSON(data, &noCompression, "", true, true); err == nil {
		u.NoCompression = &noCompression
		u.Type = CompressionCodecTypeNoCompression
		return nil
	}

	var bzip2 Bzip2 = Bzip2{}
	if err := utils.UnmarshalJSON(data, &bzip2, "", true, true); err == nil {
		u.Bzip2 = &bzip2
		u.Type = CompressionCodecTypeBzip2
		return nil
	}

	var snappy Snappy = Snappy{}
	if err := utils.UnmarshalJSON(data, &snappy, "", true, true); err == nil {
		u.Snappy = &snappy
		u.Type = CompressionCodecTypeSnappy
		return nil
	}

	var deflate Deflate = Deflate{}
	if err := utils.UnmarshalJSON(data, &deflate, "", true, true); err == nil {
		u.Deflate = &deflate
		u.Type = CompressionCodecTypeDeflate
		return nil
	}

	var xz Xz = Xz{}
	if err := utils.UnmarshalJSON(data, &xz, "", true, true); err == nil {
		u.Xz = &xz
		u.Type = CompressionCodecTypeXz
		return nil
	}

	var zstandard Zstandard = Zstandard{}
	if err := utils.UnmarshalJSON(data, &zstandard, "", true, true); err == nil {
		u.Zstandard = &zstandard
		u.Type = CompressionCodecTypeZstandard
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for CompressionCodec", string(data))
}

func (u CompressionCodec) MarshalJSON() ([]byte, error) {
	if u.NoCompression != nil {
		return utils.MarshalJSON(u.NoCompression, "", true)
	}

	if u.Deflate != nil {
		return utils.MarshalJSON(u.Deflate, "", true)
	}

	if u.Bzip2 != nil {
		return utils.MarshalJSON(u.Bzip2, "", true)
	}

	if u.Xz != nil {
		return utils.MarshalJSON(u.Xz, "", true)
	}

	if u.Zstandard != nil {
		return utils.MarshalJSON(u.Zstandard, "", true)
	}

	if u.Snappy != nil {
		return utils.MarshalJSON(u.Snappy, "", true)
	}

	return nil, errors.New("could not marshal union type CompressionCodec: all fields are null")
}

type DestinationGcsUpdateFormatType string

const (
	DestinationGcsUpdateFormatTypeAvro DestinationGcsUpdateFormatType = "Avro"
)

func (e DestinationGcsUpdateFormatType) ToPointer() *DestinationGcsUpdateFormatType {
	return &e
}
func (e *DestinationGcsUpdateFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Avro":
		*e = DestinationGcsUpdateFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsUpdateFormatType: %v", v)
	}
}

type AvroApacheAvro struct {
	// The compression algorithm used to compress data. Default to no compression.
	CompressionCodec CompressionCodec                `json:"compression_codec"`
	FormatType       *DestinationGcsUpdateFormatType `default:"Avro" json:"format_type"`
}

func (a AvroApacheAvro) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AvroApacheAvro) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *AvroApacheAvro) GetCompressionCodec() CompressionCodec {
	if o == nil {
		return CompressionCodec{}
	}
	return o.CompressionCodec
}

func (o *AvroApacheAvro) GetFormatType() *DestinationGcsUpdateFormatType {
	if o == nil {
		return nil
	}
	return o.FormatType
}

type DestinationGcsUpdateOutputFormatType string

const (
	DestinationGcsUpdateOutputFormatTypeAvroApacheAvro                                    DestinationGcsUpdateOutputFormatType = "Avro: Apache Avro"
	DestinationGcsUpdateOutputFormatTypeDestinationGcsUpdateCSVCommaSeparatedValues       DestinationGcsUpdateOutputFormatType = "destination-gcs-update_CSV: Comma-Separated Values"
	DestinationGcsUpdateOutputFormatTypeDestinationGcsUpdateJSONLinesNewlineDelimitedJSON DestinationGcsUpdateOutputFormatType = "destination-gcs-update_JSON Lines: newline-delimited JSON"
	DestinationGcsUpdateOutputFormatTypeDestinationGcsUpdateParquetColumnarStorage        DestinationGcsUpdateOutputFormatType = "destination-gcs-update_Parquet: Columnar Storage"
)

// DestinationGcsUpdateOutputFormat - Output data format. One of the following formats must be selected - <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#advantages_of_avro">AVRO</a> format, <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet#parquet_schemas">PARQUET</a> format, <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv#loading_csv_data_into_a_table">CSV</a> format, or <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json#loading_json_data_into_a_new_table">JSONL</a> format.
type DestinationGcsUpdateOutputFormat struct {
	AvroApacheAvro                                    *AvroApacheAvro
	DestinationGcsUpdateCSVCommaSeparatedValues       *DestinationGcsUpdateCSVCommaSeparatedValues
	DestinationGcsUpdateJSONLinesNewlineDelimitedJSON *DestinationGcsUpdateJSONLinesNewlineDelimitedJSON
	DestinationGcsUpdateParquetColumnarStorage        *DestinationGcsUpdateParquetColumnarStorage

	Type DestinationGcsUpdateOutputFormatType
}

func CreateDestinationGcsUpdateOutputFormatAvroApacheAvro(avroApacheAvro AvroApacheAvro) DestinationGcsUpdateOutputFormat {
	typ := DestinationGcsUpdateOutputFormatTypeAvroApacheAvro

	return DestinationGcsUpdateOutputFormat{
		AvroApacheAvro: &avroApacheAvro,
		Type:           typ,
	}
}

func CreateDestinationGcsUpdateOutputFormatDestinationGcsUpdateCSVCommaSeparatedValues(destinationGcsUpdateCSVCommaSeparatedValues DestinationGcsUpdateCSVCommaSeparatedValues) DestinationGcsUpdateOutputFormat {
	typ := DestinationGcsUpdateOutputFormatTypeDestinationGcsUpdateCSVCommaSeparatedValues

	return DestinationGcsUpdateOutputFormat{
		DestinationGcsUpdateCSVCommaSeparatedValues: &destinationGcsUpdateCSVCommaSeparatedValues,
		Type: typ,
	}
}

func CreateDestinationGcsUpdateOutputFormatDestinationGcsUpdateJSONLinesNewlineDelimitedJSON(destinationGcsUpdateJSONLinesNewlineDelimitedJSON DestinationGcsUpdateJSONLinesNewlineDelimitedJSON) DestinationGcsUpdateOutputFormat {
	typ := DestinationGcsUpdateOutputFormatTypeDestinationGcsUpdateJSONLinesNewlineDelimitedJSON

	return DestinationGcsUpdateOutputFormat{
		DestinationGcsUpdateJSONLinesNewlineDelimitedJSON: &destinationGcsUpdateJSONLinesNewlineDelimitedJSON,
		Type: typ,
	}
}

func CreateDestinationGcsUpdateOutputFormatDestinationGcsUpdateParquetColumnarStorage(destinationGcsUpdateParquetColumnarStorage DestinationGcsUpdateParquetColumnarStorage) DestinationGcsUpdateOutputFormat {
	typ := DestinationGcsUpdateOutputFormatTypeDestinationGcsUpdateParquetColumnarStorage

	return DestinationGcsUpdateOutputFormat{
		DestinationGcsUpdateParquetColumnarStorage: &destinationGcsUpdateParquetColumnarStorage,
		Type: typ,
	}
}

func (u *DestinationGcsUpdateOutputFormat) UnmarshalJSON(data []byte) error {

	var avroApacheAvro AvroApacheAvro = AvroApacheAvro{}
	if err := utils.UnmarshalJSON(data, &avroApacheAvro, "", true, true); err == nil {
		u.AvroApacheAvro = &avroApacheAvro
		u.Type = DestinationGcsUpdateOutputFormatTypeAvroApacheAvro
		return nil
	}

	var destinationGcsUpdateJSONLinesNewlineDelimitedJSON DestinationGcsUpdateJSONLinesNewlineDelimitedJSON = DestinationGcsUpdateJSONLinesNewlineDelimitedJSON{}
	if err := utils.UnmarshalJSON(data, &destinationGcsUpdateJSONLinesNewlineDelimitedJSON, "", true, true); err == nil {
		u.DestinationGcsUpdateJSONLinesNewlineDelimitedJSON = &destinationGcsUpdateJSONLinesNewlineDelimitedJSON
		u.Type = DestinationGcsUpdateOutputFormatTypeDestinationGcsUpdateJSONLinesNewlineDelimitedJSON
		return nil
	}

	var destinationGcsUpdateCSVCommaSeparatedValues DestinationGcsUpdateCSVCommaSeparatedValues = DestinationGcsUpdateCSVCommaSeparatedValues{}
	if err := utils.UnmarshalJSON(data, &destinationGcsUpdateCSVCommaSeparatedValues, "", true, true); err == nil {
		u.DestinationGcsUpdateCSVCommaSeparatedValues = &destinationGcsUpdateCSVCommaSeparatedValues
		u.Type = DestinationGcsUpdateOutputFormatTypeDestinationGcsUpdateCSVCommaSeparatedValues
		return nil
	}

	var destinationGcsUpdateParquetColumnarStorage DestinationGcsUpdateParquetColumnarStorage = DestinationGcsUpdateParquetColumnarStorage{}
	if err := utils.UnmarshalJSON(data, &destinationGcsUpdateParquetColumnarStorage, "", true, true); err == nil {
		u.DestinationGcsUpdateParquetColumnarStorage = &destinationGcsUpdateParquetColumnarStorage
		u.Type = DestinationGcsUpdateOutputFormatTypeDestinationGcsUpdateParquetColumnarStorage
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsUpdateOutputFormat", string(data))
}

func (u DestinationGcsUpdateOutputFormat) MarshalJSON() ([]byte, error) {
	if u.AvroApacheAvro != nil {
		return utils.MarshalJSON(u.AvroApacheAvro, "", true)
	}

	if u.DestinationGcsUpdateCSVCommaSeparatedValues != nil {
		return utils.MarshalJSON(u.DestinationGcsUpdateCSVCommaSeparatedValues, "", true)
	}

	if u.DestinationGcsUpdateJSONLinesNewlineDelimitedJSON != nil {
		return utils.MarshalJSON(u.DestinationGcsUpdateJSONLinesNewlineDelimitedJSON, "", true)
	}

	if u.DestinationGcsUpdateParquetColumnarStorage != nil {
		return utils.MarshalJSON(u.DestinationGcsUpdateParquetColumnarStorage, "", true)
	}

	return nil, errors.New("could not marshal union type DestinationGcsUpdateOutputFormat: all fields are null")
}

// GCSBucketRegion - Select a Region of the GCS Bucket. Read more <a href="https://cloud.google.com/storage/docs/locations">here</a>.
type GCSBucketRegion string

const (
	GCSBucketRegionNorthamericaNortheast1 GCSBucketRegion = "northamerica-northeast1"
	GCSBucketRegionNorthamericaNortheast2 GCSBucketRegion = "northamerica-northeast2"
	GCSBucketRegionUsCentral1             GCSBucketRegion = "us-central1"
	GCSBucketRegionUsEast1                GCSBucketRegion = "us-east1"
	GCSBucketRegionUsEast4                GCSBucketRegion = "us-east4"
	GCSBucketRegionUsWest1                GCSBucketRegion = "us-west1"
	GCSBucketRegionUsWest2                GCSBucketRegion = "us-west2"
	GCSBucketRegionUsWest3                GCSBucketRegion = "us-west3"
	GCSBucketRegionUsWest4                GCSBucketRegion = "us-west4"
	GCSBucketRegionSouthamericaEast1      GCSBucketRegion = "southamerica-east1"
	GCSBucketRegionSouthamericaWest1      GCSBucketRegion = "southamerica-west1"
	GCSBucketRegionEuropeCentral2         GCSBucketRegion = "europe-central2"
	GCSBucketRegionEuropeNorth1           GCSBucketRegion = "europe-north1"
	GCSBucketRegionEuropeWest1            GCSBucketRegion = "europe-west1"
	GCSBucketRegionEuropeWest2            GCSBucketRegion = "europe-west2"
	GCSBucketRegionEuropeWest3            GCSBucketRegion = "europe-west3"
	GCSBucketRegionEuropeWest4            GCSBucketRegion = "europe-west4"
	GCSBucketRegionEuropeWest6            GCSBucketRegion = "europe-west6"
	GCSBucketRegionAsiaEast1              GCSBucketRegion = "asia-east1"
	GCSBucketRegionAsiaEast2              GCSBucketRegion = "asia-east2"
	GCSBucketRegionAsiaNortheast1         GCSBucketRegion = "asia-northeast1"
	GCSBucketRegionAsiaNortheast2         GCSBucketRegion = "asia-northeast2"
	GCSBucketRegionAsiaNortheast3         GCSBucketRegion = "asia-northeast3"
	GCSBucketRegionAsiaSouth1             GCSBucketRegion = "asia-south1"
	GCSBucketRegionAsiaSouth2             GCSBucketRegion = "asia-south2"
	GCSBucketRegionAsiaSoutheast1         GCSBucketRegion = "asia-southeast1"
	GCSBucketRegionAsiaSoutheast2         GCSBucketRegion = "asia-southeast2"
	GCSBucketRegionAustraliaSoutheast1    GCSBucketRegion = "australia-southeast1"
	GCSBucketRegionAustraliaSoutheast2    GCSBucketRegion = "australia-southeast2"
	GCSBucketRegionAsia                   GCSBucketRegion = "asia"
	GCSBucketRegionEu                     GCSBucketRegion = "eu"
	GCSBucketRegionUs                     GCSBucketRegion = "us"
	GCSBucketRegionAsia1                  GCSBucketRegion = "asia1"
	GCSBucketRegionEur4                   GCSBucketRegion = "eur4"
	GCSBucketRegionNam4                   GCSBucketRegion = "nam4"
)

func (e GCSBucketRegion) ToPointer() *GCSBucketRegion {
	return &e
}
func (e *GCSBucketRegion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "northamerica-northeast1":
		fallthrough
	case "northamerica-northeast2":
		fallthrough
	case "us-central1":
		fallthrough
	case "us-east1":
		fallthrough
	case "us-east4":
		fallthrough
	case "us-west1":
		fallthrough
	case "us-west2":
		fallthrough
	case "us-west3":
		fallthrough
	case "us-west4":
		fallthrough
	case "southamerica-east1":
		fallthrough
	case "southamerica-west1":
		fallthrough
	case "europe-central2":
		fallthrough
	case "europe-north1":
		fallthrough
	case "europe-west1":
		fallthrough
	case "europe-west2":
		fallthrough
	case "europe-west3":
		fallthrough
	case "europe-west4":
		fallthrough
	case "europe-west6":
		fallthrough
	case "asia-east1":
		fallthrough
	case "asia-east2":
		fallthrough
	case "asia-northeast1":
		fallthrough
	case "asia-northeast2":
		fallthrough
	case "asia-northeast3":
		fallthrough
	case "asia-south1":
		fallthrough
	case "asia-south2":
		fallthrough
	case "asia-southeast1":
		fallthrough
	case "asia-southeast2":
		fallthrough
	case "australia-southeast1":
		fallthrough
	case "australia-southeast2":
		fallthrough
	case "asia":
		fallthrough
	case "eu":
		fallthrough
	case "us":
		fallthrough
	case "asia1":
		fallthrough
	case "eur4":
		fallthrough
	case "nam4":
		*e = GCSBucketRegion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for GCSBucketRegion: %v", v)
	}
}

type DestinationGcsUpdate struct {
	// An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys">here</a>.
	Credential DestinationGcsUpdateAuthentication `json:"credential"`
	// Output data format. One of the following formats must be selected - <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#advantages_of_avro">AVRO</a> format, <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet#parquet_schemas">PARQUET</a> format, <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv#loading_csv_data_into_a_table">CSV</a> format, or <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json#loading_json_data_into_a_new_table">JSONL</a> format.
	Format DestinationGcsUpdateOutputFormat `json:"format"`
	// You can find the bucket name in the App Engine Admin console Application Settings page, under the label Google Cloud Storage Bucket. Read more <a href="https://cloud.google.com/storage/docs/naming-buckets">here</a>.
	GcsBucketName string `json:"gcs_bucket_name"`
	// GCS Bucket Path string Subdirectory under the above bucket to sync the data into.
	GcsBucketPath string `json:"gcs_bucket_path"`
	// Select a Region of the GCS Bucket. Read more <a href="https://cloud.google.com/storage/docs/locations">here</a>.
	GcsBucketRegion *GCSBucketRegion `default:"us" json:"gcs_bucket_region"`
}

func (d DestinationGcsUpdate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsUpdate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DestinationGcsUpdate) GetCredential() DestinationGcsUpdateAuthentication {
	if o == nil {
		return DestinationGcsUpdateAuthentication{}
	}
	return o.Credential
}

func (o *DestinationGcsUpdate) GetFormat() DestinationGcsUpdateOutputFormat {
	if o == nil {
		return DestinationGcsUpdateOutputFormat{}
	}
	return o.Format
}

func (o *DestinationGcsUpdate) GetGcsBucketName() string {
	if o == nil {
		return ""
	}
	return o.GcsBucketName
}

func (o *DestinationGcsUpdate) GetGcsBucketPath() string {
	if o == nil {
		return ""
	}
	return o.GcsBucketPath
}

func (o *DestinationGcsUpdate) GetGcsBucketRegion() *GCSBucketRegion {
	if o == nil {
		return nil
	}
	return o.GcsBucketRegion
}
