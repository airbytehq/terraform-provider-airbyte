// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/internal/utils"
	"time"
)

type SourceSftpBulkSchemasAuthType string

const (
	SourceSftpBulkSchemasAuthTypePrivateKey SourceSftpBulkSchemasAuthType = "private_key"
)

func (e SourceSftpBulkSchemasAuthType) ToPointer() *SourceSftpBulkSchemasAuthType {
	return &e
}
func (e *SourceSftpBulkSchemasAuthType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private_key":
		*e = SourceSftpBulkSchemasAuthType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkSchemasAuthType: %v", v)
	}
}

type SourceSftpBulkAuthenticateViaPrivateKey struct {
	authType *SourceSftpBulkSchemasAuthType `const:"private_key" json:"auth_type"`
	// The Private key
	PrivateKey string `json:"private_key"`
}

func (s SourceSftpBulkAuthenticateViaPrivateKey) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkAuthenticateViaPrivateKey) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkAuthenticateViaPrivateKey) GetAuthType() *SourceSftpBulkSchemasAuthType {
	return SourceSftpBulkSchemasAuthTypePrivateKey.ToPointer()
}

func (o *SourceSftpBulkAuthenticateViaPrivateKey) GetPrivateKey() string {
	if o == nil {
		return ""
	}
	return o.PrivateKey
}

type SourceSftpBulkAuthType string

const (
	SourceSftpBulkAuthTypePassword SourceSftpBulkAuthType = "password"
)

func (e SourceSftpBulkAuthType) ToPointer() *SourceSftpBulkAuthType {
	return &e
}
func (e *SourceSftpBulkAuthType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "password":
		*e = SourceSftpBulkAuthType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkAuthType: %v", v)
	}
}

type SourceSftpBulkAuthenticateViaPassword struct {
	authType *SourceSftpBulkAuthType `const:"password" json:"auth_type"`
	// Password
	Password string `json:"password"`
}

func (s SourceSftpBulkAuthenticateViaPassword) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkAuthenticateViaPassword) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkAuthenticateViaPassword) GetAuthType() *SourceSftpBulkAuthType {
	return SourceSftpBulkAuthTypePassword.ToPointer()
}

func (o *SourceSftpBulkAuthenticateViaPassword) GetPassword() string {
	if o == nil {
		return ""
	}
	return o.Password
}

type SourceSftpBulkAuthenticationType string

const (
	SourceSftpBulkAuthenticationTypeSourceSftpBulkAuthenticateViaPassword   SourceSftpBulkAuthenticationType = "source-sftp-bulk_Authenticate via Password"
	SourceSftpBulkAuthenticationTypeSourceSftpBulkAuthenticateViaPrivateKey SourceSftpBulkAuthenticationType = "source-sftp-bulk_Authenticate via Private Key"
)

// SourceSftpBulkAuthentication - Credentials for connecting to the SFTP Server
type SourceSftpBulkAuthentication struct {
	SourceSftpBulkAuthenticateViaPassword   *SourceSftpBulkAuthenticateViaPassword
	SourceSftpBulkAuthenticateViaPrivateKey *SourceSftpBulkAuthenticateViaPrivateKey

	Type SourceSftpBulkAuthenticationType
}

func CreateSourceSftpBulkAuthenticationSourceSftpBulkAuthenticateViaPassword(sourceSftpBulkAuthenticateViaPassword SourceSftpBulkAuthenticateViaPassword) SourceSftpBulkAuthentication {
	typ := SourceSftpBulkAuthenticationTypeSourceSftpBulkAuthenticateViaPassword

	return SourceSftpBulkAuthentication{
		SourceSftpBulkAuthenticateViaPassword: &sourceSftpBulkAuthenticateViaPassword,
		Type:                                  typ,
	}
}

func CreateSourceSftpBulkAuthenticationSourceSftpBulkAuthenticateViaPrivateKey(sourceSftpBulkAuthenticateViaPrivateKey SourceSftpBulkAuthenticateViaPrivateKey) SourceSftpBulkAuthentication {
	typ := SourceSftpBulkAuthenticationTypeSourceSftpBulkAuthenticateViaPrivateKey

	return SourceSftpBulkAuthentication{
		SourceSftpBulkAuthenticateViaPrivateKey: &sourceSftpBulkAuthenticateViaPrivateKey,
		Type:                                    typ,
	}
}

func (u *SourceSftpBulkAuthentication) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkAuthenticateViaPassword SourceSftpBulkAuthenticateViaPassword = SourceSftpBulkAuthenticateViaPassword{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkAuthenticateViaPassword, "", true, true); err == nil {
		u.SourceSftpBulkAuthenticateViaPassword = &sourceSftpBulkAuthenticateViaPassword
		u.Type = SourceSftpBulkAuthenticationTypeSourceSftpBulkAuthenticateViaPassword
		return nil
	}

	var sourceSftpBulkAuthenticateViaPrivateKey SourceSftpBulkAuthenticateViaPrivateKey = SourceSftpBulkAuthenticateViaPrivateKey{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkAuthenticateViaPrivateKey, "", true, true); err == nil {
		u.SourceSftpBulkAuthenticateViaPrivateKey = &sourceSftpBulkAuthenticateViaPrivateKey
		u.Type = SourceSftpBulkAuthenticationTypeSourceSftpBulkAuthenticateViaPrivateKey
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkAuthentication", string(data))
}

func (u SourceSftpBulkAuthentication) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkAuthenticateViaPassword != nil {
		return utils.MarshalJSON(u.SourceSftpBulkAuthenticateViaPassword, "", true)
	}

	if u.SourceSftpBulkAuthenticateViaPrivateKey != nil {
		return utils.MarshalJSON(u.SourceSftpBulkAuthenticateViaPrivateKey, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkAuthentication: all fields are null")
}

type SftpBulk string

const (
	SftpBulkSftpBulk SftpBulk = "sftp-bulk"
)

func (e SftpBulk) ToPointer() *SftpBulk {
	return &e
}
func (e *SftpBulk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sftp-bulk":
		*e = SftpBulk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SftpBulk: %v", v)
	}
}

type SourceSftpBulkSchemasStreamsFormatFormat6Filetype string

const (
	SourceSftpBulkSchemasStreamsFormatFormat6FiletypeExcel SourceSftpBulkSchemasStreamsFormatFormat6Filetype = "excel"
)

func (e SourceSftpBulkSchemasStreamsFormatFormat6Filetype) ToPointer() *SourceSftpBulkSchemasStreamsFormatFormat6Filetype {
	return &e
}
func (e *SourceSftpBulkSchemasStreamsFormatFormat6Filetype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "excel":
		*e = SourceSftpBulkSchemasStreamsFormatFormat6Filetype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkSchemasStreamsFormatFormat6Filetype: %v", v)
	}
}

type SourceSftpBulkExcelFormat struct {
	filetype *SourceSftpBulkSchemasStreamsFormatFormat6Filetype `const:"excel" json:"filetype"`
}

func (s SourceSftpBulkExcelFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkExcelFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkExcelFormat) GetFiletype() *SourceSftpBulkSchemasStreamsFormatFormat6Filetype {
	return SourceSftpBulkSchemasStreamsFormatFormat6FiletypeExcel.ToPointer()
}

type SourceSftpBulkSchemasStreamsFormatFormatFiletype string

const (
	SourceSftpBulkSchemasStreamsFormatFormatFiletypeUnstructured SourceSftpBulkSchemasStreamsFormatFormatFiletype = "unstructured"
)

func (e SourceSftpBulkSchemasStreamsFormatFormatFiletype) ToPointer() *SourceSftpBulkSchemasStreamsFormatFormatFiletype {
	return &e
}
func (e *SourceSftpBulkSchemasStreamsFormatFormatFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "unstructured":
		*e = SourceSftpBulkSchemasStreamsFormatFormatFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkSchemasStreamsFormatFormatFiletype: %v", v)
	}
}

type SourceSftpBulkSchemasMode string

const (
	SourceSftpBulkSchemasModeAPI SourceSftpBulkSchemasMode = "api"
)

func (e SourceSftpBulkSchemasMode) ToPointer() *SourceSftpBulkSchemasMode {
	return &e
}
func (e *SourceSftpBulkSchemasMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "api":
		*e = SourceSftpBulkSchemasMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkSchemasMode: %v", v)
	}
}

type SourceSftpBulkAPIParameterConfigModel struct {
	// The name of the unstructured API parameter to use
	Name string `json:"name"`
	// The value of the parameter
	Value string `json:"value"`
}

func (o *SourceSftpBulkAPIParameterConfigModel) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SourceSftpBulkAPIParameterConfigModel) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// SourceSftpBulkViaAPI - Process files via an API, using the `hi_res` mode. This option is useful for increased performance and accuracy, but requires an API key and a hosted instance of unstructured.
type SourceSftpBulkViaAPI struct {
	// The API key to use matching the environment
	APIKey *string `default:"" json:"api_key"`
	// The URL of the unstructured API to use
	APIURL *string                    `default:"https://api.unstructured.io" json:"api_url"`
	mode   *SourceSftpBulkSchemasMode `const:"api" json:"mode"`
	// List of parameters send to the API
	Parameters []SourceSftpBulkAPIParameterConfigModel `json:"parameters,omitempty"`
}

func (s SourceSftpBulkViaAPI) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkViaAPI) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkViaAPI) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *SourceSftpBulkViaAPI) GetAPIURL() *string {
	if o == nil {
		return nil
	}
	return o.APIURL
}

func (o *SourceSftpBulkViaAPI) GetMode() *SourceSftpBulkSchemasMode {
	return SourceSftpBulkSchemasModeAPI.ToPointer()
}

func (o *SourceSftpBulkViaAPI) GetParameters() []SourceSftpBulkAPIParameterConfigModel {
	if o == nil {
		return nil
	}
	return o.Parameters
}

type SourceSftpBulkMode string

const (
	SourceSftpBulkModeLocal SourceSftpBulkMode = "local"
)

func (e SourceSftpBulkMode) ToPointer() *SourceSftpBulkMode {
	return &e
}
func (e *SourceSftpBulkMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "local":
		*e = SourceSftpBulkMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkMode: %v", v)
	}
}

// SourceSftpBulkLocal - Process files locally, supporting `fast` and `ocr` modes. This is the default option.
type SourceSftpBulkLocal struct {
	mode *SourceSftpBulkMode `const:"local" json:"mode"`
}

func (s SourceSftpBulkLocal) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkLocal) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkLocal) GetMode() *SourceSftpBulkMode {
	return SourceSftpBulkModeLocal.ToPointer()
}

type SourceSftpBulkProcessingType string

const (
	SourceSftpBulkProcessingTypeSourceSftpBulkLocal  SourceSftpBulkProcessingType = "source-sftp-bulk_Local"
	SourceSftpBulkProcessingTypeSourceSftpBulkViaAPI SourceSftpBulkProcessingType = "source-sftp-bulk_via API"
)

// SourceSftpBulkProcessing - Processing configuration
type SourceSftpBulkProcessing struct {
	SourceSftpBulkLocal  *SourceSftpBulkLocal
	SourceSftpBulkViaAPI *SourceSftpBulkViaAPI

	Type SourceSftpBulkProcessingType
}

func CreateSourceSftpBulkProcessingSourceSftpBulkLocal(sourceSftpBulkLocal SourceSftpBulkLocal) SourceSftpBulkProcessing {
	typ := SourceSftpBulkProcessingTypeSourceSftpBulkLocal

	return SourceSftpBulkProcessing{
		SourceSftpBulkLocal: &sourceSftpBulkLocal,
		Type:                typ,
	}
}

func CreateSourceSftpBulkProcessingSourceSftpBulkViaAPI(sourceSftpBulkViaAPI SourceSftpBulkViaAPI) SourceSftpBulkProcessing {
	typ := SourceSftpBulkProcessingTypeSourceSftpBulkViaAPI

	return SourceSftpBulkProcessing{
		SourceSftpBulkViaAPI: &sourceSftpBulkViaAPI,
		Type:                 typ,
	}
}

func (u *SourceSftpBulkProcessing) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkLocal SourceSftpBulkLocal = SourceSftpBulkLocal{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkLocal, "", true, true); err == nil {
		u.SourceSftpBulkLocal = &sourceSftpBulkLocal
		u.Type = SourceSftpBulkProcessingTypeSourceSftpBulkLocal
		return nil
	}

	var sourceSftpBulkViaAPI SourceSftpBulkViaAPI = SourceSftpBulkViaAPI{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkViaAPI, "", true, true); err == nil {
		u.SourceSftpBulkViaAPI = &sourceSftpBulkViaAPI
		u.Type = SourceSftpBulkProcessingTypeSourceSftpBulkViaAPI
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkProcessing", string(data))
}

func (u SourceSftpBulkProcessing) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkLocal != nil {
		return utils.MarshalJSON(u.SourceSftpBulkLocal, "", true)
	}

	if u.SourceSftpBulkViaAPI != nil {
		return utils.MarshalJSON(u.SourceSftpBulkViaAPI, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkProcessing: all fields are null")
}

// SourceSftpBulkParsingStrategy - The strategy used to parse documents. `fast` extracts text directly from the document which doesn't work for all files. `ocr_only` is more reliable, but slower. `hi_res` is the most reliable, but requires an API key and a hosted instance of unstructured and can't be used with local mode. See the unstructured.io documentation for more details: https://unstructured-io.github.io/unstructured/core/partition.html#partition-pdf
type SourceSftpBulkParsingStrategy string

const (
	SourceSftpBulkParsingStrategyAuto    SourceSftpBulkParsingStrategy = "auto"
	SourceSftpBulkParsingStrategyFast    SourceSftpBulkParsingStrategy = "fast"
	SourceSftpBulkParsingStrategyOcrOnly SourceSftpBulkParsingStrategy = "ocr_only"
	SourceSftpBulkParsingStrategyHiRes   SourceSftpBulkParsingStrategy = "hi_res"
)

func (e SourceSftpBulkParsingStrategy) ToPointer() *SourceSftpBulkParsingStrategy {
	return &e
}
func (e *SourceSftpBulkParsingStrategy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "fast":
		fallthrough
	case "ocr_only":
		fallthrough
	case "hi_res":
		*e = SourceSftpBulkParsingStrategy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkParsingStrategy: %v", v)
	}
}

// SourceSftpBulkUnstructuredDocumentFormat - Extract text from document formats (.pdf, .docx, .md, .pptx) and emit as one record per file.
type SourceSftpBulkUnstructuredDocumentFormat struct {
	filetype *SourceSftpBulkSchemasStreamsFormatFormatFiletype `const:"unstructured" json:"filetype"`
	// Processing configuration
	Processing *SourceSftpBulkProcessing `json:"processing,omitempty"`
	// If true, skip files that cannot be parsed and pass the error message along as the _ab_source_file_parse_error field. If false, fail the sync.
	SkipUnprocessableFiles *bool `default:"true" json:"skip_unprocessable_files"`
	// The strategy used to parse documents. `fast` extracts text directly from the document which doesn't work for all files. `ocr_only` is more reliable, but slower. `hi_res` is the most reliable, but requires an API key and a hosted instance of unstructured and can't be used with local mode. See the unstructured.io documentation for more details: https://unstructured-io.github.io/unstructured/core/partition.html#partition-pdf
	Strategy *SourceSftpBulkParsingStrategy `default:"auto" json:"strategy"`
}

func (s SourceSftpBulkUnstructuredDocumentFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUnstructuredDocumentFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUnstructuredDocumentFormat) GetFiletype() *SourceSftpBulkSchemasStreamsFormatFormatFiletype {
	return SourceSftpBulkSchemasStreamsFormatFormatFiletypeUnstructured.ToPointer()
}

func (o *SourceSftpBulkUnstructuredDocumentFormat) GetProcessing() *SourceSftpBulkProcessing {
	if o == nil {
		return nil
	}
	return o.Processing
}

func (o *SourceSftpBulkUnstructuredDocumentFormat) GetSkipUnprocessableFiles() *bool {
	if o == nil {
		return nil
	}
	return o.SkipUnprocessableFiles
}

func (o *SourceSftpBulkUnstructuredDocumentFormat) GetStrategy() *SourceSftpBulkParsingStrategy {
	if o == nil {
		return nil
	}
	return o.Strategy
}

type SourceSftpBulkSchemasStreamsFormatFiletype string

const (
	SourceSftpBulkSchemasStreamsFormatFiletypeParquet SourceSftpBulkSchemasStreamsFormatFiletype = "parquet"
)

func (e SourceSftpBulkSchemasStreamsFormatFiletype) ToPointer() *SourceSftpBulkSchemasStreamsFormatFiletype {
	return &e
}
func (e *SourceSftpBulkSchemasStreamsFormatFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "parquet":
		*e = SourceSftpBulkSchemasStreamsFormatFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkSchemasStreamsFormatFiletype: %v", v)
	}
}

type SourceSftpBulkParquetFormat struct {
	// Whether to convert decimal fields to floats. There is a loss of precision when converting decimals to floats, so this is not recommended.
	DecimalAsFloat *bool                                       `default:"false" json:"decimal_as_float"`
	filetype       *SourceSftpBulkSchemasStreamsFormatFiletype `const:"parquet" json:"filetype"`
}

func (s SourceSftpBulkParquetFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkParquetFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkParquetFormat) GetDecimalAsFloat() *bool {
	if o == nil {
		return nil
	}
	return o.DecimalAsFloat
}

func (o *SourceSftpBulkParquetFormat) GetFiletype() *SourceSftpBulkSchemasStreamsFormatFiletype {
	return SourceSftpBulkSchemasStreamsFormatFiletypeParquet.ToPointer()
}

type SourceSftpBulkSchemasStreamsFiletype string

const (
	SourceSftpBulkSchemasStreamsFiletypeJsonl SourceSftpBulkSchemasStreamsFiletype = "jsonl"
)

func (e SourceSftpBulkSchemasStreamsFiletype) ToPointer() *SourceSftpBulkSchemasStreamsFiletype {
	return &e
}
func (e *SourceSftpBulkSchemasStreamsFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "jsonl":
		*e = SourceSftpBulkSchemasStreamsFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkSchemasStreamsFiletype: %v", v)
	}
}

type SourceSftpBulkJsonlFormat struct {
	filetype *SourceSftpBulkSchemasStreamsFiletype `const:"jsonl" json:"filetype"`
}

func (s SourceSftpBulkJsonlFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkJsonlFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkJsonlFormat) GetFiletype() *SourceSftpBulkSchemasStreamsFiletype {
	return SourceSftpBulkSchemasStreamsFiletypeJsonl.ToPointer()
}

type SourceSftpBulkSchemasFiletype string

const (
	SourceSftpBulkSchemasFiletypeCsv SourceSftpBulkSchemasFiletype = "csv"
)

func (e SourceSftpBulkSchemasFiletype) ToPointer() *SourceSftpBulkSchemasFiletype {
	return &e
}
func (e *SourceSftpBulkSchemasFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "csv":
		*e = SourceSftpBulkSchemasFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkSchemasFiletype: %v", v)
	}
}

type SourceSftpBulkSchemasStreamsHeaderDefinitionType string

const (
	SourceSftpBulkSchemasStreamsHeaderDefinitionTypeUserProvided SourceSftpBulkSchemasStreamsHeaderDefinitionType = "User Provided"
)

func (e SourceSftpBulkSchemasStreamsHeaderDefinitionType) ToPointer() *SourceSftpBulkSchemasStreamsHeaderDefinitionType {
	return &e
}
func (e *SourceSftpBulkSchemasStreamsHeaderDefinitionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "User Provided":
		*e = SourceSftpBulkSchemasStreamsHeaderDefinitionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkSchemasStreamsHeaderDefinitionType: %v", v)
	}
}

type SourceSftpBulkUserProvided struct {
	// The column names that will be used while emitting the CSV records
	ColumnNames          []string                                          `json:"column_names"`
	headerDefinitionType *SourceSftpBulkSchemasStreamsHeaderDefinitionType `const:"User Provided" json:"header_definition_type"`
}

func (s SourceSftpBulkUserProvided) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUserProvided) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUserProvided) GetColumnNames() []string {
	if o == nil {
		return []string{}
	}
	return o.ColumnNames
}

func (o *SourceSftpBulkUserProvided) GetHeaderDefinitionType() *SourceSftpBulkSchemasStreamsHeaderDefinitionType {
	return SourceSftpBulkSchemasStreamsHeaderDefinitionTypeUserProvided.ToPointer()
}

type SourceSftpBulkSchemasHeaderDefinitionType string

const (
	SourceSftpBulkSchemasHeaderDefinitionTypeAutogenerated SourceSftpBulkSchemasHeaderDefinitionType = "Autogenerated"
)

func (e SourceSftpBulkSchemasHeaderDefinitionType) ToPointer() *SourceSftpBulkSchemasHeaderDefinitionType {
	return &e
}
func (e *SourceSftpBulkSchemasHeaderDefinitionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Autogenerated":
		*e = SourceSftpBulkSchemasHeaderDefinitionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkSchemasHeaderDefinitionType: %v", v)
	}
}

type SourceSftpBulkAutogenerated struct {
	headerDefinitionType *SourceSftpBulkSchemasHeaderDefinitionType `const:"Autogenerated" json:"header_definition_type"`
}

func (s SourceSftpBulkAutogenerated) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkAutogenerated) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkAutogenerated) GetHeaderDefinitionType() *SourceSftpBulkSchemasHeaderDefinitionType {
	return SourceSftpBulkSchemasHeaderDefinitionTypeAutogenerated.ToPointer()
}

type SourceSftpBulkHeaderDefinitionType string

const (
	SourceSftpBulkHeaderDefinitionTypeFromCsv SourceSftpBulkHeaderDefinitionType = "From CSV"
)

func (e SourceSftpBulkHeaderDefinitionType) ToPointer() *SourceSftpBulkHeaderDefinitionType {
	return &e
}
func (e *SourceSftpBulkHeaderDefinitionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "From CSV":
		*e = SourceSftpBulkHeaderDefinitionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkHeaderDefinitionType: %v", v)
	}
}

type SourceSftpBulkFromCSV struct {
	headerDefinitionType *SourceSftpBulkHeaderDefinitionType `const:"From CSV" json:"header_definition_type"`
}

func (s SourceSftpBulkFromCSV) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkFromCSV) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkFromCSV) GetHeaderDefinitionType() *SourceSftpBulkHeaderDefinitionType {
	return SourceSftpBulkHeaderDefinitionTypeFromCsv.ToPointer()
}

type SourceSftpBulkCSVHeaderDefinitionType string

const (
	SourceSftpBulkCSVHeaderDefinitionTypeSourceSftpBulkFromCSV       SourceSftpBulkCSVHeaderDefinitionType = "source-sftp-bulk_From CSV"
	SourceSftpBulkCSVHeaderDefinitionTypeSourceSftpBulkAutogenerated SourceSftpBulkCSVHeaderDefinitionType = "source-sftp-bulk_Autogenerated"
	SourceSftpBulkCSVHeaderDefinitionTypeSourceSftpBulkUserProvided  SourceSftpBulkCSVHeaderDefinitionType = "source-sftp-bulk_User Provided"
)

// SourceSftpBulkCSVHeaderDefinition - How headers will be defined. `User Provided` assumes the CSV does not have a header row and uses the headers provided and `Autogenerated` assumes the CSV does not have a header row and the CDK will generate headers using for `f{i}` where `i` is the index starting from 0. Else, the default behavior is to use the header from the CSV file. If a user wants to autogenerate or provide column names for a CSV having headers, they can skip rows.
type SourceSftpBulkCSVHeaderDefinition struct {
	SourceSftpBulkFromCSV       *SourceSftpBulkFromCSV
	SourceSftpBulkAutogenerated *SourceSftpBulkAutogenerated
	SourceSftpBulkUserProvided  *SourceSftpBulkUserProvided

	Type SourceSftpBulkCSVHeaderDefinitionType
}

func CreateSourceSftpBulkCSVHeaderDefinitionSourceSftpBulkFromCSV(sourceSftpBulkFromCSV SourceSftpBulkFromCSV) SourceSftpBulkCSVHeaderDefinition {
	typ := SourceSftpBulkCSVHeaderDefinitionTypeSourceSftpBulkFromCSV

	return SourceSftpBulkCSVHeaderDefinition{
		SourceSftpBulkFromCSV: &sourceSftpBulkFromCSV,
		Type:                  typ,
	}
}

func CreateSourceSftpBulkCSVHeaderDefinitionSourceSftpBulkAutogenerated(sourceSftpBulkAutogenerated SourceSftpBulkAutogenerated) SourceSftpBulkCSVHeaderDefinition {
	typ := SourceSftpBulkCSVHeaderDefinitionTypeSourceSftpBulkAutogenerated

	return SourceSftpBulkCSVHeaderDefinition{
		SourceSftpBulkAutogenerated: &sourceSftpBulkAutogenerated,
		Type:                        typ,
	}
}

func CreateSourceSftpBulkCSVHeaderDefinitionSourceSftpBulkUserProvided(sourceSftpBulkUserProvided SourceSftpBulkUserProvided) SourceSftpBulkCSVHeaderDefinition {
	typ := SourceSftpBulkCSVHeaderDefinitionTypeSourceSftpBulkUserProvided

	return SourceSftpBulkCSVHeaderDefinition{
		SourceSftpBulkUserProvided: &sourceSftpBulkUserProvided,
		Type:                       typ,
	}
}

func (u *SourceSftpBulkCSVHeaderDefinition) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkFromCSV SourceSftpBulkFromCSV = SourceSftpBulkFromCSV{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkFromCSV, "", true, true); err == nil {
		u.SourceSftpBulkFromCSV = &sourceSftpBulkFromCSV
		u.Type = SourceSftpBulkCSVHeaderDefinitionTypeSourceSftpBulkFromCSV
		return nil
	}

	var sourceSftpBulkAutogenerated SourceSftpBulkAutogenerated = SourceSftpBulkAutogenerated{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkAutogenerated, "", true, true); err == nil {
		u.SourceSftpBulkAutogenerated = &sourceSftpBulkAutogenerated
		u.Type = SourceSftpBulkCSVHeaderDefinitionTypeSourceSftpBulkAutogenerated
		return nil
	}

	var sourceSftpBulkUserProvided SourceSftpBulkUserProvided = SourceSftpBulkUserProvided{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUserProvided, "", true, true); err == nil {
		u.SourceSftpBulkUserProvided = &sourceSftpBulkUserProvided
		u.Type = SourceSftpBulkCSVHeaderDefinitionTypeSourceSftpBulkUserProvided
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkCSVHeaderDefinition", string(data))
}

func (u SourceSftpBulkCSVHeaderDefinition) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkFromCSV != nil {
		return utils.MarshalJSON(u.SourceSftpBulkFromCSV, "", true)
	}

	if u.SourceSftpBulkAutogenerated != nil {
		return utils.MarshalJSON(u.SourceSftpBulkAutogenerated, "", true)
	}

	if u.SourceSftpBulkUserProvided != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUserProvided, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkCSVHeaderDefinition: all fields are null")
}

// SourceSftpBulkInferenceType - How to infer the types of the columns. If none, inference default to strings.
type SourceSftpBulkInferenceType string

const (
	SourceSftpBulkInferenceTypeNone               SourceSftpBulkInferenceType = "None"
	SourceSftpBulkInferenceTypePrimitiveTypesOnly SourceSftpBulkInferenceType = "Primitive Types Only"
)

func (e SourceSftpBulkInferenceType) ToPointer() *SourceSftpBulkInferenceType {
	return &e
}
func (e *SourceSftpBulkInferenceType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "None":
		fallthrough
	case "Primitive Types Only":
		*e = SourceSftpBulkInferenceType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkInferenceType: %v", v)
	}
}

type SourceSftpBulkCSVFormat struct {
	// The character delimiting individual cells in the CSV data. This may only be a 1-character string. For tab-delimited data enter '\t'.
	Delimiter *string `default:"," json:"delimiter"`
	// Whether two quotes in a quoted CSV value denote a single quote in the data.
	DoubleQuote *bool `default:"true" json:"double_quote"`
	// The character encoding of the CSV data. Leave blank to default to <strong>UTF8</strong>. See <a href="https://docs.python.org/3/library/codecs.html#standard-encodings" target="_blank">list of python encodings</a> for allowable options.
	Encoding *string `default:"utf8" json:"encoding"`
	// The character used for escaping special characters. To disallow escaping, leave this field blank.
	EscapeChar *string `json:"escape_char,omitempty"`
	// A set of case-sensitive strings that should be interpreted as false values.
	FalseValues []string                       `json:"false_values,omitempty"`
	filetype    *SourceSftpBulkSchemasFiletype `const:"csv" json:"filetype"`
	// How headers will be defined. `User Provided` assumes the CSV does not have a header row and uses the headers provided and `Autogenerated` assumes the CSV does not have a header row and the CDK will generate headers using for `f{i}` where `i` is the index starting from 0. Else, the default behavior is to use the header from the CSV file. If a user wants to autogenerate or provide column names for a CSV having headers, they can skip rows.
	HeaderDefinition *SourceSftpBulkCSVHeaderDefinition `json:"header_definition,omitempty"`
	// Whether to ignore errors that occur when the number of fields in the CSV does not match the number of columns in the schema.
	IgnoreErrorsOnFieldsMismatch *bool `default:"false" json:"ignore_errors_on_fields_mismatch"`
	// How to infer the types of the columns. If none, inference default to strings.
	InferenceType *SourceSftpBulkInferenceType `default:"None" json:"inference_type"`
	// A set of case-sensitive strings that should be interpreted as null values. For example, if the value 'NA' should be interpreted as null, enter 'NA' in this field.
	NullValues []string `json:"null_values,omitempty"`
	// The character used for quoting CSV values. To disallow quoting, make this field blank.
	QuoteChar *string `default:"\"" json:"quote_char"`
	// The number of rows to skip after the header row.
	SkipRowsAfterHeader *int64 `default:"0" json:"skip_rows_after_header"`
	// The number of rows to skip before the header row. For example, if the header row is on the 3rd row, enter 2 in this field.
	SkipRowsBeforeHeader *int64 `default:"0" json:"skip_rows_before_header"`
	// Whether strings can be interpreted as null values. If true, strings that match the null_values set will be interpreted as null. If false, strings that match the null_values set will be interpreted as the string itself.
	StringsCanBeNull *bool `default:"true" json:"strings_can_be_null"`
	// A set of case-sensitive strings that should be interpreted as true values.
	TrueValues []string `json:"true_values,omitempty"`
}

func (s SourceSftpBulkCSVFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkCSVFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkCSVFormat) GetDelimiter() *string {
	if o == nil {
		return nil
	}
	return o.Delimiter
}

func (o *SourceSftpBulkCSVFormat) GetDoubleQuote() *bool {
	if o == nil {
		return nil
	}
	return o.DoubleQuote
}

func (o *SourceSftpBulkCSVFormat) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *SourceSftpBulkCSVFormat) GetEscapeChar() *string {
	if o == nil {
		return nil
	}
	return o.EscapeChar
}

func (o *SourceSftpBulkCSVFormat) GetFalseValues() []string {
	if o == nil {
		return nil
	}
	return o.FalseValues
}

func (o *SourceSftpBulkCSVFormat) GetFiletype() *SourceSftpBulkSchemasFiletype {
	return SourceSftpBulkSchemasFiletypeCsv.ToPointer()
}

func (o *SourceSftpBulkCSVFormat) GetHeaderDefinition() *SourceSftpBulkCSVHeaderDefinition {
	if o == nil {
		return nil
	}
	return o.HeaderDefinition
}

func (o *SourceSftpBulkCSVFormat) GetIgnoreErrorsOnFieldsMismatch() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreErrorsOnFieldsMismatch
}

func (o *SourceSftpBulkCSVFormat) GetInferenceType() *SourceSftpBulkInferenceType {
	if o == nil {
		return nil
	}
	return o.InferenceType
}

func (o *SourceSftpBulkCSVFormat) GetNullValues() []string {
	if o == nil {
		return nil
	}
	return o.NullValues
}

func (o *SourceSftpBulkCSVFormat) GetQuoteChar() *string {
	if o == nil {
		return nil
	}
	return o.QuoteChar
}

func (o *SourceSftpBulkCSVFormat) GetSkipRowsAfterHeader() *int64 {
	if o == nil {
		return nil
	}
	return o.SkipRowsAfterHeader
}

func (o *SourceSftpBulkCSVFormat) GetSkipRowsBeforeHeader() *int64 {
	if o == nil {
		return nil
	}
	return o.SkipRowsBeforeHeader
}

func (o *SourceSftpBulkCSVFormat) GetStringsCanBeNull() *bool {
	if o == nil {
		return nil
	}
	return o.StringsCanBeNull
}

func (o *SourceSftpBulkCSVFormat) GetTrueValues() []string {
	if o == nil {
		return nil
	}
	return o.TrueValues
}

type SourceSftpBulkFiletype string

const (
	SourceSftpBulkFiletypeAvro SourceSftpBulkFiletype = "avro"
)

func (e SourceSftpBulkFiletype) ToPointer() *SourceSftpBulkFiletype {
	return &e
}
func (e *SourceSftpBulkFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "avro":
		*e = SourceSftpBulkFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkFiletype: %v", v)
	}
}

type SourceSftpBulkAvroFormat struct {
	// Whether to convert double fields to strings. This is recommended if you have decimal numbers with a high degree of precision because there can be a loss precision when handling floating point numbers.
	DoubleAsString *bool                   `default:"false" json:"double_as_string"`
	filetype       *SourceSftpBulkFiletype `const:"avro" json:"filetype"`
}

func (s SourceSftpBulkAvroFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkAvroFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkAvroFormat) GetDoubleAsString() *bool {
	if o == nil {
		return nil
	}
	return o.DoubleAsString
}

func (o *SourceSftpBulkAvroFormat) GetFiletype() *SourceSftpBulkFiletype {
	return SourceSftpBulkFiletypeAvro.ToPointer()
}

type SourceSftpBulkFormatType string

const (
	SourceSftpBulkFormatTypeSourceSftpBulkAvroFormat                 SourceSftpBulkFormatType = "source-sftp-bulk_Avro Format"
	SourceSftpBulkFormatTypeSourceSftpBulkCSVFormat                  SourceSftpBulkFormatType = "source-sftp-bulk_CSV Format"
	SourceSftpBulkFormatTypeSourceSftpBulkJsonlFormat                SourceSftpBulkFormatType = "source-sftp-bulk_Jsonl Format"
	SourceSftpBulkFormatTypeSourceSftpBulkParquetFormat              SourceSftpBulkFormatType = "source-sftp-bulk_Parquet Format"
	SourceSftpBulkFormatTypeSourceSftpBulkUnstructuredDocumentFormat SourceSftpBulkFormatType = "source-sftp-bulk_Unstructured Document Format"
	SourceSftpBulkFormatTypeSourceSftpBulkExcelFormat                SourceSftpBulkFormatType = "source-sftp-bulk_Excel Format"
)

// SourceSftpBulkFormat - The configuration options that are used to alter how to read incoming files that deviate from the standard formatting.
type SourceSftpBulkFormat struct {
	SourceSftpBulkAvroFormat                 *SourceSftpBulkAvroFormat
	SourceSftpBulkCSVFormat                  *SourceSftpBulkCSVFormat
	SourceSftpBulkJsonlFormat                *SourceSftpBulkJsonlFormat
	SourceSftpBulkParquetFormat              *SourceSftpBulkParquetFormat
	SourceSftpBulkUnstructuredDocumentFormat *SourceSftpBulkUnstructuredDocumentFormat
	SourceSftpBulkExcelFormat                *SourceSftpBulkExcelFormat

	Type SourceSftpBulkFormatType
}

func CreateSourceSftpBulkFormatSourceSftpBulkAvroFormat(sourceSftpBulkAvroFormat SourceSftpBulkAvroFormat) SourceSftpBulkFormat {
	typ := SourceSftpBulkFormatTypeSourceSftpBulkAvroFormat

	return SourceSftpBulkFormat{
		SourceSftpBulkAvroFormat: &sourceSftpBulkAvroFormat,
		Type:                     typ,
	}
}

func CreateSourceSftpBulkFormatSourceSftpBulkCSVFormat(sourceSftpBulkCSVFormat SourceSftpBulkCSVFormat) SourceSftpBulkFormat {
	typ := SourceSftpBulkFormatTypeSourceSftpBulkCSVFormat

	return SourceSftpBulkFormat{
		SourceSftpBulkCSVFormat: &sourceSftpBulkCSVFormat,
		Type:                    typ,
	}
}

func CreateSourceSftpBulkFormatSourceSftpBulkJsonlFormat(sourceSftpBulkJsonlFormat SourceSftpBulkJsonlFormat) SourceSftpBulkFormat {
	typ := SourceSftpBulkFormatTypeSourceSftpBulkJsonlFormat

	return SourceSftpBulkFormat{
		SourceSftpBulkJsonlFormat: &sourceSftpBulkJsonlFormat,
		Type:                      typ,
	}
}

func CreateSourceSftpBulkFormatSourceSftpBulkParquetFormat(sourceSftpBulkParquetFormat SourceSftpBulkParquetFormat) SourceSftpBulkFormat {
	typ := SourceSftpBulkFormatTypeSourceSftpBulkParquetFormat

	return SourceSftpBulkFormat{
		SourceSftpBulkParquetFormat: &sourceSftpBulkParquetFormat,
		Type:                        typ,
	}
}

func CreateSourceSftpBulkFormatSourceSftpBulkUnstructuredDocumentFormat(sourceSftpBulkUnstructuredDocumentFormat SourceSftpBulkUnstructuredDocumentFormat) SourceSftpBulkFormat {
	typ := SourceSftpBulkFormatTypeSourceSftpBulkUnstructuredDocumentFormat

	return SourceSftpBulkFormat{
		SourceSftpBulkUnstructuredDocumentFormat: &sourceSftpBulkUnstructuredDocumentFormat,
		Type:                                     typ,
	}
}

func CreateSourceSftpBulkFormatSourceSftpBulkExcelFormat(sourceSftpBulkExcelFormat SourceSftpBulkExcelFormat) SourceSftpBulkFormat {
	typ := SourceSftpBulkFormatTypeSourceSftpBulkExcelFormat

	return SourceSftpBulkFormat{
		SourceSftpBulkExcelFormat: &sourceSftpBulkExcelFormat,
		Type:                      typ,
	}
}

func (u *SourceSftpBulkFormat) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkJsonlFormat SourceSftpBulkJsonlFormat = SourceSftpBulkJsonlFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkJsonlFormat, "", true, true); err == nil {
		u.SourceSftpBulkJsonlFormat = &sourceSftpBulkJsonlFormat
		u.Type = SourceSftpBulkFormatTypeSourceSftpBulkJsonlFormat
		return nil
	}

	var sourceSftpBulkExcelFormat SourceSftpBulkExcelFormat = SourceSftpBulkExcelFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkExcelFormat, "", true, true); err == nil {
		u.SourceSftpBulkExcelFormat = &sourceSftpBulkExcelFormat
		u.Type = SourceSftpBulkFormatTypeSourceSftpBulkExcelFormat
		return nil
	}

	var sourceSftpBulkAvroFormat SourceSftpBulkAvroFormat = SourceSftpBulkAvroFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkAvroFormat, "", true, true); err == nil {
		u.SourceSftpBulkAvroFormat = &sourceSftpBulkAvroFormat
		u.Type = SourceSftpBulkFormatTypeSourceSftpBulkAvroFormat
		return nil
	}

	var sourceSftpBulkParquetFormat SourceSftpBulkParquetFormat = SourceSftpBulkParquetFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkParquetFormat, "", true, true); err == nil {
		u.SourceSftpBulkParquetFormat = &sourceSftpBulkParquetFormat
		u.Type = SourceSftpBulkFormatTypeSourceSftpBulkParquetFormat
		return nil
	}

	var sourceSftpBulkUnstructuredDocumentFormat SourceSftpBulkUnstructuredDocumentFormat = SourceSftpBulkUnstructuredDocumentFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUnstructuredDocumentFormat, "", true, true); err == nil {
		u.SourceSftpBulkUnstructuredDocumentFormat = &sourceSftpBulkUnstructuredDocumentFormat
		u.Type = SourceSftpBulkFormatTypeSourceSftpBulkUnstructuredDocumentFormat
		return nil
	}

	var sourceSftpBulkCSVFormat SourceSftpBulkCSVFormat = SourceSftpBulkCSVFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkCSVFormat, "", true, true); err == nil {
		u.SourceSftpBulkCSVFormat = &sourceSftpBulkCSVFormat
		u.Type = SourceSftpBulkFormatTypeSourceSftpBulkCSVFormat
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkFormat", string(data))
}

func (u SourceSftpBulkFormat) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkAvroFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkAvroFormat, "", true)
	}

	if u.SourceSftpBulkCSVFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkCSVFormat, "", true)
	}

	if u.SourceSftpBulkJsonlFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkJsonlFormat, "", true)
	}

	if u.SourceSftpBulkParquetFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkParquetFormat, "", true)
	}

	if u.SourceSftpBulkUnstructuredDocumentFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUnstructuredDocumentFormat, "", true)
	}

	if u.SourceSftpBulkExcelFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkExcelFormat, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkFormat: all fields are null")
}

// SourceSftpBulkValidationPolicy - The name of the validation policy that dictates sync behavior when a record does not adhere to the stream schema.
type SourceSftpBulkValidationPolicy string

const (
	SourceSftpBulkValidationPolicyEmitRecord      SourceSftpBulkValidationPolicy = "Emit Record"
	SourceSftpBulkValidationPolicySkipRecord      SourceSftpBulkValidationPolicy = "Skip Record"
	SourceSftpBulkValidationPolicyWaitForDiscover SourceSftpBulkValidationPolicy = "Wait for Discover"
)

func (e SourceSftpBulkValidationPolicy) ToPointer() *SourceSftpBulkValidationPolicy {
	return &e
}
func (e *SourceSftpBulkValidationPolicy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Emit Record":
		fallthrough
	case "Skip Record":
		fallthrough
	case "Wait for Discover":
		*e = SourceSftpBulkValidationPolicy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkValidationPolicy: %v", v)
	}
}

type SourceSftpBulkFileBasedStreamConfig struct {
	// When the state history of the file store is full, syncs will only read files that were last modified in the provided day range.
	DaysToSyncIfHistoryIsFull *int64 `default:"3" json:"days_to_sync_if_history_is_full"`
	// The configuration options that are used to alter how to read incoming files that deviate from the standard formatting.
	Format SourceSftpBulkFormat `json:"format"`
	// The pattern used to specify which files should be selected from the file system. For more information on glob pattern matching look <a href="https://en.wikipedia.org/wiki/Glob_(programming)">here</a>.
	Globs []string `json:"globs,omitempty"`
	// The schema that will be used to validate records extracted from the file. This will override the stream schema that is auto-detected from incoming files.
	InputSchema *string `json:"input_schema,omitempty"`
	// The path prefix configured in v3 versions of the S3 connector. This option is deprecated in favor of a single glob.
	LegacyPrefix *string `json:"legacy_prefix,omitempty"`
	// The name of the stream.
	Name string `json:"name"`
	// The column or columns (for a composite key) that serves as the unique identifier of a record. If empty, the primary key will default to the parser's default primary key.
	PrimaryKey *string `json:"primary_key,omitempty"`
	// The number of resent files which will be used to discover the schema for this stream.
	RecentNFilesToReadForSchemaDiscovery *int64 `json:"recent_n_files_to_read_for_schema_discovery,omitempty"`
	// When enabled, syncs will not validate or structure records against the stream's schema.
	Schemaless *bool `default:"false" json:"schemaless"`
	// The name of the validation policy that dictates sync behavior when a record does not adhere to the stream schema.
	ValidationPolicy *SourceSftpBulkValidationPolicy `default:"Emit Record" json:"validation_policy"`
}

func (s SourceSftpBulkFileBasedStreamConfig) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkFileBasedStreamConfig) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetDaysToSyncIfHistoryIsFull() *int64 {
	if o == nil {
		return nil
	}
	return o.DaysToSyncIfHistoryIsFull
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetFormat() SourceSftpBulkFormat {
	if o == nil {
		return SourceSftpBulkFormat{}
	}
	return o.Format
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetGlobs() []string {
	if o == nil {
		return nil
	}
	return o.Globs
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetInputSchema() *string {
	if o == nil {
		return nil
	}
	return o.InputSchema
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetLegacyPrefix() *string {
	if o == nil {
		return nil
	}
	return o.LegacyPrefix
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetPrimaryKey() *string {
	if o == nil {
		return nil
	}
	return o.PrimaryKey
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetRecentNFilesToReadForSchemaDiscovery() *int64 {
	if o == nil {
		return nil
	}
	return o.RecentNFilesToReadForSchemaDiscovery
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetSchemaless() *bool {
	if o == nil {
		return nil
	}
	return o.Schemaless
}

func (o *SourceSftpBulkFileBasedStreamConfig) GetValidationPolicy() *SourceSftpBulkValidationPolicy {
	if o == nil {
		return nil
	}
	return o.ValidationPolicy
}

// SourceSftpBulk - Used during spec; allows the developer to configure the cloud provider specific options
// that are needed when users configure a file-based source.
type SourceSftpBulk struct {
	// Credentials for connecting to the SFTP Server
	Credentials SourceSftpBulkAuthentication `json:"credentials"`
	// The directory to search files for sync
	FolderPath *string `default:"/" json:"folder_path"`
	// The server host address
	Host string `json:"host"`
	// The server port
	Port       *int64   `default:"22" json:"port"`
	sourceType SftpBulk `const:"sftp-bulk" json:"sourceType"`
	// UTC date and time in the format 2017-01-25T00:00:00.000000Z. Any file modified before this date will not be replicated.
	StartDate *time.Time `json:"start_date,omitempty"`
	// Each instance of this configuration defines a <a href="https://docs.airbyte.com/cloud/core-concepts#stream">stream</a>. Use this to define which files belong in the stream, their format, and how they should be parsed and validated. When sending data to warehouse destination such as Snowflake or BigQuery, each stream is a separate table.
	Streams []SourceSftpBulkFileBasedStreamConfig `json:"streams"`
	// The server user
	Username string `json:"username"`
}

func (s SourceSftpBulk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulk) GetCredentials() SourceSftpBulkAuthentication {
	if o == nil {
		return SourceSftpBulkAuthentication{}
	}
	return o.Credentials
}

func (o *SourceSftpBulk) GetFolderPath() *string {
	if o == nil {
		return nil
	}
	return o.FolderPath
}

func (o *SourceSftpBulk) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *SourceSftpBulk) GetPort() *int64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *SourceSftpBulk) GetSourceType() SftpBulk {
	return SftpBulkSftpBulk
}

func (o *SourceSftpBulk) GetStartDate() *time.Time {
	if o == nil {
		return nil
	}
	return o.StartDate
}

func (o *SourceSftpBulk) GetStreams() []SourceSftpBulkFileBasedStreamConfig {
	if o == nil {
		return []SourceSftpBulkFileBasedStreamConfig{}
	}
	return o.Streams
}

func (o *SourceSftpBulk) GetUsername() string {
	if o == nil {
		return ""
	}
	return o.Username
}
