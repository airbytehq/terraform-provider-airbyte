// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/internal/utils"
	"time"
)

// SourceSftpBulkUpdateValidationPolicy - The name of the validation policy that dictates sync behavior when a record does not adhere to the stream schema.
type SourceSftpBulkUpdateValidationPolicy string

const (
	SourceSftpBulkUpdateValidationPolicyEmitRecord      SourceSftpBulkUpdateValidationPolicy = "Emit Record"
	SourceSftpBulkUpdateValidationPolicySkipRecord      SourceSftpBulkUpdateValidationPolicy = "Skip Record"
	SourceSftpBulkUpdateValidationPolicyWaitForDiscover SourceSftpBulkUpdateValidationPolicy = "Wait for Discover"
)

func (e SourceSftpBulkUpdateValidationPolicy) ToPointer() *SourceSftpBulkUpdateValidationPolicy {
	return &e
}
func (e *SourceSftpBulkUpdateValidationPolicy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Emit Record":
		fallthrough
	case "Skip Record":
		fallthrough
	case "Wait for Discover":
		*e = SourceSftpBulkUpdateValidationPolicy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateValidationPolicy: %v", v)
	}
}

type SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype string

const (
	SourceSftpBulkUpdateSchemasStreamsFormatFormat6FiletypeExcel SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype = "excel"
)

func (e SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype) ToPointer() *SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "excel":
		*e = SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype: %v", v)
	}
}

type SourceSftpBulkUpdateExcelFormat struct {
	filetype *SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype `const:"excel" json:"filetype"`
}

func (s SourceSftpBulkUpdateExcelFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateExcelFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateExcelFormat) GetFiletype() *SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype {
	return SourceSftpBulkUpdateSchemasStreamsFormatFormat6FiletypeExcel.ToPointer()
}

type SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype string

const (
	SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletypeUnstructured SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype = "unstructured"
)

func (e SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype) ToPointer() *SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "unstructured":
		*e = SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype: %v", v)
	}
}

// SourceSftpBulkUpdateParsingStrategy - The strategy used to parse documents. `fast` extracts text directly from the document which doesn't work for all files. `ocr_only` is more reliable, but slower. `hi_res` is the most reliable, but requires an API key and a hosted instance of unstructured and can't be used with local mode. See the unstructured.io documentation for more details: https://unstructured-io.github.io/unstructured/core/partition.html#partition-pdf
type SourceSftpBulkUpdateParsingStrategy string

const (
	SourceSftpBulkUpdateParsingStrategyAuto    SourceSftpBulkUpdateParsingStrategy = "auto"
	SourceSftpBulkUpdateParsingStrategyFast    SourceSftpBulkUpdateParsingStrategy = "fast"
	SourceSftpBulkUpdateParsingStrategyOcrOnly SourceSftpBulkUpdateParsingStrategy = "ocr_only"
	SourceSftpBulkUpdateParsingStrategyHiRes   SourceSftpBulkUpdateParsingStrategy = "hi_res"
)

func (e SourceSftpBulkUpdateParsingStrategy) ToPointer() *SourceSftpBulkUpdateParsingStrategy {
	return &e
}
func (e *SourceSftpBulkUpdateParsingStrategy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "fast":
		fallthrough
	case "ocr_only":
		fallthrough
	case "hi_res":
		*e = SourceSftpBulkUpdateParsingStrategy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateParsingStrategy: %v", v)
	}
}

type SourceSftpBulkUpdateSchemasMode string

const (
	SourceSftpBulkUpdateSchemasModeAPI SourceSftpBulkUpdateSchemasMode = "api"
)

func (e SourceSftpBulkUpdateSchemasMode) ToPointer() *SourceSftpBulkUpdateSchemasMode {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "api":
		*e = SourceSftpBulkUpdateSchemasMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasMode: %v", v)
	}
}

type SourceSftpBulkUpdateAPIParameterConfigModel struct {
	// The name of the unstructured API parameter to use
	Name string `json:"name"`
	// The value of the parameter
	Value string `json:"value"`
}

func (o *SourceSftpBulkUpdateAPIParameterConfigModel) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SourceSftpBulkUpdateAPIParameterConfigModel) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// SourceSftpBulkUpdateViaAPI - Process files via an API, using the `hi_res` mode. This option is useful for increased performance and accuracy, but requires an API key and a hosted instance of unstructured.
type SourceSftpBulkUpdateViaAPI struct {
	mode *SourceSftpBulkUpdateSchemasMode `const:"api" json:"mode"`
	// The API key to use matching the environment
	APIKey *string `default:"" json:"api_key"`
	// The URL of the unstructured API to use
	APIURL *string `default:"https://api.unstructured.io" json:"api_url"`
	// List of parameters send to the API
	Parameters []SourceSftpBulkUpdateAPIParameterConfigModel `json:"parameters,omitempty"`
}

func (s SourceSftpBulkUpdateViaAPI) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateViaAPI) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateViaAPI) GetMode() *SourceSftpBulkUpdateSchemasMode {
	return SourceSftpBulkUpdateSchemasModeAPI.ToPointer()
}

func (o *SourceSftpBulkUpdateViaAPI) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *SourceSftpBulkUpdateViaAPI) GetAPIURL() *string {
	if o == nil {
		return nil
	}
	return o.APIURL
}

func (o *SourceSftpBulkUpdateViaAPI) GetParameters() []SourceSftpBulkUpdateAPIParameterConfigModel {
	if o == nil {
		return nil
	}
	return o.Parameters
}

type SourceSftpBulkUpdateMode string

const (
	SourceSftpBulkUpdateModeLocal SourceSftpBulkUpdateMode = "local"
)

func (e SourceSftpBulkUpdateMode) ToPointer() *SourceSftpBulkUpdateMode {
	return &e
}
func (e *SourceSftpBulkUpdateMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "local":
		*e = SourceSftpBulkUpdateMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateMode: %v", v)
	}
}

// SourceSftpBulkUpdateLocal - Process files locally, supporting `fast` and `ocr` modes. This is the default option.
type SourceSftpBulkUpdateLocal struct {
	mode *SourceSftpBulkUpdateMode `const:"local" json:"mode"`
}

func (s SourceSftpBulkUpdateLocal) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateLocal) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateLocal) GetMode() *SourceSftpBulkUpdateMode {
	return SourceSftpBulkUpdateModeLocal.ToPointer()
}

type SourceSftpBulkUpdateProcessingType string

const (
	SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateLocal  SourceSftpBulkUpdateProcessingType = "source-sftp-bulk-update_Local"
	SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateViaAPI SourceSftpBulkUpdateProcessingType = "source-sftp-bulk-update_via API"
)

// SourceSftpBulkUpdateProcessing - Processing configuration
type SourceSftpBulkUpdateProcessing struct {
	SourceSftpBulkUpdateLocal  *SourceSftpBulkUpdateLocal  `queryParam:"inline"`
	SourceSftpBulkUpdateViaAPI *SourceSftpBulkUpdateViaAPI `queryParam:"inline"`

	Type SourceSftpBulkUpdateProcessingType
}

func CreateSourceSftpBulkUpdateProcessingSourceSftpBulkUpdateLocal(sourceSftpBulkUpdateLocal SourceSftpBulkUpdateLocal) SourceSftpBulkUpdateProcessing {
	typ := SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateLocal

	return SourceSftpBulkUpdateProcessing{
		SourceSftpBulkUpdateLocal: &sourceSftpBulkUpdateLocal,
		Type:                      typ,
	}
}

func CreateSourceSftpBulkUpdateProcessingSourceSftpBulkUpdateViaAPI(sourceSftpBulkUpdateViaAPI SourceSftpBulkUpdateViaAPI) SourceSftpBulkUpdateProcessing {
	typ := SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateViaAPI

	return SourceSftpBulkUpdateProcessing{
		SourceSftpBulkUpdateViaAPI: &sourceSftpBulkUpdateViaAPI,
		Type:                       typ,
	}
}

func (u *SourceSftpBulkUpdateProcessing) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkUpdateLocal SourceSftpBulkUpdateLocal = SourceSftpBulkUpdateLocal{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateLocal, "", true, true); err == nil {
		u.SourceSftpBulkUpdateLocal = &sourceSftpBulkUpdateLocal
		u.Type = SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateLocal
		return nil
	}

	var sourceSftpBulkUpdateViaAPI SourceSftpBulkUpdateViaAPI = SourceSftpBulkUpdateViaAPI{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateViaAPI, "", true, true); err == nil {
		u.SourceSftpBulkUpdateViaAPI = &sourceSftpBulkUpdateViaAPI
		u.Type = SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateViaAPI
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkUpdateProcessing", string(data))
}

func (u SourceSftpBulkUpdateProcessing) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkUpdateLocal != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateLocal, "", true)
	}

	if u.SourceSftpBulkUpdateViaAPI != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateViaAPI, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkUpdateProcessing: all fields are null")
}

// SourceSftpBulkUpdateUnstructuredDocumentFormat - Extract text from document formats (.pdf, .docx, .md, .pptx) and emit as one record per file.
type SourceSftpBulkUpdateUnstructuredDocumentFormat struct {
	filetype *SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype `const:"unstructured" json:"filetype"`
	// If true, skip files that cannot be parsed and pass the error message along as the _ab_source_file_parse_error field. If false, fail the sync.
	SkipUnprocessableFiles *bool `default:"true" json:"skip_unprocessable_files"`
	// The strategy used to parse documents. `fast` extracts text directly from the document which doesn't work for all files. `ocr_only` is more reliable, but slower. `hi_res` is the most reliable, but requires an API key and a hosted instance of unstructured and can't be used with local mode. See the unstructured.io documentation for more details: https://unstructured-io.github.io/unstructured/core/partition.html#partition-pdf
	Strategy *SourceSftpBulkUpdateParsingStrategy `default:"auto" json:"strategy"`
	// Processing configuration
	Processing *SourceSftpBulkUpdateProcessing `json:"processing,omitempty"`
}

func (s SourceSftpBulkUpdateUnstructuredDocumentFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateUnstructuredDocumentFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateUnstructuredDocumentFormat) GetFiletype() *SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype {
	return SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletypeUnstructured.ToPointer()
}

func (o *SourceSftpBulkUpdateUnstructuredDocumentFormat) GetSkipUnprocessableFiles() *bool {
	if o == nil {
		return nil
	}
	return o.SkipUnprocessableFiles
}

func (o *SourceSftpBulkUpdateUnstructuredDocumentFormat) GetStrategy() *SourceSftpBulkUpdateParsingStrategy {
	if o == nil {
		return nil
	}
	return o.Strategy
}

func (o *SourceSftpBulkUpdateUnstructuredDocumentFormat) GetProcessing() *SourceSftpBulkUpdateProcessing {
	if o == nil {
		return nil
	}
	return o.Processing
}

type SourceSftpBulkUpdateSchemasStreamsFormatFiletype string

const (
	SourceSftpBulkUpdateSchemasStreamsFormatFiletypeParquet SourceSftpBulkUpdateSchemasStreamsFormatFiletype = "parquet"
)

func (e SourceSftpBulkUpdateSchemasStreamsFormatFiletype) ToPointer() *SourceSftpBulkUpdateSchemasStreamsFormatFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsFormatFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "parquet":
		*e = SourceSftpBulkUpdateSchemasStreamsFormatFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsFormatFiletype: %v", v)
	}
}

type SourceSftpBulkUpdateParquetFormat struct {
	filetype *SourceSftpBulkUpdateSchemasStreamsFormatFiletype `const:"parquet" json:"filetype"`
	// Whether to convert decimal fields to floats. There is a loss of precision when converting decimals to floats, so this is not recommended.
	DecimalAsFloat *bool `default:"false" json:"decimal_as_float"`
}

func (s SourceSftpBulkUpdateParquetFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateParquetFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateParquetFormat) GetFiletype() *SourceSftpBulkUpdateSchemasStreamsFormatFiletype {
	return SourceSftpBulkUpdateSchemasStreamsFormatFiletypeParquet.ToPointer()
}

func (o *SourceSftpBulkUpdateParquetFormat) GetDecimalAsFloat() *bool {
	if o == nil {
		return nil
	}
	return o.DecimalAsFloat
}

type SourceSftpBulkUpdateSchemasStreamsFiletype string

const (
	SourceSftpBulkUpdateSchemasStreamsFiletypeJsonl SourceSftpBulkUpdateSchemasStreamsFiletype = "jsonl"
)

func (e SourceSftpBulkUpdateSchemasStreamsFiletype) ToPointer() *SourceSftpBulkUpdateSchemasStreamsFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "jsonl":
		*e = SourceSftpBulkUpdateSchemasStreamsFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsFiletype: %v", v)
	}
}

type SourceSftpBulkUpdateJsonlFormat struct {
	filetype *SourceSftpBulkUpdateSchemasStreamsFiletype `const:"jsonl" json:"filetype"`
}

func (s SourceSftpBulkUpdateJsonlFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateJsonlFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateJsonlFormat) GetFiletype() *SourceSftpBulkUpdateSchemasStreamsFiletype {
	return SourceSftpBulkUpdateSchemasStreamsFiletypeJsonl.ToPointer()
}

type SourceSftpBulkUpdateSchemasFiletype string

const (
	SourceSftpBulkUpdateSchemasFiletypeCsv SourceSftpBulkUpdateSchemasFiletype = "csv"
)

func (e SourceSftpBulkUpdateSchemasFiletype) ToPointer() *SourceSftpBulkUpdateSchemasFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "csv":
		*e = SourceSftpBulkUpdateSchemasFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasFiletype: %v", v)
	}
}

type SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType string

const (
	SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionTypeUserProvided SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType = "User Provided"
)

func (e SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType) ToPointer() *SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "User Provided":
		*e = SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType: %v", v)
	}
}

type SourceSftpBulkUpdateUserProvided struct {
	headerDefinitionType *SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType `const:"User Provided" json:"header_definition_type"`
	// The column names that will be used while emitting the CSV records
	ColumnNames []string `json:"column_names"`
}

func (s SourceSftpBulkUpdateUserProvided) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateUserProvided) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateUserProvided) GetHeaderDefinitionType() *SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType {
	return SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionTypeUserProvided.ToPointer()
}

func (o *SourceSftpBulkUpdateUserProvided) GetColumnNames() []string {
	if o == nil {
		return []string{}
	}
	return o.ColumnNames
}

type SourceSftpBulkUpdateSchemasHeaderDefinitionType string

const (
	SourceSftpBulkUpdateSchemasHeaderDefinitionTypeAutogenerated SourceSftpBulkUpdateSchemasHeaderDefinitionType = "Autogenerated"
)

func (e SourceSftpBulkUpdateSchemasHeaderDefinitionType) ToPointer() *SourceSftpBulkUpdateSchemasHeaderDefinitionType {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasHeaderDefinitionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Autogenerated":
		*e = SourceSftpBulkUpdateSchemasHeaderDefinitionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasHeaderDefinitionType: %v", v)
	}
}

type SourceSftpBulkUpdateAutogenerated struct {
	headerDefinitionType *SourceSftpBulkUpdateSchemasHeaderDefinitionType `const:"Autogenerated" json:"header_definition_type"`
}

func (s SourceSftpBulkUpdateAutogenerated) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateAutogenerated) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateAutogenerated) GetHeaderDefinitionType() *SourceSftpBulkUpdateSchemasHeaderDefinitionType {
	return SourceSftpBulkUpdateSchemasHeaderDefinitionTypeAutogenerated.ToPointer()
}

type SourceSftpBulkUpdateHeaderDefinitionType string

const (
	SourceSftpBulkUpdateHeaderDefinitionTypeFromCsv SourceSftpBulkUpdateHeaderDefinitionType = "From CSV"
)

func (e SourceSftpBulkUpdateHeaderDefinitionType) ToPointer() *SourceSftpBulkUpdateHeaderDefinitionType {
	return &e
}
func (e *SourceSftpBulkUpdateHeaderDefinitionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "From CSV":
		*e = SourceSftpBulkUpdateHeaderDefinitionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateHeaderDefinitionType: %v", v)
	}
}

type SourceSftpBulkUpdateFromCSV struct {
	headerDefinitionType *SourceSftpBulkUpdateHeaderDefinitionType `const:"From CSV" json:"header_definition_type"`
}

func (s SourceSftpBulkUpdateFromCSV) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateFromCSV) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateFromCSV) GetHeaderDefinitionType() *SourceSftpBulkUpdateHeaderDefinitionType {
	return SourceSftpBulkUpdateHeaderDefinitionTypeFromCsv.ToPointer()
}

type SourceSftpBulkUpdateCSVHeaderDefinitionType string

const (
	SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateFromCSV       SourceSftpBulkUpdateCSVHeaderDefinitionType = "source-sftp-bulk-update_From CSV"
	SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateAutogenerated SourceSftpBulkUpdateCSVHeaderDefinitionType = "source-sftp-bulk-update_Autogenerated"
	SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateUserProvided  SourceSftpBulkUpdateCSVHeaderDefinitionType = "source-sftp-bulk-update_User Provided"
)

// SourceSftpBulkUpdateCSVHeaderDefinition - How headers will be defined. `User Provided` assumes the CSV does not have a header row and uses the headers provided and `Autogenerated` assumes the CSV does not have a header row and the CDK will generate headers using for `f{i}` where `i` is the index starting from 0. Else, the default behavior is to use the header from the CSV file. If a user wants to autogenerate or provide column names for a CSV having headers, they can skip rows.
type SourceSftpBulkUpdateCSVHeaderDefinition struct {
	SourceSftpBulkUpdateFromCSV       *SourceSftpBulkUpdateFromCSV       `queryParam:"inline"`
	SourceSftpBulkUpdateAutogenerated *SourceSftpBulkUpdateAutogenerated `queryParam:"inline"`
	SourceSftpBulkUpdateUserProvided  *SourceSftpBulkUpdateUserProvided  `queryParam:"inline"`

	Type SourceSftpBulkUpdateCSVHeaderDefinitionType
}

func CreateSourceSftpBulkUpdateCSVHeaderDefinitionSourceSftpBulkUpdateFromCSV(sourceSftpBulkUpdateFromCSV SourceSftpBulkUpdateFromCSV) SourceSftpBulkUpdateCSVHeaderDefinition {
	typ := SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateFromCSV

	return SourceSftpBulkUpdateCSVHeaderDefinition{
		SourceSftpBulkUpdateFromCSV: &sourceSftpBulkUpdateFromCSV,
		Type:                        typ,
	}
}

func CreateSourceSftpBulkUpdateCSVHeaderDefinitionSourceSftpBulkUpdateAutogenerated(sourceSftpBulkUpdateAutogenerated SourceSftpBulkUpdateAutogenerated) SourceSftpBulkUpdateCSVHeaderDefinition {
	typ := SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateAutogenerated

	return SourceSftpBulkUpdateCSVHeaderDefinition{
		SourceSftpBulkUpdateAutogenerated: &sourceSftpBulkUpdateAutogenerated,
		Type:                              typ,
	}
}

func CreateSourceSftpBulkUpdateCSVHeaderDefinitionSourceSftpBulkUpdateUserProvided(sourceSftpBulkUpdateUserProvided SourceSftpBulkUpdateUserProvided) SourceSftpBulkUpdateCSVHeaderDefinition {
	typ := SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateUserProvided

	return SourceSftpBulkUpdateCSVHeaderDefinition{
		SourceSftpBulkUpdateUserProvided: &sourceSftpBulkUpdateUserProvided,
		Type:                             typ,
	}
}

func (u *SourceSftpBulkUpdateCSVHeaderDefinition) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkUpdateFromCSV SourceSftpBulkUpdateFromCSV = SourceSftpBulkUpdateFromCSV{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateFromCSV, "", true, true); err == nil {
		u.SourceSftpBulkUpdateFromCSV = &sourceSftpBulkUpdateFromCSV
		u.Type = SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateFromCSV
		return nil
	}

	var sourceSftpBulkUpdateAutogenerated SourceSftpBulkUpdateAutogenerated = SourceSftpBulkUpdateAutogenerated{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateAutogenerated, "", true, true); err == nil {
		u.SourceSftpBulkUpdateAutogenerated = &sourceSftpBulkUpdateAutogenerated
		u.Type = SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateAutogenerated
		return nil
	}

	var sourceSftpBulkUpdateUserProvided SourceSftpBulkUpdateUserProvided = SourceSftpBulkUpdateUserProvided{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateUserProvided, "", true, true); err == nil {
		u.SourceSftpBulkUpdateUserProvided = &sourceSftpBulkUpdateUserProvided
		u.Type = SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateUserProvided
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkUpdateCSVHeaderDefinition", string(data))
}

func (u SourceSftpBulkUpdateCSVHeaderDefinition) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkUpdateFromCSV != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateFromCSV, "", true)
	}

	if u.SourceSftpBulkUpdateAutogenerated != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateAutogenerated, "", true)
	}

	if u.SourceSftpBulkUpdateUserProvided != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateUserProvided, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkUpdateCSVHeaderDefinition: all fields are null")
}

type SourceSftpBulkUpdateCSVFormat struct {
	filetype *SourceSftpBulkUpdateSchemasFiletype `const:"csv" json:"filetype"`
	// The character delimiting individual cells in the CSV data. This may only be a 1-character string. For tab-delimited data enter '\t'.
	Delimiter *string `default:"," json:"delimiter"`
	// The character used for quoting CSV values. To disallow quoting, make this field blank.
	QuoteChar *string `default:"\"" json:"quote_char"`
	// The character used for escaping special characters. To disallow escaping, leave this field blank.
	EscapeChar *string `json:"escape_char,omitempty"`
	// The character encoding of the CSV data. Leave blank to default to <strong>UTF8</strong>. See <a href="https://docs.python.org/3/library/codecs.html#standard-encodings" target="_blank">list of python encodings</a> for allowable options.
	Encoding *string `default:"utf8" json:"encoding"`
	// Whether two quotes in a quoted CSV value denote a single quote in the data.
	DoubleQuote *bool `default:"true" json:"double_quote"`
	// A set of case-sensitive strings that should be interpreted as null values. For example, if the value 'NA' should be interpreted as null, enter 'NA' in this field.
	NullValues []string `json:"null_values,omitempty"`
	// Whether strings can be interpreted as null values. If true, strings that match the null_values set will be interpreted as null. If false, strings that match the null_values set will be interpreted as the string itself.
	StringsCanBeNull *bool `default:"true" json:"strings_can_be_null"`
	// The number of rows to skip before the header row. For example, if the header row is on the 3rd row, enter 2 in this field.
	SkipRowsBeforeHeader *int64 `default:"0" json:"skip_rows_before_header"`
	// The number of rows to skip after the header row.
	SkipRowsAfterHeader *int64 `default:"0" json:"skip_rows_after_header"`
	// How headers will be defined. `User Provided` assumes the CSV does not have a header row and uses the headers provided and `Autogenerated` assumes the CSV does not have a header row and the CDK will generate headers using for `f{i}` where `i` is the index starting from 0. Else, the default behavior is to use the header from the CSV file. If a user wants to autogenerate or provide column names for a CSV having headers, they can skip rows.
	HeaderDefinition *SourceSftpBulkUpdateCSVHeaderDefinition `json:"header_definition,omitempty"`
	// A set of case-sensitive strings that should be interpreted as true values.
	TrueValues []string `json:"true_values,omitempty"`
	// A set of case-sensitive strings that should be interpreted as false values.
	FalseValues []string `json:"false_values,omitempty"`
	// Whether to ignore errors that occur when the number of fields in the CSV does not match the number of columns in the schema.
	IgnoreErrorsOnFieldsMismatch *bool `default:"false" json:"ignore_errors_on_fields_mismatch"`
}

func (s SourceSftpBulkUpdateCSVFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateCSVFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateCSVFormat) GetFiletype() *SourceSftpBulkUpdateSchemasFiletype {
	return SourceSftpBulkUpdateSchemasFiletypeCsv.ToPointer()
}

func (o *SourceSftpBulkUpdateCSVFormat) GetDelimiter() *string {
	if o == nil {
		return nil
	}
	return o.Delimiter
}

func (o *SourceSftpBulkUpdateCSVFormat) GetQuoteChar() *string {
	if o == nil {
		return nil
	}
	return o.QuoteChar
}

func (o *SourceSftpBulkUpdateCSVFormat) GetEscapeChar() *string {
	if o == nil {
		return nil
	}
	return o.EscapeChar
}

func (o *SourceSftpBulkUpdateCSVFormat) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *SourceSftpBulkUpdateCSVFormat) GetDoubleQuote() *bool {
	if o == nil {
		return nil
	}
	return o.DoubleQuote
}

func (o *SourceSftpBulkUpdateCSVFormat) GetNullValues() []string {
	if o == nil {
		return nil
	}
	return o.NullValues
}

func (o *SourceSftpBulkUpdateCSVFormat) GetStringsCanBeNull() *bool {
	if o == nil {
		return nil
	}
	return o.StringsCanBeNull
}

func (o *SourceSftpBulkUpdateCSVFormat) GetSkipRowsBeforeHeader() *int64 {
	if o == nil {
		return nil
	}
	return o.SkipRowsBeforeHeader
}

func (o *SourceSftpBulkUpdateCSVFormat) GetSkipRowsAfterHeader() *int64 {
	if o == nil {
		return nil
	}
	return o.SkipRowsAfterHeader
}

func (o *SourceSftpBulkUpdateCSVFormat) GetHeaderDefinition() *SourceSftpBulkUpdateCSVHeaderDefinition {
	if o == nil {
		return nil
	}
	return o.HeaderDefinition
}

func (o *SourceSftpBulkUpdateCSVFormat) GetTrueValues() []string {
	if o == nil {
		return nil
	}
	return o.TrueValues
}

func (o *SourceSftpBulkUpdateCSVFormat) GetFalseValues() []string {
	if o == nil {
		return nil
	}
	return o.FalseValues
}

func (o *SourceSftpBulkUpdateCSVFormat) GetIgnoreErrorsOnFieldsMismatch() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreErrorsOnFieldsMismatch
}

type SourceSftpBulkUpdateFiletype string

const (
	SourceSftpBulkUpdateFiletypeAvro SourceSftpBulkUpdateFiletype = "avro"
)

func (e SourceSftpBulkUpdateFiletype) ToPointer() *SourceSftpBulkUpdateFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "avro":
		*e = SourceSftpBulkUpdateFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateFiletype: %v", v)
	}
}

type SourceSftpBulkUpdateAvroFormat struct {
	filetype *SourceSftpBulkUpdateFiletype `const:"avro" json:"filetype"`
	// Whether to convert double fields to strings. This is recommended if you have decimal numbers with a high degree of precision because there can be a loss precision when handling floating point numbers.
	DoubleAsString *bool `default:"false" json:"double_as_string"`
}

func (s SourceSftpBulkUpdateAvroFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateAvroFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateAvroFormat) GetFiletype() *SourceSftpBulkUpdateFiletype {
	return SourceSftpBulkUpdateFiletypeAvro.ToPointer()
}

func (o *SourceSftpBulkUpdateAvroFormat) GetDoubleAsString() *bool {
	if o == nil {
		return nil
	}
	return o.DoubleAsString
}

type SourceSftpBulkUpdateFormatType string

const (
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateAvroFormat                 SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Avro Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateCSVFormat                  SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_CSV Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateJsonlFormat                SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Jsonl Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateParquetFormat              SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Parquet Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateUnstructuredDocumentFormat SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Unstructured Document Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateExcelFormat                SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Excel Format"
)

// SourceSftpBulkUpdateFormat - The configuration options that are used to alter how to read incoming files that deviate from the standard formatting.
type SourceSftpBulkUpdateFormat struct {
	SourceSftpBulkUpdateAvroFormat                 *SourceSftpBulkUpdateAvroFormat                 `queryParam:"inline"`
	SourceSftpBulkUpdateCSVFormat                  *SourceSftpBulkUpdateCSVFormat                  `queryParam:"inline"`
	SourceSftpBulkUpdateJsonlFormat                *SourceSftpBulkUpdateJsonlFormat                `queryParam:"inline"`
	SourceSftpBulkUpdateParquetFormat              *SourceSftpBulkUpdateParquetFormat              `queryParam:"inline"`
	SourceSftpBulkUpdateUnstructuredDocumentFormat *SourceSftpBulkUpdateUnstructuredDocumentFormat `queryParam:"inline"`
	SourceSftpBulkUpdateExcelFormat                *SourceSftpBulkUpdateExcelFormat                `queryParam:"inline"`

	Type SourceSftpBulkUpdateFormatType
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateAvroFormat(sourceSftpBulkUpdateAvroFormat SourceSftpBulkUpdateAvroFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateAvroFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateAvroFormat: &sourceSftpBulkUpdateAvroFormat,
		Type:                           typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateCSVFormat(sourceSftpBulkUpdateCSVFormat SourceSftpBulkUpdateCSVFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateCSVFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateCSVFormat: &sourceSftpBulkUpdateCSVFormat,
		Type:                          typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateJsonlFormat(sourceSftpBulkUpdateJsonlFormat SourceSftpBulkUpdateJsonlFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateJsonlFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateJsonlFormat: &sourceSftpBulkUpdateJsonlFormat,
		Type:                            typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateParquetFormat(sourceSftpBulkUpdateParquetFormat SourceSftpBulkUpdateParquetFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateParquetFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateParquetFormat: &sourceSftpBulkUpdateParquetFormat,
		Type:                              typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateUnstructuredDocumentFormat(sourceSftpBulkUpdateUnstructuredDocumentFormat SourceSftpBulkUpdateUnstructuredDocumentFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateUnstructuredDocumentFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateUnstructuredDocumentFormat: &sourceSftpBulkUpdateUnstructuredDocumentFormat,
		Type: typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateExcelFormat(sourceSftpBulkUpdateExcelFormat SourceSftpBulkUpdateExcelFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateExcelFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateExcelFormat: &sourceSftpBulkUpdateExcelFormat,
		Type:                            typ,
	}
}

func (u *SourceSftpBulkUpdateFormat) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkUpdateJsonlFormat SourceSftpBulkUpdateJsonlFormat = SourceSftpBulkUpdateJsonlFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateJsonlFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateJsonlFormat = &sourceSftpBulkUpdateJsonlFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateJsonlFormat
		return nil
	}

	var sourceSftpBulkUpdateExcelFormat SourceSftpBulkUpdateExcelFormat = SourceSftpBulkUpdateExcelFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateExcelFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateExcelFormat = &sourceSftpBulkUpdateExcelFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateExcelFormat
		return nil
	}

	var sourceSftpBulkUpdateAvroFormat SourceSftpBulkUpdateAvroFormat = SourceSftpBulkUpdateAvroFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateAvroFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateAvroFormat = &sourceSftpBulkUpdateAvroFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateAvroFormat
		return nil
	}

	var sourceSftpBulkUpdateParquetFormat SourceSftpBulkUpdateParquetFormat = SourceSftpBulkUpdateParquetFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateParquetFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateParquetFormat = &sourceSftpBulkUpdateParquetFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateParquetFormat
		return nil
	}

	var sourceSftpBulkUpdateUnstructuredDocumentFormat SourceSftpBulkUpdateUnstructuredDocumentFormat = SourceSftpBulkUpdateUnstructuredDocumentFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateUnstructuredDocumentFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateUnstructuredDocumentFormat = &sourceSftpBulkUpdateUnstructuredDocumentFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateUnstructuredDocumentFormat
		return nil
	}

	var sourceSftpBulkUpdateCSVFormat SourceSftpBulkUpdateCSVFormat = SourceSftpBulkUpdateCSVFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateCSVFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateCSVFormat = &sourceSftpBulkUpdateCSVFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateCSVFormat
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkUpdateFormat", string(data))
}

func (u SourceSftpBulkUpdateFormat) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkUpdateAvroFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateAvroFormat, "", true)
	}

	if u.SourceSftpBulkUpdateCSVFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateCSVFormat, "", true)
	}

	if u.SourceSftpBulkUpdateJsonlFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateJsonlFormat, "", true)
	}

	if u.SourceSftpBulkUpdateParquetFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateParquetFormat, "", true)
	}

	if u.SourceSftpBulkUpdateUnstructuredDocumentFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateUnstructuredDocumentFormat, "", true)
	}

	if u.SourceSftpBulkUpdateExcelFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateExcelFormat, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkUpdateFormat: all fields are null")
}

type SourceSftpBulkUpdateFileBasedStreamConfig struct {
	// The name of the stream.
	Name string `json:"name"`
	// The pattern used to specify which files should be selected from the file system. For more information on glob pattern matching look <a href="https://en.wikipedia.org/wiki/Glob_(programming)">here</a>.
	Globs []string `json:"globs,omitempty"`
	// The name of the validation policy that dictates sync behavior when a record does not adhere to the stream schema.
	ValidationPolicy *SourceSftpBulkUpdateValidationPolicy `default:"Emit Record" json:"validation_policy"`
	// The schema that will be used to validate records extracted from the file. This will override the stream schema that is auto-detected from incoming files.
	InputSchema *string `json:"input_schema,omitempty"`
	// When the state history of the file store is full, syncs will only read files that were last modified in the provided day range.
	DaysToSyncIfHistoryIsFull *int64 `default:"3" json:"days_to_sync_if_history_is_full"`
	// The configuration options that are used to alter how to read incoming files that deviate from the standard formatting.
	Format SourceSftpBulkUpdateFormat `json:"format"`
	// When enabled, syncs will not validate or structure records against the stream's schema.
	Schemaless *bool `default:"false" json:"schemaless"`
	// The number of resent files which will be used to discover the schema for this stream.
	RecentNFilesToReadForSchemaDiscovery *int64 `json:"recent_n_files_to_read_for_schema_discovery,omitempty"`
}

func (s SourceSftpBulkUpdateFileBasedStreamConfig) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateFileBasedStreamConfig) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetGlobs() []string {
	if o == nil {
		return nil
	}
	return o.Globs
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetValidationPolicy() *SourceSftpBulkUpdateValidationPolicy {
	if o == nil {
		return nil
	}
	return o.ValidationPolicy
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetInputSchema() *string {
	if o == nil {
		return nil
	}
	return o.InputSchema
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetDaysToSyncIfHistoryIsFull() *int64 {
	if o == nil {
		return nil
	}
	return o.DaysToSyncIfHistoryIsFull
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetFormat() SourceSftpBulkUpdateFormat {
	if o == nil {
		return SourceSftpBulkUpdateFormat{}
	}
	return o.Format
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetSchemaless() *bool {
	if o == nil {
		return nil
	}
	return o.Schemaless
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetRecentNFilesToReadForSchemaDiscovery() *int64 {
	if o == nil {
		return nil
	}
	return o.RecentNFilesToReadForSchemaDiscovery
}

type SourceSftpBulkUpdateSchemasDeliveryType string

const (
	SourceSftpBulkUpdateSchemasDeliveryTypeUseFileTransfer SourceSftpBulkUpdateSchemasDeliveryType = "use_file_transfer"
)

func (e SourceSftpBulkUpdateSchemasDeliveryType) ToPointer() *SourceSftpBulkUpdateSchemasDeliveryType {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasDeliveryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "use_file_transfer":
		*e = SourceSftpBulkUpdateSchemasDeliveryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasDeliveryType: %v", v)
	}
}

// SourceSftpBulkUpdateCopyRawFiles - Copy raw files without parsing their contents. Bits are copied into the destination exactly as they appeared in the source. Recommended for use with unstructured text data, non-text and compressed files.
type SourceSftpBulkUpdateCopyRawFiles struct {
	deliveryType *SourceSftpBulkUpdateSchemasDeliveryType `const:"use_file_transfer" json:"delivery_type"`
	// If enabled, sends subdirectory folder structure along with source file names to the destination. Otherwise, files will be synced by their names only. This option is ignored when file-based replication is not enabled.
	PreserveDirectoryStructure *bool `default:"true" json:"preserve_directory_structure"`
}

func (s SourceSftpBulkUpdateCopyRawFiles) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateCopyRawFiles) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateCopyRawFiles) GetDeliveryType() *SourceSftpBulkUpdateSchemasDeliveryType {
	return SourceSftpBulkUpdateSchemasDeliveryTypeUseFileTransfer.ToPointer()
}

func (o *SourceSftpBulkUpdateCopyRawFiles) GetPreserveDirectoryStructure() *bool {
	if o == nil {
		return nil
	}
	return o.PreserveDirectoryStructure
}

type SourceSftpBulkUpdateDeliveryType string

const (
	SourceSftpBulkUpdateDeliveryTypeUseRecordsTransfer SourceSftpBulkUpdateDeliveryType = "use_records_transfer"
)

func (e SourceSftpBulkUpdateDeliveryType) ToPointer() *SourceSftpBulkUpdateDeliveryType {
	return &e
}
func (e *SourceSftpBulkUpdateDeliveryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "use_records_transfer":
		*e = SourceSftpBulkUpdateDeliveryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateDeliveryType: %v", v)
	}
}

// SourceSftpBulkUpdateReplicateRecords - Recommended - Extract and load structured records into your destination of choice. This is the classic method of moving data in Airbyte. It allows for blocking and hashing individual fields or files from a structured schema. Data can be flattened, typed and deduped depending on the destination.
type SourceSftpBulkUpdateReplicateRecords struct {
	deliveryType *SourceSftpBulkUpdateDeliveryType `const:"use_records_transfer" json:"delivery_type"`
}

func (s SourceSftpBulkUpdateReplicateRecords) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateReplicateRecords) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateReplicateRecords) GetDeliveryType() *SourceSftpBulkUpdateDeliveryType {
	return SourceSftpBulkUpdateDeliveryTypeUseRecordsTransfer.ToPointer()
}

type SourceSftpBulkUpdateDeliveryMethodType string

const (
	SourceSftpBulkUpdateDeliveryMethodTypeSourceSftpBulkUpdateReplicateRecords SourceSftpBulkUpdateDeliveryMethodType = "source-sftp-bulk-update_Replicate Records"
	SourceSftpBulkUpdateDeliveryMethodTypeSourceSftpBulkUpdateCopyRawFiles     SourceSftpBulkUpdateDeliveryMethodType = "source-sftp-bulk-update_Copy Raw Files"
)

type SourceSftpBulkUpdateDeliveryMethod struct {
	SourceSftpBulkUpdateReplicateRecords *SourceSftpBulkUpdateReplicateRecords `queryParam:"inline"`
	SourceSftpBulkUpdateCopyRawFiles     *SourceSftpBulkUpdateCopyRawFiles     `queryParam:"inline"`

	Type SourceSftpBulkUpdateDeliveryMethodType
}

func CreateSourceSftpBulkUpdateDeliveryMethodSourceSftpBulkUpdateReplicateRecords(sourceSftpBulkUpdateReplicateRecords SourceSftpBulkUpdateReplicateRecords) SourceSftpBulkUpdateDeliveryMethod {
	typ := SourceSftpBulkUpdateDeliveryMethodTypeSourceSftpBulkUpdateReplicateRecords

	return SourceSftpBulkUpdateDeliveryMethod{
		SourceSftpBulkUpdateReplicateRecords: &sourceSftpBulkUpdateReplicateRecords,
		Type:                                 typ,
	}
}

func CreateSourceSftpBulkUpdateDeliveryMethodSourceSftpBulkUpdateCopyRawFiles(sourceSftpBulkUpdateCopyRawFiles SourceSftpBulkUpdateCopyRawFiles) SourceSftpBulkUpdateDeliveryMethod {
	typ := SourceSftpBulkUpdateDeliveryMethodTypeSourceSftpBulkUpdateCopyRawFiles

	return SourceSftpBulkUpdateDeliveryMethod{
		SourceSftpBulkUpdateCopyRawFiles: &sourceSftpBulkUpdateCopyRawFiles,
		Type:                             typ,
	}
}

func (u *SourceSftpBulkUpdateDeliveryMethod) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkUpdateReplicateRecords SourceSftpBulkUpdateReplicateRecords = SourceSftpBulkUpdateReplicateRecords{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateReplicateRecords, "", true, true); err == nil {
		u.SourceSftpBulkUpdateReplicateRecords = &sourceSftpBulkUpdateReplicateRecords
		u.Type = SourceSftpBulkUpdateDeliveryMethodTypeSourceSftpBulkUpdateReplicateRecords
		return nil
	}

	var sourceSftpBulkUpdateCopyRawFiles SourceSftpBulkUpdateCopyRawFiles = SourceSftpBulkUpdateCopyRawFiles{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateCopyRawFiles, "", true, true); err == nil {
		u.SourceSftpBulkUpdateCopyRawFiles = &sourceSftpBulkUpdateCopyRawFiles
		u.Type = SourceSftpBulkUpdateDeliveryMethodTypeSourceSftpBulkUpdateCopyRawFiles
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkUpdateDeliveryMethod", string(data))
}

func (u SourceSftpBulkUpdateDeliveryMethod) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkUpdateReplicateRecords != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateReplicateRecords, "", true)
	}

	if u.SourceSftpBulkUpdateCopyRawFiles != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateCopyRawFiles, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkUpdateDeliveryMethod: all fields are null")
}

type SourceSftpBulkUpdateSchemasAuthType string

const (
	SourceSftpBulkUpdateSchemasAuthTypePrivateKey SourceSftpBulkUpdateSchemasAuthType = "private_key"
)

func (e SourceSftpBulkUpdateSchemasAuthType) ToPointer() *SourceSftpBulkUpdateSchemasAuthType {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasAuthType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private_key":
		*e = SourceSftpBulkUpdateSchemasAuthType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasAuthType: %v", v)
	}
}

type SourceSftpBulkUpdateAuthenticateViaPrivateKey struct {
	authType *SourceSftpBulkUpdateSchemasAuthType `const:"private_key" json:"auth_type"`
	// The Private key
	PrivateKey string `json:"private_key"`
}

func (s SourceSftpBulkUpdateAuthenticateViaPrivateKey) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateAuthenticateViaPrivateKey) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateAuthenticateViaPrivateKey) GetAuthType() *SourceSftpBulkUpdateSchemasAuthType {
	return SourceSftpBulkUpdateSchemasAuthTypePrivateKey.ToPointer()
}

func (o *SourceSftpBulkUpdateAuthenticateViaPrivateKey) GetPrivateKey() string {
	if o == nil {
		return ""
	}
	return o.PrivateKey
}

type SourceSftpBulkUpdateAuthType string

const (
	SourceSftpBulkUpdateAuthTypePassword SourceSftpBulkUpdateAuthType = "password"
)

func (e SourceSftpBulkUpdateAuthType) ToPointer() *SourceSftpBulkUpdateAuthType {
	return &e
}
func (e *SourceSftpBulkUpdateAuthType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "password":
		*e = SourceSftpBulkUpdateAuthType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateAuthType: %v", v)
	}
}

type SourceSftpBulkUpdateAuthenticateViaPassword struct {
	authType *SourceSftpBulkUpdateAuthType `const:"password" json:"auth_type"`
	// Password
	Password string `json:"password"`
}

func (s SourceSftpBulkUpdateAuthenticateViaPassword) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateAuthenticateViaPassword) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateAuthenticateViaPassword) GetAuthType() *SourceSftpBulkUpdateAuthType {
	return SourceSftpBulkUpdateAuthTypePassword.ToPointer()
}

func (o *SourceSftpBulkUpdateAuthenticateViaPassword) GetPassword() string {
	if o == nil {
		return ""
	}
	return o.Password
}

type SourceSftpBulkUpdateAuthenticationType string

const (
	SourceSftpBulkUpdateAuthenticationTypeSourceSftpBulkUpdateAuthenticateViaPassword   SourceSftpBulkUpdateAuthenticationType = "source-sftp-bulk-update_Authenticate via Password"
	SourceSftpBulkUpdateAuthenticationTypeSourceSftpBulkUpdateAuthenticateViaPrivateKey SourceSftpBulkUpdateAuthenticationType = "source-sftp-bulk-update_Authenticate via Private Key"
)

// SourceSftpBulkUpdateAuthentication - Credentials for connecting to the SFTP Server
type SourceSftpBulkUpdateAuthentication struct {
	SourceSftpBulkUpdateAuthenticateViaPassword   *SourceSftpBulkUpdateAuthenticateViaPassword   `queryParam:"inline"`
	SourceSftpBulkUpdateAuthenticateViaPrivateKey *SourceSftpBulkUpdateAuthenticateViaPrivateKey `queryParam:"inline"`

	Type SourceSftpBulkUpdateAuthenticationType
}

func CreateSourceSftpBulkUpdateAuthenticationSourceSftpBulkUpdateAuthenticateViaPassword(sourceSftpBulkUpdateAuthenticateViaPassword SourceSftpBulkUpdateAuthenticateViaPassword) SourceSftpBulkUpdateAuthentication {
	typ := SourceSftpBulkUpdateAuthenticationTypeSourceSftpBulkUpdateAuthenticateViaPassword

	return SourceSftpBulkUpdateAuthentication{
		SourceSftpBulkUpdateAuthenticateViaPassword: &sourceSftpBulkUpdateAuthenticateViaPassword,
		Type: typ,
	}
}

func CreateSourceSftpBulkUpdateAuthenticationSourceSftpBulkUpdateAuthenticateViaPrivateKey(sourceSftpBulkUpdateAuthenticateViaPrivateKey SourceSftpBulkUpdateAuthenticateViaPrivateKey) SourceSftpBulkUpdateAuthentication {
	typ := SourceSftpBulkUpdateAuthenticationTypeSourceSftpBulkUpdateAuthenticateViaPrivateKey

	return SourceSftpBulkUpdateAuthentication{
		SourceSftpBulkUpdateAuthenticateViaPrivateKey: &sourceSftpBulkUpdateAuthenticateViaPrivateKey,
		Type: typ,
	}
}

func (u *SourceSftpBulkUpdateAuthentication) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkUpdateAuthenticateViaPassword SourceSftpBulkUpdateAuthenticateViaPassword = SourceSftpBulkUpdateAuthenticateViaPassword{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateAuthenticateViaPassword, "", true, true); err == nil {
		u.SourceSftpBulkUpdateAuthenticateViaPassword = &sourceSftpBulkUpdateAuthenticateViaPassword
		u.Type = SourceSftpBulkUpdateAuthenticationTypeSourceSftpBulkUpdateAuthenticateViaPassword
		return nil
	}

	var sourceSftpBulkUpdateAuthenticateViaPrivateKey SourceSftpBulkUpdateAuthenticateViaPrivateKey = SourceSftpBulkUpdateAuthenticateViaPrivateKey{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateAuthenticateViaPrivateKey, "", true, true); err == nil {
		u.SourceSftpBulkUpdateAuthenticateViaPrivateKey = &sourceSftpBulkUpdateAuthenticateViaPrivateKey
		u.Type = SourceSftpBulkUpdateAuthenticationTypeSourceSftpBulkUpdateAuthenticateViaPrivateKey
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkUpdateAuthentication", string(data))
}

func (u SourceSftpBulkUpdateAuthentication) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkUpdateAuthenticateViaPassword != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateAuthenticateViaPassword, "", true)
	}

	if u.SourceSftpBulkUpdateAuthenticateViaPrivateKey != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateAuthenticateViaPrivateKey, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkUpdateAuthentication: all fields are null")
}

// SourceSftpBulkUpdate - Used during spec; allows the developer to configure the cloud provider specific options
// that are needed when users configure a file-based source.
type SourceSftpBulkUpdate struct {
	// UTC date and time in the format 2017-01-25T00:00:00.000000Z. Any file modified before this date will not be replicated.
	StartDate *time.Time `json:"start_date,omitempty"`
	// Each instance of this configuration defines a <a href="https://docs.airbyte.com/cloud/core-concepts#stream">stream</a>. Use this to define which files belong in the stream, their format, and how they should be parsed and validated. When sending data to warehouse destination such as Snowflake or BigQuery, each stream is a separate table.
	Streams        []SourceSftpBulkUpdateFileBasedStreamConfig `json:"streams"`
	DeliveryMethod *SourceSftpBulkUpdateDeliveryMethod         `json:"delivery_method,omitempty"`
	// The server host address
	Host string `json:"host"`
	// The server user
	Username string `json:"username"`
	// Credentials for connecting to the SFTP Server
	Credentials SourceSftpBulkUpdateAuthentication `json:"credentials"`
	// The server port
	Port *int64 `default:"22" json:"port"`
	// The directory to search files for sync
	FolderPath *string `default:"/" json:"folder_path"`
}

func (s SourceSftpBulkUpdate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdate) GetStartDate() *time.Time {
	if o == nil {
		return nil
	}
	return o.StartDate
}

func (o *SourceSftpBulkUpdate) GetStreams() []SourceSftpBulkUpdateFileBasedStreamConfig {
	if o == nil {
		return []SourceSftpBulkUpdateFileBasedStreamConfig{}
	}
	return o.Streams
}

func (o *SourceSftpBulkUpdate) GetDeliveryMethod() *SourceSftpBulkUpdateDeliveryMethod {
	if o == nil {
		return nil
	}
	return o.DeliveryMethod
}

func (o *SourceSftpBulkUpdate) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *SourceSftpBulkUpdate) GetUsername() string {
	if o == nil {
		return ""
	}
	return o.Username
}

func (o *SourceSftpBulkUpdate) GetCredentials() SourceSftpBulkUpdateAuthentication {
	if o == nil {
		return SourceSftpBulkUpdateAuthentication{}
	}
	return o.Credentials
}

func (o *SourceSftpBulkUpdate) GetPort() *int64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *SourceSftpBulkUpdate) GetFolderPath() *string {
	if o == nil {
		return nil
	}
	return o.FolderPath
}
