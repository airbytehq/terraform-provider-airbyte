// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/internal/utils"
	"time"
)

type SourceSftpBulkUpdateSchemasAuthType string

const (
	SourceSftpBulkUpdateSchemasAuthTypePrivateKey SourceSftpBulkUpdateSchemasAuthType = "private_key"
)

func (e SourceSftpBulkUpdateSchemasAuthType) ToPointer() *SourceSftpBulkUpdateSchemasAuthType {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasAuthType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private_key":
		*e = SourceSftpBulkUpdateSchemasAuthType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasAuthType: %v", v)
	}
}

type AuthenticateViaPrivateKey struct {
	authType *SourceSftpBulkUpdateSchemasAuthType `const:"private_key" json:"auth_type"`
	// The Private key
	PrivateKey string `json:"private_key"`
}

func (a AuthenticateViaPrivateKey) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthenticateViaPrivateKey) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *AuthenticateViaPrivateKey) GetAuthType() *SourceSftpBulkUpdateSchemasAuthType {
	return SourceSftpBulkUpdateSchemasAuthTypePrivateKey.ToPointer()
}

func (o *AuthenticateViaPrivateKey) GetPrivateKey() string {
	if o == nil {
		return ""
	}
	return o.PrivateKey
}

type SourceSftpBulkUpdateAuthType string

const (
	SourceSftpBulkUpdateAuthTypePassword SourceSftpBulkUpdateAuthType = "password"
)

func (e SourceSftpBulkUpdateAuthType) ToPointer() *SourceSftpBulkUpdateAuthType {
	return &e
}
func (e *SourceSftpBulkUpdateAuthType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "password":
		*e = SourceSftpBulkUpdateAuthType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateAuthType: %v", v)
	}
}

type AuthenticateViaPassword struct {
	authType *SourceSftpBulkUpdateAuthType `const:"password" json:"auth_type"`
	// Password
	Password string `json:"password"`
}

func (a AuthenticateViaPassword) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthenticateViaPassword) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *AuthenticateViaPassword) GetAuthType() *SourceSftpBulkUpdateAuthType {
	return SourceSftpBulkUpdateAuthTypePassword.ToPointer()
}

func (o *AuthenticateViaPassword) GetPassword() string {
	if o == nil {
		return ""
	}
	return o.Password
}

type SourceSftpBulkUpdateAuthenticationType string

const (
	SourceSftpBulkUpdateAuthenticationTypeAuthenticateViaPassword   SourceSftpBulkUpdateAuthenticationType = "Authenticate via Password"
	SourceSftpBulkUpdateAuthenticationTypeAuthenticateViaPrivateKey SourceSftpBulkUpdateAuthenticationType = "Authenticate via Private Key"
)

// SourceSftpBulkUpdateAuthentication - Credentials for connecting to the SFTP Server
type SourceSftpBulkUpdateAuthentication struct {
	AuthenticateViaPassword   *AuthenticateViaPassword
	AuthenticateViaPrivateKey *AuthenticateViaPrivateKey

	Type SourceSftpBulkUpdateAuthenticationType
}

func CreateSourceSftpBulkUpdateAuthenticationAuthenticateViaPassword(authenticateViaPassword AuthenticateViaPassword) SourceSftpBulkUpdateAuthentication {
	typ := SourceSftpBulkUpdateAuthenticationTypeAuthenticateViaPassword

	return SourceSftpBulkUpdateAuthentication{
		AuthenticateViaPassword: &authenticateViaPassword,
		Type:                    typ,
	}
}

func CreateSourceSftpBulkUpdateAuthenticationAuthenticateViaPrivateKey(authenticateViaPrivateKey AuthenticateViaPrivateKey) SourceSftpBulkUpdateAuthentication {
	typ := SourceSftpBulkUpdateAuthenticationTypeAuthenticateViaPrivateKey

	return SourceSftpBulkUpdateAuthentication{
		AuthenticateViaPrivateKey: &authenticateViaPrivateKey,
		Type:                      typ,
	}
}

func (u *SourceSftpBulkUpdateAuthentication) UnmarshalJSON(data []byte) error {

	var authenticateViaPassword AuthenticateViaPassword = AuthenticateViaPassword{}
	if err := utils.UnmarshalJSON(data, &authenticateViaPassword, "", true, true); err == nil {
		u.AuthenticateViaPassword = &authenticateViaPassword
		u.Type = SourceSftpBulkUpdateAuthenticationTypeAuthenticateViaPassword
		return nil
	}

	var authenticateViaPrivateKey AuthenticateViaPrivateKey = AuthenticateViaPrivateKey{}
	if err := utils.UnmarshalJSON(data, &authenticateViaPrivateKey, "", true, true); err == nil {
		u.AuthenticateViaPrivateKey = &authenticateViaPrivateKey
		u.Type = SourceSftpBulkUpdateAuthenticationTypeAuthenticateViaPrivateKey
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkUpdateAuthentication", string(data))
}

func (u SourceSftpBulkUpdateAuthentication) MarshalJSON() ([]byte, error) {
	if u.AuthenticateViaPassword != nil {
		return utils.MarshalJSON(u.AuthenticateViaPassword, "", true)
	}

	if u.AuthenticateViaPrivateKey != nil {
		return utils.MarshalJSON(u.AuthenticateViaPrivateKey, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkUpdateAuthentication: all fields are null")
}

type SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype string

const (
	SourceSftpBulkUpdateSchemasStreamsFormatFormat6FiletypeExcel SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype = "excel"
)

func (e SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype) ToPointer() *SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "excel":
		*e = SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype: %v", v)
	}
}

type SourceSftpBulkUpdateExcelFormat struct {
	filetype *SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype `const:"excel" json:"filetype"`
}

func (s SourceSftpBulkUpdateExcelFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateExcelFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateExcelFormat) GetFiletype() *SourceSftpBulkUpdateSchemasStreamsFormatFormat6Filetype {
	return SourceSftpBulkUpdateSchemasStreamsFormatFormat6FiletypeExcel.ToPointer()
}

type SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype string

const (
	SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletypeUnstructured SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype = "unstructured"
)

func (e SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype) ToPointer() *SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "unstructured":
		*e = SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype: %v", v)
	}
}

type SourceSftpBulkUpdateSchemasMode string

const (
	SourceSftpBulkUpdateSchemasModeAPI SourceSftpBulkUpdateSchemasMode = "api"
)

func (e SourceSftpBulkUpdateSchemasMode) ToPointer() *SourceSftpBulkUpdateSchemasMode {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "api":
		*e = SourceSftpBulkUpdateSchemasMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasMode: %v", v)
	}
}

type SourceSftpBulkUpdateAPIParameterConfigModel struct {
	// The name of the unstructured API parameter to use
	Name string `json:"name"`
	// The value of the parameter
	Value string `json:"value"`
}

func (o *SourceSftpBulkUpdateAPIParameterConfigModel) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SourceSftpBulkUpdateAPIParameterConfigModel) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// SourceSftpBulkUpdateViaAPI - Process files via an API, using the `hi_res` mode. This option is useful for increased performance and accuracy, but requires an API key and a hosted instance of unstructured.
type SourceSftpBulkUpdateViaAPI struct {
	// The API key to use matching the environment
	APIKey *string `default:"" json:"api_key"`
	// The URL of the unstructured API to use
	APIURL *string                          `default:"https://api.unstructured.io" json:"api_url"`
	mode   *SourceSftpBulkUpdateSchemasMode `const:"api" json:"mode"`
	// List of parameters send to the API
	Parameters []SourceSftpBulkUpdateAPIParameterConfigModel `json:"parameters,omitempty"`
}

func (s SourceSftpBulkUpdateViaAPI) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateViaAPI) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateViaAPI) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *SourceSftpBulkUpdateViaAPI) GetAPIURL() *string {
	if o == nil {
		return nil
	}
	return o.APIURL
}

func (o *SourceSftpBulkUpdateViaAPI) GetMode() *SourceSftpBulkUpdateSchemasMode {
	return SourceSftpBulkUpdateSchemasModeAPI.ToPointer()
}

func (o *SourceSftpBulkUpdateViaAPI) GetParameters() []SourceSftpBulkUpdateAPIParameterConfigModel {
	if o == nil {
		return nil
	}
	return o.Parameters
}

type SourceSftpBulkUpdateMode string

const (
	SourceSftpBulkUpdateModeLocal SourceSftpBulkUpdateMode = "local"
)

func (e SourceSftpBulkUpdateMode) ToPointer() *SourceSftpBulkUpdateMode {
	return &e
}
func (e *SourceSftpBulkUpdateMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "local":
		*e = SourceSftpBulkUpdateMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateMode: %v", v)
	}
}

// SourceSftpBulkUpdateLocal - Process files locally, supporting `fast` and `ocr` modes. This is the default option.
type SourceSftpBulkUpdateLocal struct {
	mode *SourceSftpBulkUpdateMode `const:"local" json:"mode"`
}

func (s SourceSftpBulkUpdateLocal) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateLocal) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateLocal) GetMode() *SourceSftpBulkUpdateMode {
	return SourceSftpBulkUpdateModeLocal.ToPointer()
}

type SourceSftpBulkUpdateProcessingType string

const (
	SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateLocal  SourceSftpBulkUpdateProcessingType = "source-sftp-bulk-update_Local"
	SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateViaAPI SourceSftpBulkUpdateProcessingType = "source-sftp-bulk-update_via API"
)

// SourceSftpBulkUpdateProcessing - Processing configuration
type SourceSftpBulkUpdateProcessing struct {
	SourceSftpBulkUpdateLocal  *SourceSftpBulkUpdateLocal
	SourceSftpBulkUpdateViaAPI *SourceSftpBulkUpdateViaAPI

	Type SourceSftpBulkUpdateProcessingType
}

func CreateSourceSftpBulkUpdateProcessingSourceSftpBulkUpdateLocal(sourceSftpBulkUpdateLocal SourceSftpBulkUpdateLocal) SourceSftpBulkUpdateProcessing {
	typ := SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateLocal

	return SourceSftpBulkUpdateProcessing{
		SourceSftpBulkUpdateLocal: &sourceSftpBulkUpdateLocal,
		Type:                      typ,
	}
}

func CreateSourceSftpBulkUpdateProcessingSourceSftpBulkUpdateViaAPI(sourceSftpBulkUpdateViaAPI SourceSftpBulkUpdateViaAPI) SourceSftpBulkUpdateProcessing {
	typ := SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateViaAPI

	return SourceSftpBulkUpdateProcessing{
		SourceSftpBulkUpdateViaAPI: &sourceSftpBulkUpdateViaAPI,
		Type:                       typ,
	}
}

func (u *SourceSftpBulkUpdateProcessing) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkUpdateLocal SourceSftpBulkUpdateLocal = SourceSftpBulkUpdateLocal{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateLocal, "", true, true); err == nil {
		u.SourceSftpBulkUpdateLocal = &sourceSftpBulkUpdateLocal
		u.Type = SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateLocal
		return nil
	}

	var sourceSftpBulkUpdateViaAPI SourceSftpBulkUpdateViaAPI = SourceSftpBulkUpdateViaAPI{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateViaAPI, "", true, true); err == nil {
		u.SourceSftpBulkUpdateViaAPI = &sourceSftpBulkUpdateViaAPI
		u.Type = SourceSftpBulkUpdateProcessingTypeSourceSftpBulkUpdateViaAPI
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkUpdateProcessing", string(data))
}

func (u SourceSftpBulkUpdateProcessing) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkUpdateLocal != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateLocal, "", true)
	}

	if u.SourceSftpBulkUpdateViaAPI != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateViaAPI, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkUpdateProcessing: all fields are null")
}

// SourceSftpBulkUpdateParsingStrategy - The strategy used to parse documents. `fast` extracts text directly from the document which doesn't work for all files. `ocr_only` is more reliable, but slower. `hi_res` is the most reliable, but requires an API key and a hosted instance of unstructured and can't be used with local mode. See the unstructured.io documentation for more details: https://unstructured-io.github.io/unstructured/core/partition.html#partition-pdf
type SourceSftpBulkUpdateParsingStrategy string

const (
	SourceSftpBulkUpdateParsingStrategyAuto    SourceSftpBulkUpdateParsingStrategy = "auto"
	SourceSftpBulkUpdateParsingStrategyFast    SourceSftpBulkUpdateParsingStrategy = "fast"
	SourceSftpBulkUpdateParsingStrategyOcrOnly SourceSftpBulkUpdateParsingStrategy = "ocr_only"
	SourceSftpBulkUpdateParsingStrategyHiRes   SourceSftpBulkUpdateParsingStrategy = "hi_res"
)

func (e SourceSftpBulkUpdateParsingStrategy) ToPointer() *SourceSftpBulkUpdateParsingStrategy {
	return &e
}
func (e *SourceSftpBulkUpdateParsingStrategy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "fast":
		fallthrough
	case "ocr_only":
		fallthrough
	case "hi_res":
		*e = SourceSftpBulkUpdateParsingStrategy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateParsingStrategy: %v", v)
	}
}

// SourceSftpBulkUpdateUnstructuredDocumentFormat - Extract text from document formats (.pdf, .docx, .md, .pptx) and emit as one record per file.
type SourceSftpBulkUpdateUnstructuredDocumentFormat struct {
	filetype *SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype `const:"unstructured" json:"filetype"`
	// Processing configuration
	Processing *SourceSftpBulkUpdateProcessing `json:"processing,omitempty"`
	// If true, skip files that cannot be parsed and pass the error message along as the _ab_source_file_parse_error field. If false, fail the sync.
	SkipUnprocessableFiles *bool `default:"true" json:"skip_unprocessable_files"`
	// The strategy used to parse documents. `fast` extracts text directly from the document which doesn't work for all files. `ocr_only` is more reliable, but slower. `hi_res` is the most reliable, but requires an API key and a hosted instance of unstructured and can't be used with local mode. See the unstructured.io documentation for more details: https://unstructured-io.github.io/unstructured/core/partition.html#partition-pdf
	Strategy *SourceSftpBulkUpdateParsingStrategy `default:"auto" json:"strategy"`
}

func (s SourceSftpBulkUpdateUnstructuredDocumentFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateUnstructuredDocumentFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateUnstructuredDocumentFormat) GetFiletype() *SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletype {
	return SourceSftpBulkUpdateSchemasStreamsFormatFormatFiletypeUnstructured.ToPointer()
}

func (o *SourceSftpBulkUpdateUnstructuredDocumentFormat) GetProcessing() *SourceSftpBulkUpdateProcessing {
	if o == nil {
		return nil
	}
	return o.Processing
}

func (o *SourceSftpBulkUpdateUnstructuredDocumentFormat) GetSkipUnprocessableFiles() *bool {
	if o == nil {
		return nil
	}
	return o.SkipUnprocessableFiles
}

func (o *SourceSftpBulkUpdateUnstructuredDocumentFormat) GetStrategy() *SourceSftpBulkUpdateParsingStrategy {
	if o == nil {
		return nil
	}
	return o.Strategy
}

type SourceSftpBulkUpdateSchemasStreamsFormatFiletype string

const (
	SourceSftpBulkUpdateSchemasStreamsFormatFiletypeParquet SourceSftpBulkUpdateSchemasStreamsFormatFiletype = "parquet"
)

func (e SourceSftpBulkUpdateSchemasStreamsFormatFiletype) ToPointer() *SourceSftpBulkUpdateSchemasStreamsFormatFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsFormatFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "parquet":
		*e = SourceSftpBulkUpdateSchemasStreamsFormatFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsFormatFiletype: %v", v)
	}
}

type SourceSftpBulkUpdateParquetFormat struct {
	// Whether to convert decimal fields to floats. There is a loss of precision when converting decimals to floats, so this is not recommended.
	DecimalAsFloat *bool                                             `default:"false" json:"decimal_as_float"`
	filetype       *SourceSftpBulkUpdateSchemasStreamsFormatFiletype `const:"parquet" json:"filetype"`
}

func (s SourceSftpBulkUpdateParquetFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateParquetFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateParquetFormat) GetDecimalAsFloat() *bool {
	if o == nil {
		return nil
	}
	return o.DecimalAsFloat
}

func (o *SourceSftpBulkUpdateParquetFormat) GetFiletype() *SourceSftpBulkUpdateSchemasStreamsFormatFiletype {
	return SourceSftpBulkUpdateSchemasStreamsFormatFiletypeParquet.ToPointer()
}

type SourceSftpBulkUpdateSchemasStreamsFiletype string

const (
	SourceSftpBulkUpdateSchemasStreamsFiletypeJsonl SourceSftpBulkUpdateSchemasStreamsFiletype = "jsonl"
)

func (e SourceSftpBulkUpdateSchemasStreamsFiletype) ToPointer() *SourceSftpBulkUpdateSchemasStreamsFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "jsonl":
		*e = SourceSftpBulkUpdateSchemasStreamsFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsFiletype: %v", v)
	}
}

type SourceSftpBulkUpdateJsonlFormat struct {
	filetype *SourceSftpBulkUpdateSchemasStreamsFiletype `const:"jsonl" json:"filetype"`
}

func (s SourceSftpBulkUpdateJsonlFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateJsonlFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateJsonlFormat) GetFiletype() *SourceSftpBulkUpdateSchemasStreamsFiletype {
	return SourceSftpBulkUpdateSchemasStreamsFiletypeJsonl.ToPointer()
}

type SourceSftpBulkUpdateSchemasFiletype string

const (
	SourceSftpBulkUpdateSchemasFiletypeCsv SourceSftpBulkUpdateSchemasFiletype = "csv"
)

func (e SourceSftpBulkUpdateSchemasFiletype) ToPointer() *SourceSftpBulkUpdateSchemasFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "csv":
		*e = SourceSftpBulkUpdateSchemasFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasFiletype: %v", v)
	}
}

type SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType string

const (
	SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionTypeUserProvided SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType = "User Provided"
)

func (e SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType) ToPointer() *SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "User Provided":
		*e = SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType: %v", v)
	}
}

type SourceSftpBulkUpdateUserProvided struct {
	// The column names that will be used while emitting the CSV records
	ColumnNames          []string                                                `json:"column_names"`
	headerDefinitionType *SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType `const:"User Provided" json:"header_definition_type"`
}

func (s SourceSftpBulkUpdateUserProvided) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateUserProvided) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateUserProvided) GetColumnNames() []string {
	if o == nil {
		return []string{}
	}
	return o.ColumnNames
}

func (o *SourceSftpBulkUpdateUserProvided) GetHeaderDefinitionType() *SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionType {
	return SourceSftpBulkUpdateSchemasStreamsHeaderDefinitionTypeUserProvided.ToPointer()
}

type SourceSftpBulkUpdateSchemasHeaderDefinitionType string

const (
	SourceSftpBulkUpdateSchemasHeaderDefinitionTypeAutogenerated SourceSftpBulkUpdateSchemasHeaderDefinitionType = "Autogenerated"
)

func (e SourceSftpBulkUpdateSchemasHeaderDefinitionType) ToPointer() *SourceSftpBulkUpdateSchemasHeaderDefinitionType {
	return &e
}
func (e *SourceSftpBulkUpdateSchemasHeaderDefinitionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Autogenerated":
		*e = SourceSftpBulkUpdateSchemasHeaderDefinitionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateSchemasHeaderDefinitionType: %v", v)
	}
}

type SourceSftpBulkUpdateAutogenerated struct {
	headerDefinitionType *SourceSftpBulkUpdateSchemasHeaderDefinitionType `const:"Autogenerated" json:"header_definition_type"`
}

func (s SourceSftpBulkUpdateAutogenerated) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateAutogenerated) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateAutogenerated) GetHeaderDefinitionType() *SourceSftpBulkUpdateSchemasHeaderDefinitionType {
	return SourceSftpBulkUpdateSchemasHeaderDefinitionTypeAutogenerated.ToPointer()
}

type SourceSftpBulkUpdateHeaderDefinitionType string

const (
	SourceSftpBulkUpdateHeaderDefinitionTypeFromCsv SourceSftpBulkUpdateHeaderDefinitionType = "From CSV"
)

func (e SourceSftpBulkUpdateHeaderDefinitionType) ToPointer() *SourceSftpBulkUpdateHeaderDefinitionType {
	return &e
}
func (e *SourceSftpBulkUpdateHeaderDefinitionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "From CSV":
		*e = SourceSftpBulkUpdateHeaderDefinitionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateHeaderDefinitionType: %v", v)
	}
}

type SourceSftpBulkUpdateFromCSV struct {
	headerDefinitionType *SourceSftpBulkUpdateHeaderDefinitionType `const:"From CSV" json:"header_definition_type"`
}

func (s SourceSftpBulkUpdateFromCSV) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateFromCSV) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateFromCSV) GetHeaderDefinitionType() *SourceSftpBulkUpdateHeaderDefinitionType {
	return SourceSftpBulkUpdateHeaderDefinitionTypeFromCsv.ToPointer()
}

type SourceSftpBulkUpdateCSVHeaderDefinitionType string

const (
	SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateFromCSV       SourceSftpBulkUpdateCSVHeaderDefinitionType = "source-sftp-bulk-update_From CSV"
	SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateAutogenerated SourceSftpBulkUpdateCSVHeaderDefinitionType = "source-sftp-bulk-update_Autogenerated"
	SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateUserProvided  SourceSftpBulkUpdateCSVHeaderDefinitionType = "source-sftp-bulk-update_User Provided"
)

// SourceSftpBulkUpdateCSVHeaderDefinition - How headers will be defined. `User Provided` assumes the CSV does not have a header row and uses the headers provided and `Autogenerated` assumes the CSV does not have a header row and the CDK will generate headers using for `f{i}` where `i` is the index starting from 0. Else, the default behavior is to use the header from the CSV file. If a user wants to autogenerate or provide column names for a CSV having headers, they can skip rows.
type SourceSftpBulkUpdateCSVHeaderDefinition struct {
	SourceSftpBulkUpdateFromCSV       *SourceSftpBulkUpdateFromCSV
	SourceSftpBulkUpdateAutogenerated *SourceSftpBulkUpdateAutogenerated
	SourceSftpBulkUpdateUserProvided  *SourceSftpBulkUpdateUserProvided

	Type SourceSftpBulkUpdateCSVHeaderDefinitionType
}

func CreateSourceSftpBulkUpdateCSVHeaderDefinitionSourceSftpBulkUpdateFromCSV(sourceSftpBulkUpdateFromCSV SourceSftpBulkUpdateFromCSV) SourceSftpBulkUpdateCSVHeaderDefinition {
	typ := SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateFromCSV

	return SourceSftpBulkUpdateCSVHeaderDefinition{
		SourceSftpBulkUpdateFromCSV: &sourceSftpBulkUpdateFromCSV,
		Type:                        typ,
	}
}

func CreateSourceSftpBulkUpdateCSVHeaderDefinitionSourceSftpBulkUpdateAutogenerated(sourceSftpBulkUpdateAutogenerated SourceSftpBulkUpdateAutogenerated) SourceSftpBulkUpdateCSVHeaderDefinition {
	typ := SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateAutogenerated

	return SourceSftpBulkUpdateCSVHeaderDefinition{
		SourceSftpBulkUpdateAutogenerated: &sourceSftpBulkUpdateAutogenerated,
		Type:                              typ,
	}
}

func CreateSourceSftpBulkUpdateCSVHeaderDefinitionSourceSftpBulkUpdateUserProvided(sourceSftpBulkUpdateUserProvided SourceSftpBulkUpdateUserProvided) SourceSftpBulkUpdateCSVHeaderDefinition {
	typ := SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateUserProvided

	return SourceSftpBulkUpdateCSVHeaderDefinition{
		SourceSftpBulkUpdateUserProvided: &sourceSftpBulkUpdateUserProvided,
		Type:                             typ,
	}
}

func (u *SourceSftpBulkUpdateCSVHeaderDefinition) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkUpdateFromCSV SourceSftpBulkUpdateFromCSV = SourceSftpBulkUpdateFromCSV{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateFromCSV, "", true, true); err == nil {
		u.SourceSftpBulkUpdateFromCSV = &sourceSftpBulkUpdateFromCSV
		u.Type = SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateFromCSV
		return nil
	}

	var sourceSftpBulkUpdateAutogenerated SourceSftpBulkUpdateAutogenerated = SourceSftpBulkUpdateAutogenerated{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateAutogenerated, "", true, true); err == nil {
		u.SourceSftpBulkUpdateAutogenerated = &sourceSftpBulkUpdateAutogenerated
		u.Type = SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateAutogenerated
		return nil
	}

	var sourceSftpBulkUpdateUserProvided SourceSftpBulkUpdateUserProvided = SourceSftpBulkUpdateUserProvided{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateUserProvided, "", true, true); err == nil {
		u.SourceSftpBulkUpdateUserProvided = &sourceSftpBulkUpdateUserProvided
		u.Type = SourceSftpBulkUpdateCSVHeaderDefinitionTypeSourceSftpBulkUpdateUserProvided
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkUpdateCSVHeaderDefinition", string(data))
}

func (u SourceSftpBulkUpdateCSVHeaderDefinition) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkUpdateFromCSV != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateFromCSV, "", true)
	}

	if u.SourceSftpBulkUpdateAutogenerated != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateAutogenerated, "", true)
	}

	if u.SourceSftpBulkUpdateUserProvided != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateUserProvided, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkUpdateCSVHeaderDefinition: all fields are null")
}

// SourceSftpBulkUpdateInferenceType - How to infer the types of the columns. If none, inference default to strings.
type SourceSftpBulkUpdateInferenceType string

const (
	SourceSftpBulkUpdateInferenceTypeNone               SourceSftpBulkUpdateInferenceType = "None"
	SourceSftpBulkUpdateInferenceTypePrimitiveTypesOnly SourceSftpBulkUpdateInferenceType = "Primitive Types Only"
)

func (e SourceSftpBulkUpdateInferenceType) ToPointer() *SourceSftpBulkUpdateInferenceType {
	return &e
}
func (e *SourceSftpBulkUpdateInferenceType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "None":
		fallthrough
	case "Primitive Types Only":
		*e = SourceSftpBulkUpdateInferenceType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateInferenceType: %v", v)
	}
}

type SourceSftpBulkUpdateCSVFormat struct {
	// The character delimiting individual cells in the CSV data. This may only be a 1-character string. For tab-delimited data enter '\t'.
	Delimiter *string `default:"," json:"delimiter"`
	// Whether two quotes in a quoted CSV value denote a single quote in the data.
	DoubleQuote *bool `default:"true" json:"double_quote"`
	// The character encoding of the CSV data. Leave blank to default to <strong>UTF8</strong>. See <a href="https://docs.python.org/3/library/codecs.html#standard-encodings" target="_blank">list of python encodings</a> for allowable options.
	Encoding *string `default:"utf8" json:"encoding"`
	// The character used for escaping special characters. To disallow escaping, leave this field blank.
	EscapeChar *string `json:"escape_char,omitempty"`
	// A set of case-sensitive strings that should be interpreted as false values.
	FalseValues []string                             `json:"false_values,omitempty"`
	filetype    *SourceSftpBulkUpdateSchemasFiletype `const:"csv" json:"filetype"`
	// How headers will be defined. `User Provided` assumes the CSV does not have a header row and uses the headers provided and `Autogenerated` assumes the CSV does not have a header row and the CDK will generate headers using for `f{i}` where `i` is the index starting from 0. Else, the default behavior is to use the header from the CSV file. If a user wants to autogenerate or provide column names for a CSV having headers, they can skip rows.
	HeaderDefinition *SourceSftpBulkUpdateCSVHeaderDefinition `json:"header_definition,omitempty"`
	// Whether to ignore errors that occur when the number of fields in the CSV does not match the number of columns in the schema.
	IgnoreErrorsOnFieldsMismatch *bool `default:"false" json:"ignore_errors_on_fields_mismatch"`
	// How to infer the types of the columns. If none, inference default to strings.
	InferenceType *SourceSftpBulkUpdateInferenceType `default:"None" json:"inference_type"`
	// A set of case-sensitive strings that should be interpreted as null values. For example, if the value 'NA' should be interpreted as null, enter 'NA' in this field.
	NullValues []string `json:"null_values,omitempty"`
	// The character used for quoting CSV values. To disallow quoting, make this field blank.
	QuoteChar *string `default:"\"" json:"quote_char"`
	// The number of rows to skip after the header row.
	SkipRowsAfterHeader *int64 `default:"0" json:"skip_rows_after_header"`
	// The number of rows to skip before the header row. For example, if the header row is on the 3rd row, enter 2 in this field.
	SkipRowsBeforeHeader *int64 `default:"0" json:"skip_rows_before_header"`
	// Whether strings can be interpreted as null values. If true, strings that match the null_values set will be interpreted as null. If false, strings that match the null_values set will be interpreted as the string itself.
	StringsCanBeNull *bool `default:"true" json:"strings_can_be_null"`
	// A set of case-sensitive strings that should be interpreted as true values.
	TrueValues []string `json:"true_values,omitempty"`
}

func (s SourceSftpBulkUpdateCSVFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateCSVFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateCSVFormat) GetDelimiter() *string {
	if o == nil {
		return nil
	}
	return o.Delimiter
}

func (o *SourceSftpBulkUpdateCSVFormat) GetDoubleQuote() *bool {
	if o == nil {
		return nil
	}
	return o.DoubleQuote
}

func (o *SourceSftpBulkUpdateCSVFormat) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *SourceSftpBulkUpdateCSVFormat) GetEscapeChar() *string {
	if o == nil {
		return nil
	}
	return o.EscapeChar
}

func (o *SourceSftpBulkUpdateCSVFormat) GetFalseValues() []string {
	if o == nil {
		return nil
	}
	return o.FalseValues
}

func (o *SourceSftpBulkUpdateCSVFormat) GetFiletype() *SourceSftpBulkUpdateSchemasFiletype {
	return SourceSftpBulkUpdateSchemasFiletypeCsv.ToPointer()
}

func (o *SourceSftpBulkUpdateCSVFormat) GetHeaderDefinition() *SourceSftpBulkUpdateCSVHeaderDefinition {
	if o == nil {
		return nil
	}
	return o.HeaderDefinition
}

func (o *SourceSftpBulkUpdateCSVFormat) GetIgnoreErrorsOnFieldsMismatch() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreErrorsOnFieldsMismatch
}

func (o *SourceSftpBulkUpdateCSVFormat) GetInferenceType() *SourceSftpBulkUpdateInferenceType {
	if o == nil {
		return nil
	}
	return o.InferenceType
}

func (o *SourceSftpBulkUpdateCSVFormat) GetNullValues() []string {
	if o == nil {
		return nil
	}
	return o.NullValues
}

func (o *SourceSftpBulkUpdateCSVFormat) GetQuoteChar() *string {
	if o == nil {
		return nil
	}
	return o.QuoteChar
}

func (o *SourceSftpBulkUpdateCSVFormat) GetSkipRowsAfterHeader() *int64 {
	if o == nil {
		return nil
	}
	return o.SkipRowsAfterHeader
}

func (o *SourceSftpBulkUpdateCSVFormat) GetSkipRowsBeforeHeader() *int64 {
	if o == nil {
		return nil
	}
	return o.SkipRowsBeforeHeader
}

func (o *SourceSftpBulkUpdateCSVFormat) GetStringsCanBeNull() *bool {
	if o == nil {
		return nil
	}
	return o.StringsCanBeNull
}

func (o *SourceSftpBulkUpdateCSVFormat) GetTrueValues() []string {
	if o == nil {
		return nil
	}
	return o.TrueValues
}

type SourceSftpBulkUpdateFiletype string

const (
	SourceSftpBulkUpdateFiletypeAvro SourceSftpBulkUpdateFiletype = "avro"
)

func (e SourceSftpBulkUpdateFiletype) ToPointer() *SourceSftpBulkUpdateFiletype {
	return &e
}
func (e *SourceSftpBulkUpdateFiletype) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "avro":
		*e = SourceSftpBulkUpdateFiletype(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateFiletype: %v", v)
	}
}

type SourceSftpBulkUpdateAvroFormat struct {
	// Whether to convert double fields to strings. This is recommended if you have decimal numbers with a high degree of precision because there can be a loss precision when handling floating point numbers.
	DoubleAsString *bool                         `default:"false" json:"double_as_string"`
	filetype       *SourceSftpBulkUpdateFiletype `const:"avro" json:"filetype"`
}

func (s SourceSftpBulkUpdateAvroFormat) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateAvroFormat) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateAvroFormat) GetDoubleAsString() *bool {
	if o == nil {
		return nil
	}
	return o.DoubleAsString
}

func (o *SourceSftpBulkUpdateAvroFormat) GetFiletype() *SourceSftpBulkUpdateFiletype {
	return SourceSftpBulkUpdateFiletypeAvro.ToPointer()
}

type SourceSftpBulkUpdateFormatType string

const (
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateAvroFormat                 SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Avro Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateCSVFormat                  SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_CSV Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateJsonlFormat                SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Jsonl Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateParquetFormat              SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Parquet Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateUnstructuredDocumentFormat SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Unstructured Document Format"
	SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateExcelFormat                SourceSftpBulkUpdateFormatType = "source-sftp-bulk-update_Excel Format"
)

// SourceSftpBulkUpdateFormat - The configuration options that are used to alter how to read incoming files that deviate from the standard formatting.
type SourceSftpBulkUpdateFormat struct {
	SourceSftpBulkUpdateAvroFormat                 *SourceSftpBulkUpdateAvroFormat
	SourceSftpBulkUpdateCSVFormat                  *SourceSftpBulkUpdateCSVFormat
	SourceSftpBulkUpdateJsonlFormat                *SourceSftpBulkUpdateJsonlFormat
	SourceSftpBulkUpdateParquetFormat              *SourceSftpBulkUpdateParquetFormat
	SourceSftpBulkUpdateUnstructuredDocumentFormat *SourceSftpBulkUpdateUnstructuredDocumentFormat
	SourceSftpBulkUpdateExcelFormat                *SourceSftpBulkUpdateExcelFormat

	Type SourceSftpBulkUpdateFormatType
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateAvroFormat(sourceSftpBulkUpdateAvroFormat SourceSftpBulkUpdateAvroFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateAvroFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateAvroFormat: &sourceSftpBulkUpdateAvroFormat,
		Type:                           typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateCSVFormat(sourceSftpBulkUpdateCSVFormat SourceSftpBulkUpdateCSVFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateCSVFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateCSVFormat: &sourceSftpBulkUpdateCSVFormat,
		Type:                          typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateJsonlFormat(sourceSftpBulkUpdateJsonlFormat SourceSftpBulkUpdateJsonlFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateJsonlFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateJsonlFormat: &sourceSftpBulkUpdateJsonlFormat,
		Type:                            typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateParquetFormat(sourceSftpBulkUpdateParquetFormat SourceSftpBulkUpdateParquetFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateParquetFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateParquetFormat: &sourceSftpBulkUpdateParquetFormat,
		Type:                              typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateUnstructuredDocumentFormat(sourceSftpBulkUpdateUnstructuredDocumentFormat SourceSftpBulkUpdateUnstructuredDocumentFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateUnstructuredDocumentFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateUnstructuredDocumentFormat: &sourceSftpBulkUpdateUnstructuredDocumentFormat,
		Type: typ,
	}
}

func CreateSourceSftpBulkUpdateFormatSourceSftpBulkUpdateExcelFormat(sourceSftpBulkUpdateExcelFormat SourceSftpBulkUpdateExcelFormat) SourceSftpBulkUpdateFormat {
	typ := SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateExcelFormat

	return SourceSftpBulkUpdateFormat{
		SourceSftpBulkUpdateExcelFormat: &sourceSftpBulkUpdateExcelFormat,
		Type:                            typ,
	}
}

func (u *SourceSftpBulkUpdateFormat) UnmarshalJSON(data []byte) error {

	var sourceSftpBulkUpdateJsonlFormat SourceSftpBulkUpdateJsonlFormat = SourceSftpBulkUpdateJsonlFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateJsonlFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateJsonlFormat = &sourceSftpBulkUpdateJsonlFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateJsonlFormat
		return nil
	}

	var sourceSftpBulkUpdateExcelFormat SourceSftpBulkUpdateExcelFormat = SourceSftpBulkUpdateExcelFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateExcelFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateExcelFormat = &sourceSftpBulkUpdateExcelFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateExcelFormat
		return nil
	}

	var sourceSftpBulkUpdateAvroFormat SourceSftpBulkUpdateAvroFormat = SourceSftpBulkUpdateAvroFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateAvroFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateAvroFormat = &sourceSftpBulkUpdateAvroFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateAvroFormat
		return nil
	}

	var sourceSftpBulkUpdateParquetFormat SourceSftpBulkUpdateParquetFormat = SourceSftpBulkUpdateParquetFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateParquetFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateParquetFormat = &sourceSftpBulkUpdateParquetFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateParquetFormat
		return nil
	}

	var sourceSftpBulkUpdateUnstructuredDocumentFormat SourceSftpBulkUpdateUnstructuredDocumentFormat = SourceSftpBulkUpdateUnstructuredDocumentFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateUnstructuredDocumentFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateUnstructuredDocumentFormat = &sourceSftpBulkUpdateUnstructuredDocumentFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateUnstructuredDocumentFormat
		return nil
	}

	var sourceSftpBulkUpdateCSVFormat SourceSftpBulkUpdateCSVFormat = SourceSftpBulkUpdateCSVFormat{}
	if err := utils.UnmarshalJSON(data, &sourceSftpBulkUpdateCSVFormat, "", true, true); err == nil {
		u.SourceSftpBulkUpdateCSVFormat = &sourceSftpBulkUpdateCSVFormat
		u.Type = SourceSftpBulkUpdateFormatTypeSourceSftpBulkUpdateCSVFormat
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for SourceSftpBulkUpdateFormat", string(data))
}

func (u SourceSftpBulkUpdateFormat) MarshalJSON() ([]byte, error) {
	if u.SourceSftpBulkUpdateAvroFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateAvroFormat, "", true)
	}

	if u.SourceSftpBulkUpdateCSVFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateCSVFormat, "", true)
	}

	if u.SourceSftpBulkUpdateJsonlFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateJsonlFormat, "", true)
	}

	if u.SourceSftpBulkUpdateParquetFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateParquetFormat, "", true)
	}

	if u.SourceSftpBulkUpdateUnstructuredDocumentFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateUnstructuredDocumentFormat, "", true)
	}

	if u.SourceSftpBulkUpdateExcelFormat != nil {
		return utils.MarshalJSON(u.SourceSftpBulkUpdateExcelFormat, "", true)
	}

	return nil, errors.New("could not marshal union type SourceSftpBulkUpdateFormat: all fields are null")
}

// SourceSftpBulkUpdateValidationPolicy - The name of the validation policy that dictates sync behavior when a record does not adhere to the stream schema.
type SourceSftpBulkUpdateValidationPolicy string

const (
	SourceSftpBulkUpdateValidationPolicyEmitRecord      SourceSftpBulkUpdateValidationPolicy = "Emit Record"
	SourceSftpBulkUpdateValidationPolicySkipRecord      SourceSftpBulkUpdateValidationPolicy = "Skip Record"
	SourceSftpBulkUpdateValidationPolicyWaitForDiscover SourceSftpBulkUpdateValidationPolicy = "Wait for Discover"
)

func (e SourceSftpBulkUpdateValidationPolicy) ToPointer() *SourceSftpBulkUpdateValidationPolicy {
	return &e
}
func (e *SourceSftpBulkUpdateValidationPolicy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Emit Record":
		fallthrough
	case "Skip Record":
		fallthrough
	case "Wait for Discover":
		*e = SourceSftpBulkUpdateValidationPolicy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SourceSftpBulkUpdateValidationPolicy: %v", v)
	}
}

type SourceSftpBulkUpdateFileBasedStreamConfig struct {
	// When the state history of the file store is full, syncs will only read files that were last modified in the provided day range.
	DaysToSyncIfHistoryIsFull *int64 `default:"3" json:"days_to_sync_if_history_is_full"`
	// The configuration options that are used to alter how to read incoming files that deviate from the standard formatting.
	Format SourceSftpBulkUpdateFormat `json:"format"`
	// The pattern used to specify which files should be selected from the file system. For more information on glob pattern matching look <a href="https://en.wikipedia.org/wiki/Glob_(programming)">here</a>.
	Globs []string `json:"globs,omitempty"`
	// The schema that will be used to validate records extracted from the file. This will override the stream schema that is auto-detected from incoming files.
	InputSchema *string `json:"input_schema,omitempty"`
	// The path prefix configured in v3 versions of the S3 connector. This option is deprecated in favor of a single glob.
	LegacyPrefix *string `json:"legacy_prefix,omitempty"`
	// The name of the stream.
	Name string `json:"name"`
	// The column or columns (for a composite key) that serves as the unique identifier of a record. If empty, the primary key will default to the parser's default primary key.
	PrimaryKey *string `json:"primary_key,omitempty"`
	// The number of resent files which will be used to discover the schema for this stream.
	RecentNFilesToReadForSchemaDiscovery *int64 `json:"recent_n_files_to_read_for_schema_discovery,omitempty"`
	// When enabled, syncs will not validate or structure records against the stream's schema.
	Schemaless *bool `default:"false" json:"schemaless"`
	// The name of the validation policy that dictates sync behavior when a record does not adhere to the stream schema.
	ValidationPolicy *SourceSftpBulkUpdateValidationPolicy `default:"Emit Record" json:"validation_policy"`
}

func (s SourceSftpBulkUpdateFileBasedStreamConfig) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdateFileBasedStreamConfig) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetDaysToSyncIfHistoryIsFull() *int64 {
	if o == nil {
		return nil
	}
	return o.DaysToSyncIfHistoryIsFull
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetFormat() SourceSftpBulkUpdateFormat {
	if o == nil {
		return SourceSftpBulkUpdateFormat{}
	}
	return o.Format
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetGlobs() []string {
	if o == nil {
		return nil
	}
	return o.Globs
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetInputSchema() *string {
	if o == nil {
		return nil
	}
	return o.InputSchema
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetLegacyPrefix() *string {
	if o == nil {
		return nil
	}
	return o.LegacyPrefix
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetPrimaryKey() *string {
	if o == nil {
		return nil
	}
	return o.PrimaryKey
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetRecentNFilesToReadForSchemaDiscovery() *int64 {
	if o == nil {
		return nil
	}
	return o.RecentNFilesToReadForSchemaDiscovery
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetSchemaless() *bool {
	if o == nil {
		return nil
	}
	return o.Schemaless
}

func (o *SourceSftpBulkUpdateFileBasedStreamConfig) GetValidationPolicy() *SourceSftpBulkUpdateValidationPolicy {
	if o == nil {
		return nil
	}
	return o.ValidationPolicy
}

// SourceSftpBulkUpdate - Used during spec; allows the developer to configure the cloud provider specific options
// that are needed when users configure a file-based source.
type SourceSftpBulkUpdate struct {
	// Credentials for connecting to the SFTP Server
	Credentials SourceSftpBulkUpdateAuthentication `json:"credentials"`
	// The directory to search files for sync
	FolderPath *string `default:"/" json:"folder_path"`
	// The server host address
	Host string `json:"host"`
	// The server port
	Port *int64 `default:"22" json:"port"`
	// UTC date and time in the format 2017-01-25T00:00:00.000000Z. Any file modified before this date will not be replicated.
	StartDate *time.Time `json:"start_date,omitempty"`
	// Each instance of this configuration defines a <a href="https://docs.airbyte.com/cloud/core-concepts#stream">stream</a>. Use this to define which files belong in the stream, their format, and how they should be parsed and validated. When sending data to warehouse destination such as Snowflake or BigQuery, each stream is a separate table.
	Streams []SourceSftpBulkUpdateFileBasedStreamConfig `json:"streams"`
	// The server user
	Username string `json:"username"`
}

func (s SourceSftpBulkUpdate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SourceSftpBulkUpdate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SourceSftpBulkUpdate) GetCredentials() SourceSftpBulkUpdateAuthentication {
	if o == nil {
		return SourceSftpBulkUpdateAuthentication{}
	}
	return o.Credentials
}

func (o *SourceSftpBulkUpdate) GetFolderPath() *string {
	if o == nil {
		return nil
	}
	return o.FolderPath
}

func (o *SourceSftpBulkUpdate) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *SourceSftpBulkUpdate) GetPort() *int64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *SourceSftpBulkUpdate) GetStartDate() *time.Time {
	if o == nil {
		return nil
	}
	return o.StartDate
}

func (o *SourceSftpBulkUpdate) GetStreams() []SourceSftpBulkUpdateFileBasedStreamConfig {
	if o == nil {
		return []SourceSftpBulkUpdateFileBasedStreamConfig{}
	}
	return o.Streams
}

func (o *SourceSftpBulkUpdate) GetUsername() string {
	if o == nil {
		return ""
	}
	return o.Username
}
