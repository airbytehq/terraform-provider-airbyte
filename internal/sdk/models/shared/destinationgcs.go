// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/internal/utils"
)

type CredentialType string

const (
	CredentialTypeHmacKey CredentialType = "HMAC_KEY"
)

func (e CredentialType) ToPointer() *CredentialType {
	return &e
}
func (e *CredentialType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "HMAC_KEY":
		*e = CredentialType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CredentialType: %v", v)
	}
}

type HMACKey struct {
	CredentialType *CredentialType `default:"HMAC_KEY" json:"credential_type"`
	// When linked to a service account, this ID is 61 characters long; when linked to a user account, it is 24 characters long. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys#overview">here</a>.
	HmacKeyAccessID string `json:"hmac_key_access_id"`
	// The corresponding secret for the access ID. It is a 40-character base-64 encoded string.  Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys#secrets">here</a>.
	HmacKeySecret string `json:"hmac_key_secret"`
}

func (h HMACKey) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HMACKey) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HMACKey) GetCredentialType() *CredentialType {
	if h == nil {
		return nil
	}
	return h.CredentialType
}

func (h *HMACKey) GetHmacKeyAccessID() string {
	if h == nil {
		return ""
	}
	return h.HmacKeyAccessID
}

func (h *HMACKey) GetHmacKeySecret() string {
	if h == nil {
		return ""
	}
	return h.HmacKeySecret
}

type DestinationGcsAuthenticationType string

const (
	DestinationGcsAuthenticationTypeHMACKey DestinationGcsAuthenticationType = "HMAC Key"
)

// DestinationGcsAuthentication - An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys">here</a>.
type DestinationGcsAuthentication struct {
	HMACKey *HMACKey `queryParam:"inline" union:"member"`

	Type DestinationGcsAuthenticationType
}

func CreateDestinationGcsAuthenticationHMACKey(hmacKey HMACKey) DestinationGcsAuthentication {
	typ := DestinationGcsAuthenticationTypeHMACKey

	return DestinationGcsAuthentication{
		HMACKey: &hmacKey,
		Type:    typ,
	}
}

func (u *DestinationGcsAuthentication) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var hmacKey HMACKey = HMACKey{}
	if err := utils.UnmarshalJSON(data, &hmacKey, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationGcsAuthenticationTypeHMACKey,
			Value: &hmacKey,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsAuthentication", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsAuthentication", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(DestinationGcsAuthenticationType)
	switch best.Type {
	case DestinationGcsAuthenticationTypeHMACKey:
		u.HMACKey = best.Value.(*HMACKey)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsAuthentication", string(data))
}

func (u DestinationGcsAuthentication) MarshalJSON() ([]byte, error) {
	if u.HMACKey != nil {
		return utils.MarshalJSON(u.HMACKey, "", true)
	}

	return nil, errors.New("could not marshal union type DestinationGcsAuthentication: all fields are null")
}

// DestinationGcsCompressionCodec - The compression algorithm used to compress data pages.
type DestinationGcsCompressionCodec string

const (
	DestinationGcsCompressionCodecUncompressed DestinationGcsCompressionCodec = "UNCOMPRESSED"
	DestinationGcsCompressionCodecSnappy       DestinationGcsCompressionCodec = "SNAPPY"
	DestinationGcsCompressionCodecGzip         DestinationGcsCompressionCodec = "GZIP"
	DestinationGcsCompressionCodecLzo          DestinationGcsCompressionCodec = "LZO"
	DestinationGcsCompressionCodecBrotli       DestinationGcsCompressionCodec = "BROTLI"
	DestinationGcsCompressionCodecLz4          DestinationGcsCompressionCodec = "LZ4"
	DestinationGcsCompressionCodecZstd         DestinationGcsCompressionCodec = "ZSTD"
)

func (e DestinationGcsCompressionCodec) ToPointer() *DestinationGcsCompressionCodec {
	return &e
}
func (e *DestinationGcsCompressionCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "UNCOMPRESSED":
		fallthrough
	case "SNAPPY":
		fallthrough
	case "GZIP":
		fallthrough
	case "LZO":
		fallthrough
	case "BROTLI":
		fallthrough
	case "LZ4":
		fallthrough
	case "ZSTD":
		*e = DestinationGcsCompressionCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsCompressionCodec: %v", v)
	}
}

type DestinationGcsSchemasFormatOutputFormatFormatType string

const (
	DestinationGcsSchemasFormatOutputFormatFormatTypeParquet DestinationGcsSchemasFormatOutputFormatFormatType = "Parquet"
)

func (e DestinationGcsSchemasFormatOutputFormatFormatType) ToPointer() *DestinationGcsSchemasFormatOutputFormatFormatType {
	return &e
}
func (e *DestinationGcsSchemasFormatOutputFormatFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Parquet":
		*e = DestinationGcsSchemasFormatOutputFormatFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsSchemasFormatOutputFormatFormatType: %v", v)
	}
}

type DestinationGcsParquetColumnarStorage struct {
	// This is the size of a row group being buffered in memory. It limits the memory usage when writing. Larger values will improve the IO when reading, but consume more memory when writing. Default: 128 MB.
	BlockSizeMb *int64 `default:"128" json:"block_size_mb"`
	// The compression algorithm used to compress data pages.
	CompressionCodec *DestinationGcsCompressionCodec `default:"UNCOMPRESSED" json:"compression_codec"`
	// Default: true.
	DictionaryEncoding *bool `default:"true" json:"dictionary_encoding"`
	// There is one dictionary page per column per row group when dictionary encoding is used. The dictionary page size works like the page size but for dictionary. Default: 1024 KB.
	DictionaryPageSizeKb *int64                                             `default:"1024" json:"dictionary_page_size_kb"`
	FormatType           *DestinationGcsSchemasFormatOutputFormatFormatType `default:"Parquet" json:"format_type"`
	// Maximum size allowed as padding to align row groups. This is also the minimum size of a row group. Default: 8 MB.
	MaxPaddingSizeMb *int64 `default:"8" json:"max_padding_size_mb"`
	// The page size is for compression. A block is composed of pages. A page is the smallest unit that must be read fully to access a single record. If this value is too small, the compression will deteriorate. Default: 1024 KB.
	PageSizeKb *int64 `default:"1024" json:"page_size_kb"`
}

func (d DestinationGcsParquetColumnarStorage) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsParquetColumnarStorage) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationGcsParquetColumnarStorage) GetBlockSizeMb() *int64 {
	if d == nil {
		return nil
	}
	return d.BlockSizeMb
}

func (d *DestinationGcsParquetColumnarStorage) GetCompressionCodec() *DestinationGcsCompressionCodec {
	if d == nil {
		return nil
	}
	return d.CompressionCodec
}

func (d *DestinationGcsParquetColumnarStorage) GetDictionaryEncoding() *bool {
	if d == nil {
		return nil
	}
	return d.DictionaryEncoding
}

func (d *DestinationGcsParquetColumnarStorage) GetDictionaryPageSizeKb() *int64 {
	if d == nil {
		return nil
	}
	return d.DictionaryPageSizeKb
}

func (d *DestinationGcsParquetColumnarStorage) GetFormatType() *DestinationGcsSchemasFormatOutputFormatFormatType {
	if d == nil {
		return nil
	}
	return d.FormatType
}

func (d *DestinationGcsParquetColumnarStorage) GetMaxPaddingSizeMb() *int64 {
	if d == nil {
		return nil
	}
	return d.MaxPaddingSizeMb
}

func (d *DestinationGcsParquetColumnarStorage) GetPageSizeKb() *int64 {
	if d == nil {
		return nil
	}
	return d.PageSizeKb
}

type DestinationGcsSchemasFormatCompressionType string

const (
	DestinationGcsSchemasFormatCompressionTypeGzip DestinationGcsSchemasFormatCompressionType = "GZIP"
)

func (e DestinationGcsSchemasFormatCompressionType) ToPointer() *DestinationGcsSchemasFormatCompressionType {
	return &e
}
func (e *DestinationGcsSchemasFormatCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GZIP":
		*e = DestinationGcsSchemasFormatCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsSchemasFormatCompressionType: %v", v)
	}
}

type DestinationGcsGZIP struct {
	CompressionType *DestinationGcsSchemasFormatCompressionType `default:"GZIP" json:"compression_type"`
}

func (d DestinationGcsGZIP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsGZIP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationGcsGZIP) GetCompressionType() *DestinationGcsSchemasFormatCompressionType {
	if d == nil {
		return nil
	}
	return d.CompressionType
}

type DestinationGcsSchemasCompressionType string

const (
	DestinationGcsSchemasCompressionTypeNoCompression DestinationGcsSchemasCompressionType = "No Compression"
)

func (e DestinationGcsSchemasCompressionType) ToPointer() *DestinationGcsSchemasCompressionType {
	return &e
}
func (e *DestinationGcsSchemasCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No Compression":
		*e = DestinationGcsSchemasCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsSchemasCompressionType: %v", v)
	}
}

type DestinationGcsSchemasNoCompression struct {
	CompressionType *DestinationGcsSchemasCompressionType `default:"No Compression" json:"compression_type"`
}

func (d DestinationGcsSchemasNoCompression) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsSchemasNoCompression) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationGcsSchemasNoCompression) GetCompressionType() *DestinationGcsSchemasCompressionType {
	if d == nil {
		return nil
	}
	return d.CompressionType
}

type DestinationGcsCompressionUnionType string

const (
	DestinationGcsCompressionUnionTypeDestinationGcsSchemasNoCompression DestinationGcsCompressionUnionType = "destination-gcs_Schemas_No Compression"
	DestinationGcsCompressionUnionTypeDestinationGcsGZIP                 DestinationGcsCompressionUnionType = "destination-gcs_GZIP"
)

// DestinationGcsCompression - Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".jsonl.gz").
type DestinationGcsCompression struct {
	DestinationGcsSchemasNoCompression *DestinationGcsSchemasNoCompression `queryParam:"inline" union:"member"`
	DestinationGcsGZIP                 *DestinationGcsGZIP                 `queryParam:"inline" union:"member"`

	Type DestinationGcsCompressionUnionType
}

func CreateDestinationGcsCompressionDestinationGcsSchemasNoCompression(destinationGcsSchemasNoCompression DestinationGcsSchemasNoCompression) DestinationGcsCompression {
	typ := DestinationGcsCompressionUnionTypeDestinationGcsSchemasNoCompression

	return DestinationGcsCompression{
		DestinationGcsSchemasNoCompression: &destinationGcsSchemasNoCompression,
		Type:                               typ,
	}
}

func CreateDestinationGcsCompressionDestinationGcsGZIP(destinationGcsGZIP DestinationGcsGZIP) DestinationGcsCompression {
	typ := DestinationGcsCompressionUnionTypeDestinationGcsGZIP

	return DestinationGcsCompression{
		DestinationGcsGZIP: &destinationGcsGZIP,
		Type:               typ,
	}
}

func (u *DestinationGcsCompression) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var destinationGcsSchemasNoCompression DestinationGcsSchemasNoCompression = DestinationGcsSchemasNoCompression{}
	if err := utils.UnmarshalJSON(data, &destinationGcsSchemasNoCompression, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationGcsCompressionUnionTypeDestinationGcsSchemasNoCompression,
			Value: &destinationGcsSchemasNoCompression,
		})
	}

	var destinationGcsGZIP DestinationGcsGZIP = DestinationGcsGZIP{}
	if err := utils.UnmarshalJSON(data, &destinationGcsGZIP, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationGcsCompressionUnionTypeDestinationGcsGZIP,
			Value: &destinationGcsGZIP,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsCompression", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsCompression", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(DestinationGcsCompressionUnionType)
	switch best.Type {
	case DestinationGcsCompressionUnionTypeDestinationGcsSchemasNoCompression:
		u.DestinationGcsSchemasNoCompression = best.Value.(*DestinationGcsSchemasNoCompression)
		return nil
	case DestinationGcsCompressionUnionTypeDestinationGcsGZIP:
		u.DestinationGcsGZIP = best.Value.(*DestinationGcsGZIP)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsCompression", string(data))
}

func (u DestinationGcsCompression) MarshalJSON() ([]byte, error) {
	if u.DestinationGcsSchemasNoCompression != nil {
		return utils.MarshalJSON(u.DestinationGcsSchemasNoCompression, "", true)
	}

	if u.DestinationGcsGZIP != nil {
		return utils.MarshalJSON(u.DestinationGcsGZIP, "", true)
	}

	return nil, errors.New("could not marshal union type DestinationGcsCompression: all fields are null")
}

type DestinationGcsSchemasFormatFormatType string

const (
	DestinationGcsSchemasFormatFormatTypeJsonl DestinationGcsSchemasFormatFormatType = "JSONL"
)

func (e DestinationGcsSchemasFormatFormatType) ToPointer() *DestinationGcsSchemasFormatFormatType {
	return &e
}
func (e *DestinationGcsSchemasFormatFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "JSONL":
		*e = DestinationGcsSchemasFormatFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsSchemasFormatFormatType: %v", v)
	}
}

type DestinationGcsJSONLinesNewlineDelimitedJSON struct {
	// Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".jsonl.gz").
	Compression *DestinationGcsCompression             `json:"compression,omitempty"`
	FormatType  *DestinationGcsSchemasFormatFormatType `default:"JSONL" json:"format_type"`
}

func (d DestinationGcsJSONLinesNewlineDelimitedJSON) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsJSONLinesNewlineDelimitedJSON) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationGcsJSONLinesNewlineDelimitedJSON) GetCompression() *DestinationGcsCompression {
	if d == nil {
		return nil
	}
	return d.Compression
}

func (d *DestinationGcsJSONLinesNewlineDelimitedJSON) GetFormatType() *DestinationGcsSchemasFormatFormatType {
	if d == nil {
		return nil
	}
	return d.FormatType
}

type DestinationGcsCompressionType string

const (
	DestinationGcsCompressionTypeGzip DestinationGcsCompressionType = "GZIP"
)

func (e DestinationGcsCompressionType) ToPointer() *DestinationGcsCompressionType {
	return &e
}
func (e *DestinationGcsCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GZIP":
		*e = DestinationGcsCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsCompressionType: %v", v)
	}
}

type Gzip struct {
	CompressionType *DestinationGcsCompressionType `default:"GZIP" json:"compression_type"`
}

func (g Gzip) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(g, "", false)
}

func (g *Gzip) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &g, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (g *Gzip) GetCompressionType() *DestinationGcsCompressionType {
	if g == nil {
		return nil
	}
	return g.CompressionType
}

type CompressionType string

const (
	CompressionTypeNoCompression CompressionType = "No Compression"
)

func (e CompressionType) ToPointer() *CompressionType {
	return &e
}
func (e *CompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No Compression":
		*e = CompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionType: %v", v)
	}
}

type DestinationGcsNoCompression struct {
	CompressionType *CompressionType `default:"No Compression" json:"compression_type"`
}

func (d DestinationGcsNoCompression) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsNoCompression) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationGcsNoCompression) GetCompressionType() *CompressionType {
	if d == nil {
		return nil
	}
	return d.CompressionType
}

type CompressionUnionType string

const (
	CompressionUnionTypeDestinationGcsNoCompression CompressionUnionType = "destination-gcs_No Compression"
	CompressionUnionTypeGzip                        CompressionUnionType = "GZIP"
)

// Compression - Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".csv.gz").
type Compression struct {
	DestinationGcsNoCompression *DestinationGcsNoCompression `queryParam:"inline" union:"member"`
	Gzip                        *Gzip                        `queryParam:"inline" union:"member"`

	Type CompressionUnionType
}

func CreateCompressionDestinationGcsNoCompression(destinationGcsNoCompression DestinationGcsNoCompression) Compression {
	typ := CompressionUnionTypeDestinationGcsNoCompression

	return Compression{
		DestinationGcsNoCompression: &destinationGcsNoCompression,
		Type:                        typ,
	}
}

func CreateCompressionGzip(gzip Gzip) Compression {
	typ := CompressionUnionTypeGzip

	return Compression{
		Gzip: &gzip,
		Type: typ,
	}
}

func (u *Compression) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var destinationGcsNoCompression DestinationGcsNoCompression = DestinationGcsNoCompression{}
	if err := utils.UnmarshalJSON(data, &destinationGcsNoCompression, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  CompressionUnionTypeDestinationGcsNoCompression,
			Value: &destinationGcsNoCompression,
		})
	}

	var gzip Gzip = Gzip{}
	if err := utils.UnmarshalJSON(data, &gzip, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  CompressionUnionTypeGzip,
			Value: &gzip,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for Compression", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for Compression", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(CompressionUnionType)
	switch best.Type {
	case CompressionUnionTypeDestinationGcsNoCompression:
		u.DestinationGcsNoCompression = best.Value.(*DestinationGcsNoCompression)
		return nil
	case CompressionUnionTypeGzip:
		u.Gzip = best.Value.(*Gzip)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for Compression", string(data))
}

func (u Compression) MarshalJSON() ([]byte, error) {
	if u.DestinationGcsNoCompression != nil {
		return utils.MarshalJSON(u.DestinationGcsNoCompression, "", true)
	}

	if u.Gzip != nil {
		return utils.MarshalJSON(u.Gzip, "", true)
	}

	return nil, errors.New("could not marshal union type Compression: all fields are null")
}

// Normalization - Whether the input JSON data should be normalized (flattened) in the output CSV. Please refer to docs for details.
type Normalization string

const (
	NormalizationNoFlattening        Normalization = "No flattening"
	NormalizationRootLevelFlattening Normalization = "Root level flattening"
)

func (e Normalization) ToPointer() *Normalization {
	return &e
}
func (e *Normalization) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No flattening":
		fallthrough
	case "Root level flattening":
		*e = Normalization(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Normalization: %v", v)
	}
}

type DestinationGcsSchemasFormatType string

const (
	DestinationGcsSchemasFormatTypeCsv DestinationGcsSchemasFormatType = "CSV"
)

func (e DestinationGcsSchemasFormatType) ToPointer() *DestinationGcsSchemasFormatType {
	return &e
}
func (e *DestinationGcsSchemasFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "CSV":
		*e = DestinationGcsSchemasFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsSchemasFormatType: %v", v)
	}
}

type DestinationGcsCSVCommaSeparatedValues struct {
	// Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".csv.gz").
	Compression *Compression `json:"compression,omitempty"`
	// Whether the input JSON data should be normalized (flattened) in the output CSV. Please refer to docs for details.
	Flattening *Normalization                   `default:"No flattening" json:"flattening"`
	FormatType *DestinationGcsSchemasFormatType `default:"CSV" json:"format_type"`
}

func (d DestinationGcsCSVCommaSeparatedValues) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcsCSVCommaSeparatedValues) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationGcsCSVCommaSeparatedValues) GetCompression() *Compression {
	if d == nil {
		return nil
	}
	return d.Compression
}

func (d *DestinationGcsCSVCommaSeparatedValues) GetFlattening() *Normalization {
	if d == nil {
		return nil
	}
	return d.Flattening
}

func (d *DestinationGcsCSVCommaSeparatedValues) GetFormatType() *DestinationGcsSchemasFormatType {
	if d == nil {
		return nil
	}
	return d.FormatType
}

type DestinationGcsSchemasFormatOutputFormat1Codec string

const (
	DestinationGcsSchemasFormatOutputFormat1CodecSnappy DestinationGcsSchemasFormatOutputFormat1Codec = "snappy"
)

func (e DestinationGcsSchemasFormatOutputFormat1Codec) ToPointer() *DestinationGcsSchemasFormatOutputFormat1Codec {
	return &e
}
func (e *DestinationGcsSchemasFormatOutputFormat1Codec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snappy":
		*e = DestinationGcsSchemasFormatOutputFormat1Codec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsSchemasFormatOutputFormat1Codec: %v", v)
	}
}

type Snappy struct {
	Codec *DestinationGcsSchemasFormatOutputFormat1Codec `default:"snappy" json:"codec"`
}

func (s Snappy) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Snappy) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *Snappy) GetCodec() *DestinationGcsSchemasFormatOutputFormat1Codec {
	if s == nil {
		return nil
	}
	return s.Codec
}

type DestinationGcsSchemasFormatOutputFormatCodec string

const (
	DestinationGcsSchemasFormatOutputFormatCodecZstandard DestinationGcsSchemasFormatOutputFormatCodec = "zstandard"
)

func (e DestinationGcsSchemasFormatOutputFormatCodec) ToPointer() *DestinationGcsSchemasFormatOutputFormatCodec {
	return &e
}
func (e *DestinationGcsSchemasFormatOutputFormatCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "zstandard":
		*e = DestinationGcsSchemasFormatOutputFormatCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsSchemasFormatOutputFormatCodec: %v", v)
	}
}

type Zstandard struct {
	Codec *DestinationGcsSchemasFormatOutputFormatCodec `default:"zstandard" json:"codec"`
	// Negative levels are 'fast' modes akin to lz4 or snappy, levels above 9 are generally for archival purposes, and levels above 18 use a lot of memory.
	CompressionLevel *int64 `default:"3" json:"compression_level"`
	// If true, include a checksum with each data block.
	IncludeChecksum *bool `default:"false" json:"include_checksum"`
}

func (z Zstandard) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(z, "", false)
}

func (z *Zstandard) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &z, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (z *Zstandard) GetCodec() *DestinationGcsSchemasFormatOutputFormatCodec {
	if z == nil {
		return nil
	}
	return z.Codec
}

func (z *Zstandard) GetCompressionLevel() *int64 {
	if z == nil {
		return nil
	}
	return z.CompressionLevel
}

func (z *Zstandard) GetIncludeChecksum() *bool {
	if z == nil {
		return nil
	}
	return z.IncludeChecksum
}

type DestinationGcsSchemasFormatCodec string

const (
	DestinationGcsSchemasFormatCodecXz DestinationGcsSchemasFormatCodec = "xz"
)

func (e DestinationGcsSchemasFormatCodec) ToPointer() *DestinationGcsSchemasFormatCodec {
	return &e
}
func (e *DestinationGcsSchemasFormatCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "xz":
		*e = DestinationGcsSchemasFormatCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsSchemasFormatCodec: %v", v)
	}
}

type Xz struct {
	Codec *DestinationGcsSchemasFormatCodec `default:"xz" json:"codec"`
	// The presets 0-3 are fast presets with medium compression. The presets 4-6 are fairly slow presets with high compression. The default preset is 6. The presets 7-9 are like the preset 6 but use bigger dictionaries and have higher compressor and decompressor memory requirements. Unless the uncompressed size of the file exceeds 8 MiB, 16 MiB, or 32 MiB, it is waste of memory to use the presets 7, 8, or 9, respectively. Read more <a href="https://commons.apache.org/proper/commons-compress/apidocs/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.html#XZCompressorOutputStream-java.io.OutputStream-int-">here</a> for details.
	CompressionLevel *int64 `default:"6" json:"compression_level"`
}

func (x Xz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(x, "", false)
}

func (x *Xz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &x, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (x *Xz) GetCodec() *DestinationGcsSchemasFormatCodec {
	if x == nil {
		return nil
	}
	return x.Codec
}

func (x *Xz) GetCompressionLevel() *int64 {
	if x == nil {
		return nil
	}
	return x.CompressionLevel
}

type DestinationGcsSchemasCodec string

const (
	DestinationGcsSchemasCodecBzip2 DestinationGcsSchemasCodec = "bzip2"
)

func (e DestinationGcsSchemasCodec) ToPointer() *DestinationGcsSchemasCodec {
	return &e
}
func (e *DestinationGcsSchemasCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "bzip2":
		*e = DestinationGcsSchemasCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsSchemasCodec: %v", v)
	}
}

type Bzip2 struct {
	Codec *DestinationGcsSchemasCodec `default:"bzip2" json:"codec"`
}

func (b Bzip2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(b, "", false)
}

func (b *Bzip2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &b, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (b *Bzip2) GetCodec() *DestinationGcsSchemasCodec {
	if b == nil {
		return nil
	}
	return b.Codec
}

type DestinationGcsCodec string

const (
	DestinationGcsCodecDeflate DestinationGcsCodec = "Deflate"
)

func (e DestinationGcsCodec) ToPointer() *DestinationGcsCodec {
	return &e
}
func (e *DestinationGcsCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Deflate":
		*e = DestinationGcsCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsCodec: %v", v)
	}
}

type Deflate struct {
	Codec *DestinationGcsCodec `default:"Deflate" json:"codec"`
	// 0: no compression & fastest, 9: best compression & slowest.
	CompressionLevel *int64 `default:"0" json:"compression_level"`
}

func (d Deflate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *Deflate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *Deflate) GetCodec() *DestinationGcsCodec {
	if d == nil {
		return nil
	}
	return d.Codec
}

func (d *Deflate) GetCompressionLevel() *int64 {
	if d == nil {
		return nil
	}
	return d.CompressionLevel
}

type Codec string

const (
	CodecNoCompression Codec = "no compression"
)

func (e Codec) ToPointer() *Codec {
	return &e
}
func (e *Codec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "no compression":
		*e = Codec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Codec: %v", v)
	}
}

type NoCompression struct {
	Codec *Codec `default:"no compression" json:"codec"`
}

func (n NoCompression) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(n, "", false)
}

func (n *NoCompression) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &n, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (n *NoCompression) GetCodec() *Codec {
	if n == nil {
		return nil
	}
	return n.Codec
}

type CompressionCodecType string

const (
	CompressionCodecTypeNoCompression CompressionCodecType = "No Compression"
	CompressionCodecTypeDeflate       CompressionCodecType = "Deflate"
	CompressionCodecTypeBzip2         CompressionCodecType = "bzip2"
	CompressionCodecTypeXz            CompressionCodecType = "xz"
	CompressionCodecTypeZstandard     CompressionCodecType = "zstandard"
	CompressionCodecTypeSnappy        CompressionCodecType = "snappy"
)

// CompressionCodec - The compression algorithm used to compress data. Default to no compression.
type CompressionCodec struct {
	NoCompression *NoCompression `queryParam:"inline" union:"member"`
	Deflate       *Deflate       `queryParam:"inline" union:"member"`
	Bzip2         *Bzip2         `queryParam:"inline" union:"member"`
	Xz            *Xz            `queryParam:"inline" union:"member"`
	Zstandard     *Zstandard     `queryParam:"inline" union:"member"`
	Snappy        *Snappy        `queryParam:"inline" union:"member"`

	Type CompressionCodecType
}

func CreateCompressionCodecNoCompression(noCompression NoCompression) CompressionCodec {
	typ := CompressionCodecTypeNoCompression

	return CompressionCodec{
		NoCompression: &noCompression,
		Type:          typ,
	}
}

func CreateCompressionCodecDeflate(deflate Deflate) CompressionCodec {
	typ := CompressionCodecTypeDeflate

	return CompressionCodec{
		Deflate: &deflate,
		Type:    typ,
	}
}

func CreateCompressionCodecBzip2(bzip2 Bzip2) CompressionCodec {
	typ := CompressionCodecTypeBzip2

	return CompressionCodec{
		Bzip2: &bzip2,
		Type:  typ,
	}
}

func CreateCompressionCodecXz(xz Xz) CompressionCodec {
	typ := CompressionCodecTypeXz

	return CompressionCodec{
		Xz:   &xz,
		Type: typ,
	}
}

func CreateCompressionCodecZstandard(zstandard Zstandard) CompressionCodec {
	typ := CompressionCodecTypeZstandard

	return CompressionCodec{
		Zstandard: &zstandard,
		Type:      typ,
	}
}

func CreateCompressionCodecSnappy(snappy Snappy) CompressionCodec {
	typ := CompressionCodecTypeSnappy

	return CompressionCodec{
		Snappy: &snappy,
		Type:   typ,
	}
}

func (u *CompressionCodec) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var noCompression NoCompression = NoCompression{}
	if err := utils.UnmarshalJSON(data, &noCompression, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  CompressionCodecTypeNoCompression,
			Value: &noCompression,
		})
	}

	var deflate Deflate = Deflate{}
	if err := utils.UnmarshalJSON(data, &deflate, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  CompressionCodecTypeDeflate,
			Value: &deflate,
		})
	}

	var bzip2 Bzip2 = Bzip2{}
	if err := utils.UnmarshalJSON(data, &bzip2, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  CompressionCodecTypeBzip2,
			Value: &bzip2,
		})
	}

	var xz Xz = Xz{}
	if err := utils.UnmarshalJSON(data, &xz, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  CompressionCodecTypeXz,
			Value: &xz,
		})
	}

	var zstandard Zstandard = Zstandard{}
	if err := utils.UnmarshalJSON(data, &zstandard, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  CompressionCodecTypeZstandard,
			Value: &zstandard,
		})
	}

	var snappy Snappy = Snappy{}
	if err := utils.UnmarshalJSON(data, &snappy, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  CompressionCodecTypeSnappy,
			Value: &snappy,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for CompressionCodec", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for CompressionCodec", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(CompressionCodecType)
	switch best.Type {
	case CompressionCodecTypeNoCompression:
		u.NoCompression = best.Value.(*NoCompression)
		return nil
	case CompressionCodecTypeDeflate:
		u.Deflate = best.Value.(*Deflate)
		return nil
	case CompressionCodecTypeBzip2:
		u.Bzip2 = best.Value.(*Bzip2)
		return nil
	case CompressionCodecTypeXz:
		u.Xz = best.Value.(*Xz)
		return nil
	case CompressionCodecTypeZstandard:
		u.Zstandard = best.Value.(*Zstandard)
		return nil
	case CompressionCodecTypeSnappy:
		u.Snappy = best.Value.(*Snappy)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for CompressionCodec", string(data))
}

func (u CompressionCodec) MarshalJSON() ([]byte, error) {
	if u.NoCompression != nil {
		return utils.MarshalJSON(u.NoCompression, "", true)
	}

	if u.Deflate != nil {
		return utils.MarshalJSON(u.Deflate, "", true)
	}

	if u.Bzip2 != nil {
		return utils.MarshalJSON(u.Bzip2, "", true)
	}

	if u.Xz != nil {
		return utils.MarshalJSON(u.Xz, "", true)
	}

	if u.Zstandard != nil {
		return utils.MarshalJSON(u.Zstandard, "", true)
	}

	if u.Snappy != nil {
		return utils.MarshalJSON(u.Snappy, "", true)
	}

	return nil, errors.New("could not marshal union type CompressionCodec: all fields are null")
}

type DestinationGcsFormatType string

const (
	DestinationGcsFormatTypeAvro DestinationGcsFormatType = "Avro"
)

func (e DestinationGcsFormatType) ToPointer() *DestinationGcsFormatType {
	return &e
}
func (e *DestinationGcsFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Avro":
		*e = DestinationGcsFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsFormatType: %v", v)
	}
}

type AvroApacheAvro struct {
	// The compression algorithm used to compress data. Default to no compression.
	CompressionCodec CompressionCodec          `json:"compression_codec"`
	FormatType       *DestinationGcsFormatType `default:"Avro" json:"format_type"`
}

func (a AvroApacheAvro) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AvroApacheAvro) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AvroApacheAvro) GetCompressionCodec() CompressionCodec {
	if a == nil {
		return CompressionCodec{}
	}
	return a.CompressionCodec
}

func (a *AvroApacheAvro) GetFormatType() *DestinationGcsFormatType {
	if a == nil {
		return nil
	}
	return a.FormatType
}

type DestinationGcsOutputFormatType string

const (
	DestinationGcsOutputFormatTypeAvroApacheAvro                              DestinationGcsOutputFormatType = "Avro: Apache Avro"
	DestinationGcsOutputFormatTypeDestinationGcsCSVCommaSeparatedValues       DestinationGcsOutputFormatType = "destination-gcs_CSV: Comma-Separated Values"
	DestinationGcsOutputFormatTypeDestinationGcsJSONLinesNewlineDelimitedJSON DestinationGcsOutputFormatType = "destination-gcs_JSON Lines: newline-delimited JSON"
	DestinationGcsOutputFormatTypeDestinationGcsParquetColumnarStorage        DestinationGcsOutputFormatType = "destination-gcs_Parquet: Columnar Storage"
)

// DestinationGcsOutputFormat - Output data format. One of the following formats must be selected - <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#advantages_of_avro">AVRO</a> format, <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet#parquet_schemas">PARQUET</a> format, <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv#loading_csv_data_into_a_table">CSV</a> format, or <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json#loading_json_data_into_a_new_table">JSONL</a> format.
type DestinationGcsOutputFormat struct {
	AvroApacheAvro                              *AvroApacheAvro                              `queryParam:"inline" union:"member"`
	DestinationGcsCSVCommaSeparatedValues       *DestinationGcsCSVCommaSeparatedValues       `queryParam:"inline" union:"member"`
	DestinationGcsJSONLinesNewlineDelimitedJSON *DestinationGcsJSONLinesNewlineDelimitedJSON `queryParam:"inline" union:"member"`
	DestinationGcsParquetColumnarStorage        *DestinationGcsParquetColumnarStorage        `queryParam:"inline" union:"member"`

	Type DestinationGcsOutputFormatType
}

func CreateDestinationGcsOutputFormatAvroApacheAvro(avroApacheAvro AvroApacheAvro) DestinationGcsOutputFormat {
	typ := DestinationGcsOutputFormatTypeAvroApacheAvro

	return DestinationGcsOutputFormat{
		AvroApacheAvro: &avroApacheAvro,
		Type:           typ,
	}
}

func CreateDestinationGcsOutputFormatDestinationGcsCSVCommaSeparatedValues(destinationGcsCSVCommaSeparatedValues DestinationGcsCSVCommaSeparatedValues) DestinationGcsOutputFormat {
	typ := DestinationGcsOutputFormatTypeDestinationGcsCSVCommaSeparatedValues

	return DestinationGcsOutputFormat{
		DestinationGcsCSVCommaSeparatedValues: &destinationGcsCSVCommaSeparatedValues,
		Type:                                  typ,
	}
}

func CreateDestinationGcsOutputFormatDestinationGcsJSONLinesNewlineDelimitedJSON(destinationGcsJSONLinesNewlineDelimitedJSON DestinationGcsJSONLinesNewlineDelimitedJSON) DestinationGcsOutputFormat {
	typ := DestinationGcsOutputFormatTypeDestinationGcsJSONLinesNewlineDelimitedJSON

	return DestinationGcsOutputFormat{
		DestinationGcsJSONLinesNewlineDelimitedJSON: &destinationGcsJSONLinesNewlineDelimitedJSON,
		Type: typ,
	}
}

func CreateDestinationGcsOutputFormatDestinationGcsParquetColumnarStorage(destinationGcsParquetColumnarStorage DestinationGcsParquetColumnarStorage) DestinationGcsOutputFormat {
	typ := DestinationGcsOutputFormatTypeDestinationGcsParquetColumnarStorage

	return DestinationGcsOutputFormat{
		DestinationGcsParquetColumnarStorage: &destinationGcsParquetColumnarStorage,
		Type:                                 typ,
	}
}

func (u *DestinationGcsOutputFormat) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var avroApacheAvro AvroApacheAvro = AvroApacheAvro{}
	if err := utils.UnmarshalJSON(data, &avroApacheAvro, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationGcsOutputFormatTypeAvroApacheAvro,
			Value: &avroApacheAvro,
		})
	}

	var destinationGcsCSVCommaSeparatedValues DestinationGcsCSVCommaSeparatedValues = DestinationGcsCSVCommaSeparatedValues{}
	if err := utils.UnmarshalJSON(data, &destinationGcsCSVCommaSeparatedValues, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationGcsOutputFormatTypeDestinationGcsCSVCommaSeparatedValues,
			Value: &destinationGcsCSVCommaSeparatedValues,
		})
	}

	var destinationGcsJSONLinesNewlineDelimitedJSON DestinationGcsJSONLinesNewlineDelimitedJSON = DestinationGcsJSONLinesNewlineDelimitedJSON{}
	if err := utils.UnmarshalJSON(data, &destinationGcsJSONLinesNewlineDelimitedJSON, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationGcsOutputFormatTypeDestinationGcsJSONLinesNewlineDelimitedJSON,
			Value: &destinationGcsJSONLinesNewlineDelimitedJSON,
		})
	}

	var destinationGcsParquetColumnarStorage DestinationGcsParquetColumnarStorage = DestinationGcsParquetColumnarStorage{}
	if err := utils.UnmarshalJSON(data, &destinationGcsParquetColumnarStorage, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationGcsOutputFormatTypeDestinationGcsParquetColumnarStorage,
			Value: &destinationGcsParquetColumnarStorage,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsOutputFormat", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsOutputFormat", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(DestinationGcsOutputFormatType)
	switch best.Type {
	case DestinationGcsOutputFormatTypeAvroApacheAvro:
		u.AvroApacheAvro = best.Value.(*AvroApacheAvro)
		return nil
	case DestinationGcsOutputFormatTypeDestinationGcsCSVCommaSeparatedValues:
		u.DestinationGcsCSVCommaSeparatedValues = best.Value.(*DestinationGcsCSVCommaSeparatedValues)
		return nil
	case DestinationGcsOutputFormatTypeDestinationGcsJSONLinesNewlineDelimitedJSON:
		u.DestinationGcsJSONLinesNewlineDelimitedJSON = best.Value.(*DestinationGcsJSONLinesNewlineDelimitedJSON)
		return nil
	case DestinationGcsOutputFormatTypeDestinationGcsParquetColumnarStorage:
		u.DestinationGcsParquetColumnarStorage = best.Value.(*DestinationGcsParquetColumnarStorage)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationGcsOutputFormat", string(data))
}

func (u DestinationGcsOutputFormat) MarshalJSON() ([]byte, error) {
	if u.AvroApacheAvro != nil {
		return utils.MarshalJSON(u.AvroApacheAvro, "", true)
	}

	if u.DestinationGcsCSVCommaSeparatedValues != nil {
		return utils.MarshalJSON(u.DestinationGcsCSVCommaSeparatedValues, "", true)
	}

	if u.DestinationGcsJSONLinesNewlineDelimitedJSON != nil {
		return utils.MarshalJSON(u.DestinationGcsJSONLinesNewlineDelimitedJSON, "", true)
	}

	if u.DestinationGcsParquetColumnarStorage != nil {
		return utils.MarshalJSON(u.DestinationGcsParquetColumnarStorage, "", true)
	}

	return nil, errors.New("could not marshal union type DestinationGcsOutputFormat: all fields are null")
}

// GCSBucketRegion - Select a Region of the GCS Bucket. Read more <a href="https://cloud.google.com/storage/docs/locations">here</a>.
type GCSBucketRegion string

const (
	GCSBucketRegionNorthamericaNortheast1 GCSBucketRegion = "northamerica-northeast1"
	GCSBucketRegionNorthamericaNortheast2 GCSBucketRegion = "northamerica-northeast2"
	GCSBucketRegionUsCentral1             GCSBucketRegion = "us-central1"
	GCSBucketRegionUsEast1                GCSBucketRegion = "us-east1"
	GCSBucketRegionUsEast4                GCSBucketRegion = "us-east4"
	GCSBucketRegionUsWest1                GCSBucketRegion = "us-west1"
	GCSBucketRegionUsWest2                GCSBucketRegion = "us-west2"
	GCSBucketRegionUsWest3                GCSBucketRegion = "us-west3"
	GCSBucketRegionUsWest4                GCSBucketRegion = "us-west4"
	GCSBucketRegionSouthamericaEast1      GCSBucketRegion = "southamerica-east1"
	GCSBucketRegionSouthamericaWest1      GCSBucketRegion = "southamerica-west1"
	GCSBucketRegionEuropeCentral2         GCSBucketRegion = "europe-central2"
	GCSBucketRegionEuropeNorth1           GCSBucketRegion = "europe-north1"
	GCSBucketRegionEuropeWest1            GCSBucketRegion = "europe-west1"
	GCSBucketRegionEuropeWest2            GCSBucketRegion = "europe-west2"
	GCSBucketRegionEuropeWest3            GCSBucketRegion = "europe-west3"
	GCSBucketRegionEuropeWest4            GCSBucketRegion = "europe-west4"
	GCSBucketRegionEuropeWest6            GCSBucketRegion = "europe-west6"
	GCSBucketRegionAsiaEast1              GCSBucketRegion = "asia-east1"
	GCSBucketRegionAsiaEast2              GCSBucketRegion = "asia-east2"
	GCSBucketRegionAsiaNortheast1         GCSBucketRegion = "asia-northeast1"
	GCSBucketRegionAsiaNortheast2         GCSBucketRegion = "asia-northeast2"
	GCSBucketRegionAsiaNortheast3         GCSBucketRegion = "asia-northeast3"
	GCSBucketRegionAsiaSouth1             GCSBucketRegion = "asia-south1"
	GCSBucketRegionAsiaSouth2             GCSBucketRegion = "asia-south2"
	GCSBucketRegionAsiaSoutheast1         GCSBucketRegion = "asia-southeast1"
	GCSBucketRegionAsiaSoutheast2         GCSBucketRegion = "asia-southeast2"
	GCSBucketRegionAustraliaSoutheast1    GCSBucketRegion = "australia-southeast1"
	GCSBucketRegionAustraliaSoutheast2    GCSBucketRegion = "australia-southeast2"
	GCSBucketRegionAsia                   GCSBucketRegion = "asia"
	GCSBucketRegionEu                     GCSBucketRegion = "eu"
	GCSBucketRegionUs                     GCSBucketRegion = "us"
	GCSBucketRegionAsia1                  GCSBucketRegion = "asia1"
	GCSBucketRegionEur4                   GCSBucketRegion = "eur4"
	GCSBucketRegionNam4                   GCSBucketRegion = "nam4"
)

func (e GCSBucketRegion) ToPointer() *GCSBucketRegion {
	return &e
}
func (e *GCSBucketRegion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "northamerica-northeast1":
		fallthrough
	case "northamerica-northeast2":
		fallthrough
	case "us-central1":
		fallthrough
	case "us-east1":
		fallthrough
	case "us-east4":
		fallthrough
	case "us-west1":
		fallthrough
	case "us-west2":
		fallthrough
	case "us-west3":
		fallthrough
	case "us-west4":
		fallthrough
	case "southamerica-east1":
		fallthrough
	case "southamerica-west1":
		fallthrough
	case "europe-central2":
		fallthrough
	case "europe-north1":
		fallthrough
	case "europe-west1":
		fallthrough
	case "europe-west2":
		fallthrough
	case "europe-west3":
		fallthrough
	case "europe-west4":
		fallthrough
	case "europe-west6":
		fallthrough
	case "asia-east1":
		fallthrough
	case "asia-east2":
		fallthrough
	case "asia-northeast1":
		fallthrough
	case "asia-northeast2":
		fallthrough
	case "asia-northeast3":
		fallthrough
	case "asia-south1":
		fallthrough
	case "asia-south2":
		fallthrough
	case "asia-southeast1":
		fallthrough
	case "asia-southeast2":
		fallthrough
	case "australia-southeast1":
		fallthrough
	case "australia-southeast2":
		fallthrough
	case "asia":
		fallthrough
	case "eu":
		fallthrough
	case "us":
		fallthrough
	case "asia1":
		fallthrough
	case "eur4":
		fallthrough
	case "nam4":
		*e = GCSBucketRegion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for GCSBucketRegion: %v", v)
	}
}

type DestinationGcsDestinationType string

const (
	DestinationGcsDestinationTypeGcs DestinationGcsDestinationType = "gcs"
)

func (e DestinationGcsDestinationType) ToPointer() *DestinationGcsDestinationType {
	return &e
}
func (e *DestinationGcsDestinationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "gcs":
		*e = DestinationGcsDestinationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationGcsDestinationType: %v", v)
	}
}

type DestinationGcs struct {
	// An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys">here</a>.
	Credential DestinationGcsAuthentication `json:"credential"`
	// Output data format. One of the following formats must be selected - <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#advantages_of_avro">AVRO</a> format, <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet#parquet_schemas">PARQUET</a> format, <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv#loading_csv_data_into_a_table">CSV</a> format, or <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json#loading_json_data_into_a_new_table">JSONL</a> format.
	Format DestinationGcsOutputFormat `json:"format"`
	// You can find the bucket name in the App Engine Admin console Application Settings page, under the label Google Cloud Storage Bucket. Read more <a href="https://cloud.google.com/storage/docs/naming-buckets">here</a>.
	GcsBucketName string `json:"gcs_bucket_name"`
	// GCS Bucket Path string Subdirectory under the above bucket to sync the data into.
	GcsBucketPath string `json:"gcs_bucket_path"`
	// Select a Region of the GCS Bucket. Read more <a href="https://cloud.google.com/storage/docs/locations">here</a>.
	GcsBucketRegion *GCSBucketRegion               `default:"us" json:"gcs_bucket_region"`
	destinationType *DestinationGcsDestinationType `const:"gcs" json:"destinationType"`
}

func (d DestinationGcs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationGcs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationGcs) GetCredential() DestinationGcsAuthentication {
	if d == nil {
		return DestinationGcsAuthentication{}
	}
	return d.Credential
}

func (d *DestinationGcs) GetFormat() DestinationGcsOutputFormat {
	if d == nil {
		return DestinationGcsOutputFormat{}
	}
	return d.Format
}

func (d *DestinationGcs) GetGcsBucketName() string {
	if d == nil {
		return ""
	}
	return d.GcsBucketName
}

func (d *DestinationGcs) GetGcsBucketPath() string {
	if d == nil {
		return ""
	}
	return d.GcsBucketPath
}

func (d *DestinationGcs) GetGcsBucketRegion() *GCSBucketRegion {
	if d == nil {
		return nil
	}
	return d.GcsBucketRegion
}

func (d *DestinationGcs) GetDestinationType() *DestinationGcsDestinationType {
	return DestinationGcsDestinationTypeGcs.ToPointer()
}
