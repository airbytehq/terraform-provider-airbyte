// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/internal/utils"
)

// DestinationBigqueryUpdateCDCDeletionMode - Whether to execute CDC deletions as hard deletes (i.e. propagate source deletions to the destination), or soft deletes (i.e. leave a tombstone record in the destination). Defaults to hard deletes.
type DestinationBigqueryUpdateCDCDeletionMode string

const (
	DestinationBigqueryUpdateCDCDeletionModeHardDelete DestinationBigqueryUpdateCDCDeletionMode = "Hard delete"
	DestinationBigqueryUpdateCDCDeletionModeSoftDelete DestinationBigqueryUpdateCDCDeletionMode = "Soft delete"
)

func (e DestinationBigqueryUpdateCDCDeletionMode) ToPointer() *DestinationBigqueryUpdateCDCDeletionMode {
	return &e
}
func (e *DestinationBigqueryUpdateCDCDeletionMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Hard delete":
		fallthrough
	case "Soft delete":
		*e = DestinationBigqueryUpdateCDCDeletionMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryUpdateCDCDeletionMode: %v", v)
	}
}

// DestinationBigqueryUpdateDatasetLocation - The location of the dataset. Warning: Changes made after creation will not be applied. Read more <a href="https://cloud.google.com/bigquery/docs/locations">here</a>.
type DestinationBigqueryUpdateDatasetLocation string

const (
	DestinationBigqueryUpdateDatasetLocationEu                     DestinationBigqueryUpdateDatasetLocation = "EU"
	DestinationBigqueryUpdateDatasetLocationUs                     DestinationBigqueryUpdateDatasetLocation = "US"
	DestinationBigqueryUpdateDatasetLocationAfricaSouth1           DestinationBigqueryUpdateDatasetLocation = "africa-south1"
	DestinationBigqueryUpdateDatasetLocationAsiaEast1              DestinationBigqueryUpdateDatasetLocation = "asia-east1"
	DestinationBigqueryUpdateDatasetLocationAsiaEast2              DestinationBigqueryUpdateDatasetLocation = "asia-east2"
	DestinationBigqueryUpdateDatasetLocationAsiaNortheast1         DestinationBigqueryUpdateDatasetLocation = "asia-northeast1"
	DestinationBigqueryUpdateDatasetLocationAsiaNortheast2         DestinationBigqueryUpdateDatasetLocation = "asia-northeast2"
	DestinationBigqueryUpdateDatasetLocationAsiaNortheast3         DestinationBigqueryUpdateDatasetLocation = "asia-northeast3"
	DestinationBigqueryUpdateDatasetLocationAsiaSouth1             DestinationBigqueryUpdateDatasetLocation = "asia-south1"
	DestinationBigqueryUpdateDatasetLocationAsiaSouth2             DestinationBigqueryUpdateDatasetLocation = "asia-south2"
	DestinationBigqueryUpdateDatasetLocationAsiaSoutheast1         DestinationBigqueryUpdateDatasetLocation = "asia-southeast1"
	DestinationBigqueryUpdateDatasetLocationAsiaSoutheast2         DestinationBigqueryUpdateDatasetLocation = "asia-southeast2"
	DestinationBigqueryUpdateDatasetLocationAustraliaSoutheast1    DestinationBigqueryUpdateDatasetLocation = "australia-southeast1"
	DestinationBigqueryUpdateDatasetLocationAustraliaSoutheast2    DestinationBigqueryUpdateDatasetLocation = "australia-southeast2"
	DestinationBigqueryUpdateDatasetLocationEuropeCentral2         DestinationBigqueryUpdateDatasetLocation = "europe-central2"
	DestinationBigqueryUpdateDatasetLocationEuropeNorth1           DestinationBigqueryUpdateDatasetLocation = "europe-north1"
	DestinationBigqueryUpdateDatasetLocationEuropeNorth2           DestinationBigqueryUpdateDatasetLocation = "europe-north2"
	DestinationBigqueryUpdateDatasetLocationEuropeSouthwest1       DestinationBigqueryUpdateDatasetLocation = "europe-southwest1"
	DestinationBigqueryUpdateDatasetLocationEuropeWest1            DestinationBigqueryUpdateDatasetLocation = "europe-west1"
	DestinationBigqueryUpdateDatasetLocationEuropeWest2            DestinationBigqueryUpdateDatasetLocation = "europe-west2"
	DestinationBigqueryUpdateDatasetLocationEuropeWest3            DestinationBigqueryUpdateDatasetLocation = "europe-west3"
	DestinationBigqueryUpdateDatasetLocationEuropeWest4            DestinationBigqueryUpdateDatasetLocation = "europe-west4"
	DestinationBigqueryUpdateDatasetLocationEuropeWest6            DestinationBigqueryUpdateDatasetLocation = "europe-west6"
	DestinationBigqueryUpdateDatasetLocationEuropeWest8            DestinationBigqueryUpdateDatasetLocation = "europe-west8"
	DestinationBigqueryUpdateDatasetLocationEuropeWest9            DestinationBigqueryUpdateDatasetLocation = "europe-west9"
	DestinationBigqueryUpdateDatasetLocationEuropeWest10           DestinationBigqueryUpdateDatasetLocation = "europe-west10"
	DestinationBigqueryUpdateDatasetLocationEuropeWest12           DestinationBigqueryUpdateDatasetLocation = "europe-west12"
	DestinationBigqueryUpdateDatasetLocationMeCentral1             DestinationBigqueryUpdateDatasetLocation = "me-central1"
	DestinationBigqueryUpdateDatasetLocationMeCentral2             DestinationBigqueryUpdateDatasetLocation = "me-central2"
	DestinationBigqueryUpdateDatasetLocationMeWest1                DestinationBigqueryUpdateDatasetLocation = "me-west1"
	DestinationBigqueryUpdateDatasetLocationNorthamericaNortheast1 DestinationBigqueryUpdateDatasetLocation = "northamerica-northeast1"
	DestinationBigqueryUpdateDatasetLocationNorthamericaNortheast2 DestinationBigqueryUpdateDatasetLocation = "northamerica-northeast2"
	DestinationBigqueryUpdateDatasetLocationNorthamericaSouth1     DestinationBigqueryUpdateDatasetLocation = "northamerica-south1"
	DestinationBigqueryUpdateDatasetLocationSouthamericaEast1      DestinationBigqueryUpdateDatasetLocation = "southamerica-east1"
	DestinationBigqueryUpdateDatasetLocationSouthamericaWest1      DestinationBigqueryUpdateDatasetLocation = "southamerica-west1"
	DestinationBigqueryUpdateDatasetLocationUsCentral1             DestinationBigqueryUpdateDatasetLocation = "us-central1"
	DestinationBigqueryUpdateDatasetLocationUsEast1                DestinationBigqueryUpdateDatasetLocation = "us-east1"
	DestinationBigqueryUpdateDatasetLocationUsEast4                DestinationBigqueryUpdateDatasetLocation = "us-east4"
	DestinationBigqueryUpdateDatasetLocationUsEast5                DestinationBigqueryUpdateDatasetLocation = "us-east5"
	DestinationBigqueryUpdateDatasetLocationUsSouth1               DestinationBigqueryUpdateDatasetLocation = "us-south1"
	DestinationBigqueryUpdateDatasetLocationUsWest1                DestinationBigqueryUpdateDatasetLocation = "us-west1"
	DestinationBigqueryUpdateDatasetLocationUsWest2                DestinationBigqueryUpdateDatasetLocation = "us-west2"
	DestinationBigqueryUpdateDatasetLocationUsWest3                DestinationBigqueryUpdateDatasetLocation = "us-west3"
	DestinationBigqueryUpdateDatasetLocationUsWest4                DestinationBigqueryUpdateDatasetLocation = "us-west4"
)

func (e DestinationBigqueryUpdateDatasetLocation) ToPointer() *DestinationBigqueryUpdateDatasetLocation {
	return &e
}
func (e *DestinationBigqueryUpdateDatasetLocation) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "EU":
		fallthrough
	case "US":
		fallthrough
	case "africa-south1":
		fallthrough
	case "asia-east1":
		fallthrough
	case "asia-east2":
		fallthrough
	case "asia-northeast1":
		fallthrough
	case "asia-northeast2":
		fallthrough
	case "asia-northeast3":
		fallthrough
	case "asia-south1":
		fallthrough
	case "asia-south2":
		fallthrough
	case "asia-southeast1":
		fallthrough
	case "asia-southeast2":
		fallthrough
	case "australia-southeast1":
		fallthrough
	case "australia-southeast2":
		fallthrough
	case "europe-central2":
		fallthrough
	case "europe-north1":
		fallthrough
	case "europe-north2":
		fallthrough
	case "europe-southwest1":
		fallthrough
	case "europe-west1":
		fallthrough
	case "europe-west2":
		fallthrough
	case "europe-west3":
		fallthrough
	case "europe-west4":
		fallthrough
	case "europe-west6":
		fallthrough
	case "europe-west8":
		fallthrough
	case "europe-west9":
		fallthrough
	case "europe-west10":
		fallthrough
	case "europe-west12":
		fallthrough
	case "me-central1":
		fallthrough
	case "me-central2":
		fallthrough
	case "me-west1":
		fallthrough
	case "northamerica-northeast1":
		fallthrough
	case "northamerica-northeast2":
		fallthrough
	case "northamerica-south1":
		fallthrough
	case "southamerica-east1":
		fallthrough
	case "southamerica-west1":
		fallthrough
	case "us-central1":
		fallthrough
	case "us-east1":
		fallthrough
	case "us-east4":
		fallthrough
	case "us-east5":
		fallthrough
	case "us-south1":
		fallthrough
	case "us-west1":
		fallthrough
	case "us-west2":
		fallthrough
	case "us-west3":
		fallthrough
	case "us-west4":
		*e = DestinationBigqueryUpdateDatasetLocation(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryUpdateDatasetLocation: %v", v)
	}
}

type DestinationBigqueryUpdateCredentialType string

const (
	DestinationBigqueryUpdateCredentialTypeHmacKey DestinationBigqueryUpdateCredentialType = "HMAC_KEY"
)

func (e DestinationBigqueryUpdateCredentialType) ToPointer() *DestinationBigqueryUpdateCredentialType {
	return &e
}
func (e *DestinationBigqueryUpdateCredentialType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "HMAC_KEY":
		*e = DestinationBigqueryUpdateCredentialType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryUpdateCredentialType: %v", v)
	}
}

type DestinationBigqueryUpdateHMACKey struct {
	CredentialType *DestinationBigqueryUpdateCredentialType `default:"HMAC_KEY" json:"credential_type"`
	// HMAC key access ID. When linked to a service account, this ID is 61 characters long; when linked to a user account, it is 24 characters long.
	HmacKeyAccessID *string `json:"hmac_key_access_id,omitempty"`
	// The corresponding secret for the access ID. It is a 40-character base-64 encoded string.
	HmacKeySecret        *string `json:"hmac_key_secret,omitempty"`
	AdditionalProperties any     `additionalProperties:"true" json:"-"`
}

func (d DestinationBigqueryUpdateHMACKey) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationBigqueryUpdateHMACKey) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationBigqueryUpdateHMACKey) GetCredentialType() *DestinationBigqueryUpdateCredentialType {
	if d == nil {
		return nil
	}
	return d.CredentialType
}

func (d *DestinationBigqueryUpdateHMACKey) GetHmacKeyAccessID() *string {
	if d == nil {
		return nil
	}
	return d.HmacKeyAccessID
}

func (d *DestinationBigqueryUpdateHMACKey) GetHmacKeySecret() *string {
	if d == nil {
		return nil
	}
	return d.HmacKeySecret
}

func (d *DestinationBigqueryUpdateHMACKey) GetAdditionalProperties() any {
	if d == nil {
		return nil
	}
	return d.AdditionalProperties
}

type DestinationBigqueryUpdateCredentialUnionType string

const (
	DestinationBigqueryUpdateCredentialUnionTypeDestinationBigqueryUpdateHMACKey DestinationBigqueryUpdateCredentialUnionType = "destination-bigquery-update_HMAC key"
)

// DestinationBigqueryUpdateCredential - An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys">here</a>.
type DestinationBigqueryUpdateCredential struct {
	DestinationBigqueryUpdateHMACKey *DestinationBigqueryUpdateHMACKey `queryParam:"inline" union:"member"`

	Type DestinationBigqueryUpdateCredentialUnionType
}

func CreateDestinationBigqueryUpdateCredentialDestinationBigqueryUpdateHMACKey(destinationBigqueryUpdateHMACKey DestinationBigqueryUpdateHMACKey) DestinationBigqueryUpdateCredential {
	typ := DestinationBigqueryUpdateCredentialUnionTypeDestinationBigqueryUpdateHMACKey

	return DestinationBigqueryUpdateCredential{
		DestinationBigqueryUpdateHMACKey: &destinationBigqueryUpdateHMACKey,
		Type:                             typ,
	}
}

func (u *DestinationBigqueryUpdateCredential) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var destinationBigqueryUpdateHMACKey DestinationBigqueryUpdateHMACKey = DestinationBigqueryUpdateHMACKey{}
	if err := utils.UnmarshalJSON(data, &destinationBigqueryUpdateHMACKey, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationBigqueryUpdateCredentialUnionTypeDestinationBigqueryUpdateHMACKey,
			Value: &destinationBigqueryUpdateHMACKey,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationBigqueryUpdateCredential", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationBigqueryUpdateCredential", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(DestinationBigqueryUpdateCredentialUnionType)
	switch best.Type {
	case DestinationBigqueryUpdateCredentialUnionTypeDestinationBigqueryUpdateHMACKey:
		u.DestinationBigqueryUpdateHMACKey = best.Value.(*DestinationBigqueryUpdateHMACKey)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationBigqueryUpdateCredential", string(data))
}

func (u DestinationBigqueryUpdateCredential) MarshalJSON() ([]byte, error) {
	if u.DestinationBigqueryUpdateHMACKey != nil {
		return utils.MarshalJSON(u.DestinationBigqueryUpdateHMACKey, "", true)
	}

	return nil, errors.New("could not marshal union type DestinationBigqueryUpdateCredential: all fields are null")
}

// DestinationBigqueryUpdateGCSTmpFilesPostProcessing - This upload method is supposed to temporary store records in GCS bucket. By this select you can chose if these records should be removed from GCS when migration has finished. The default "Delete all tmp files from GCS" value is used if not set explicitly.
type DestinationBigqueryUpdateGCSTmpFilesPostProcessing string

const (
	DestinationBigqueryUpdateGCSTmpFilesPostProcessingDeleteAllTmpFilesFromGcs DestinationBigqueryUpdateGCSTmpFilesPostProcessing = "Delete all tmp files from GCS"
	DestinationBigqueryUpdateGCSTmpFilesPostProcessingKeepAllTmpFilesInGcs     DestinationBigqueryUpdateGCSTmpFilesPostProcessing = "Keep all tmp files in GCS"
)

func (e DestinationBigqueryUpdateGCSTmpFilesPostProcessing) ToPointer() *DestinationBigqueryUpdateGCSTmpFilesPostProcessing {
	return &e
}
func (e *DestinationBigqueryUpdateGCSTmpFilesPostProcessing) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Delete all tmp files from GCS":
		fallthrough
	case "Keep all tmp files in GCS":
		*e = DestinationBigqueryUpdateGCSTmpFilesPostProcessing(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryUpdateGCSTmpFilesPostProcessing: %v", v)
	}
}

type DestinationBigqueryUpdateSchemasMethod string

const (
	DestinationBigqueryUpdateSchemasMethodGcsStaging DestinationBigqueryUpdateSchemasMethod = "GCS Staging"
)

func (e DestinationBigqueryUpdateSchemasMethod) ToPointer() *DestinationBigqueryUpdateSchemasMethod {
	return &e
}
func (e *DestinationBigqueryUpdateSchemasMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GCS Staging":
		*e = DestinationBigqueryUpdateSchemasMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryUpdateSchemasMethod: %v", v)
	}
}

// DestinationBigqueryUpdateGCSStaging - Writes large batches of records to a file, uploads the file to GCS, then uses COPY INTO to load your data into BigQuery.
type DestinationBigqueryUpdateGCSStaging struct {
	// An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys">here</a>.
	Credential *DestinationBigqueryUpdateCredential `json:"credential,omitempty"`
	// The name of the GCS bucket. Read more <a href="https://cloud.google.com/storage/docs/naming-buckets">here</a>.
	GcsBucketName *string `json:"gcs_bucket_name,omitempty"`
	// Directory under the GCS bucket where data will be written.
	GcsBucketPath *string `json:"gcs_bucket_path,omitempty"`
	// This upload method is supposed to temporary store records in GCS bucket. By this select you can chose if these records should be removed from GCS when migration has finished. The default "Delete all tmp files from GCS" value is used if not set explicitly.
	KeepFilesInGcsBucket *DestinationBigqueryUpdateGCSTmpFilesPostProcessing `default:"Delete all tmp files from GCS" json:"keep_files_in_gcs-bucket"`
	Method               *DestinationBigqueryUpdateSchemasMethod             `default:"GCS Staging" json:"method"`
	AdditionalProperties any                                                 `additionalProperties:"true" json:"-"`
}

func (d DestinationBigqueryUpdateGCSStaging) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationBigqueryUpdateGCSStaging) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationBigqueryUpdateGCSStaging) GetCredential() *DestinationBigqueryUpdateCredential {
	if d == nil {
		return nil
	}
	return d.Credential
}

func (d *DestinationBigqueryUpdateGCSStaging) GetGcsBucketName() *string {
	if d == nil {
		return nil
	}
	return d.GcsBucketName
}

func (d *DestinationBigqueryUpdateGCSStaging) GetGcsBucketPath() *string {
	if d == nil {
		return nil
	}
	return d.GcsBucketPath
}

func (d *DestinationBigqueryUpdateGCSStaging) GetKeepFilesInGcsBucket() *DestinationBigqueryUpdateGCSTmpFilesPostProcessing {
	if d == nil {
		return nil
	}
	return d.KeepFilesInGcsBucket
}

func (d *DestinationBigqueryUpdateGCSStaging) GetMethod() *DestinationBigqueryUpdateSchemasMethod {
	if d == nil {
		return nil
	}
	return d.Method
}

func (d *DestinationBigqueryUpdateGCSStaging) GetAdditionalProperties() any {
	if d == nil {
		return nil
	}
	return d.AdditionalProperties
}

type DestinationBigqueryUpdateMethod string

const (
	DestinationBigqueryUpdateMethodStandard DestinationBigqueryUpdateMethod = "Standard"
)

func (e DestinationBigqueryUpdateMethod) ToPointer() *DestinationBigqueryUpdateMethod {
	return &e
}
func (e *DestinationBigqueryUpdateMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Standard":
		*e = DestinationBigqueryUpdateMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryUpdateMethod: %v", v)
	}
}

// DestinationBigqueryUpdateBatchedStandardInserts - Direct loading using batched SQL INSERT statements. This method uses the BigQuery driver to convert large INSERT statements into file uploads automatically.
type DestinationBigqueryUpdateBatchedStandardInserts struct {
	Method               *DestinationBigqueryUpdateMethod `default:"Standard" json:"method"`
	AdditionalProperties any                              `additionalProperties:"true" json:"-"`
}

func (d DestinationBigqueryUpdateBatchedStandardInserts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationBigqueryUpdateBatchedStandardInserts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationBigqueryUpdateBatchedStandardInserts) GetMethod() *DestinationBigqueryUpdateMethod {
	if d == nil {
		return nil
	}
	return d.Method
}

func (d *DestinationBigqueryUpdateBatchedStandardInserts) GetAdditionalProperties() any {
	if d == nil {
		return nil
	}
	return d.AdditionalProperties
}

type DestinationBigqueryUpdateLoadingMethodType string

const (
	DestinationBigqueryUpdateLoadingMethodTypeDestinationBigqueryUpdateBatchedStandardInserts DestinationBigqueryUpdateLoadingMethodType = "destination-bigquery-update_Batched Standard Inserts"
	DestinationBigqueryUpdateLoadingMethodTypeDestinationBigqueryUpdateGCSStaging             DestinationBigqueryUpdateLoadingMethodType = "destination-bigquery-update_GCS Staging"
)

// DestinationBigqueryUpdateLoadingMethod - The way data will be uploaded to BigQuery.
type DestinationBigqueryUpdateLoadingMethod struct {
	DestinationBigqueryUpdateBatchedStandardInserts *DestinationBigqueryUpdateBatchedStandardInserts `queryParam:"inline" union:"member"`
	DestinationBigqueryUpdateGCSStaging             *DestinationBigqueryUpdateGCSStaging             `queryParam:"inline" union:"member"`

	Type DestinationBigqueryUpdateLoadingMethodType
}

func CreateDestinationBigqueryUpdateLoadingMethodDestinationBigqueryUpdateBatchedStandardInserts(destinationBigqueryUpdateBatchedStandardInserts DestinationBigqueryUpdateBatchedStandardInserts) DestinationBigqueryUpdateLoadingMethod {
	typ := DestinationBigqueryUpdateLoadingMethodTypeDestinationBigqueryUpdateBatchedStandardInserts

	return DestinationBigqueryUpdateLoadingMethod{
		DestinationBigqueryUpdateBatchedStandardInserts: &destinationBigqueryUpdateBatchedStandardInserts,
		Type: typ,
	}
}

func CreateDestinationBigqueryUpdateLoadingMethodDestinationBigqueryUpdateGCSStaging(destinationBigqueryUpdateGCSStaging DestinationBigqueryUpdateGCSStaging) DestinationBigqueryUpdateLoadingMethod {
	typ := DestinationBigqueryUpdateLoadingMethodTypeDestinationBigqueryUpdateGCSStaging

	return DestinationBigqueryUpdateLoadingMethod{
		DestinationBigqueryUpdateGCSStaging: &destinationBigqueryUpdateGCSStaging,
		Type:                                typ,
	}
}

func (u *DestinationBigqueryUpdateLoadingMethod) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var destinationBigqueryUpdateBatchedStandardInserts DestinationBigqueryUpdateBatchedStandardInserts = DestinationBigqueryUpdateBatchedStandardInserts{}
	if err := utils.UnmarshalJSON(data, &destinationBigqueryUpdateBatchedStandardInserts, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationBigqueryUpdateLoadingMethodTypeDestinationBigqueryUpdateBatchedStandardInserts,
			Value: &destinationBigqueryUpdateBatchedStandardInserts,
		})
	}

	var destinationBigqueryUpdateGCSStaging DestinationBigqueryUpdateGCSStaging = DestinationBigqueryUpdateGCSStaging{}
	if err := utils.UnmarshalJSON(data, &destinationBigqueryUpdateGCSStaging, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationBigqueryUpdateLoadingMethodTypeDestinationBigqueryUpdateGCSStaging,
			Value: &destinationBigqueryUpdateGCSStaging,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationBigqueryUpdateLoadingMethod", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationBigqueryUpdateLoadingMethod", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(DestinationBigqueryUpdateLoadingMethodType)
	switch best.Type {
	case DestinationBigqueryUpdateLoadingMethodTypeDestinationBigqueryUpdateBatchedStandardInserts:
		u.DestinationBigqueryUpdateBatchedStandardInserts = best.Value.(*DestinationBigqueryUpdateBatchedStandardInserts)
		return nil
	case DestinationBigqueryUpdateLoadingMethodTypeDestinationBigqueryUpdateGCSStaging:
		u.DestinationBigqueryUpdateGCSStaging = best.Value.(*DestinationBigqueryUpdateGCSStaging)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationBigqueryUpdateLoadingMethod", string(data))
}

func (u DestinationBigqueryUpdateLoadingMethod) MarshalJSON() ([]byte, error) {
	if u.DestinationBigqueryUpdateBatchedStandardInserts != nil {
		return utils.MarshalJSON(u.DestinationBigqueryUpdateBatchedStandardInserts, "", true)
	}

	if u.DestinationBigqueryUpdateGCSStaging != nil {
		return utils.MarshalJSON(u.DestinationBigqueryUpdateGCSStaging, "", true)
	}

	return nil, errors.New("could not marshal union type DestinationBigqueryUpdateLoadingMethod: all fields are null")
}

type DestinationBigqueryUpdateDestinationType string

const (
	DestinationBigqueryUpdateDestinationTypeBigquery DestinationBigqueryUpdateDestinationType = "bigquery"
)

func (e DestinationBigqueryUpdateDestinationType) ToPointer() *DestinationBigqueryUpdateDestinationType {
	return &e
}
func (e *DestinationBigqueryUpdateDestinationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "bigquery":
		*e = DestinationBigqueryUpdateDestinationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryUpdateDestinationType: %v", v)
	}
}

type DestinationBigqueryUpdate struct {
	// Whether to execute CDC deletions as hard deletes (i.e. propagate source deletions to the destination), or soft deletes (i.e. leave a tombstone record in the destination). Defaults to hard deletes.
	CdcDeletionMode *DestinationBigqueryUpdateCDCDeletionMode `default:"Hard delete" json:"cdc_deletion_mode"`
	// The contents of the JSON service account key. Check out the <a href="https://docs.airbyte.com/integrations/destinations/bigquery#service-account-key">docs</a> if you need help generating this key. Default credentials will be used if this field is left empty.
	CredentialsJSON *string `json:"credentials_json,omitempty"`
	// The default BigQuery Dataset ID that tables are replicated to if the source does not specify a namespace. Read more <a href="https://cloud.google.com/bigquery/docs/datasets#create-dataset">here</a>.
	DatasetID *string `json:"dataset_id,omitempty"`
	// The location of the dataset. Warning: Changes made after creation will not be applied. Read more <a href="https://cloud.google.com/bigquery/docs/locations">here</a>.
	DatasetLocation *DestinationBigqueryUpdateDatasetLocation `json:"dataset_location,omitempty"`
	// Write the legacy "raw tables" format, to enable backwards compatibility with older versions of this connector.
	DisableTypeDedupe *bool `default:"false" json:"disable_type_dedupe"`
	// The way data will be uploaded to BigQuery.
	LoadingMethod *DestinationBigqueryUpdateLoadingMethod `json:"loading_method,omitempty"`
	// The GCP project ID for the project containing the target BigQuery dataset. Read more <a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects">here</a>.
	ProjectID *string `json:"project_id,omitempty"`
	// Airbyte will use this dataset for various internal tables. In legacy raw tables mode, the raw tables will be stored in this dataset. Defaults to "airbyte_internal".
	RawDataDataset       *string                                   `json:"raw_data_dataset,omitempty"`
	destinationType      *DestinationBigqueryUpdateDestinationType `const:"bigquery" json:"destinationType"`
	AdditionalProperties any                                       `additionalProperties:"true" json:"-"`
}

func (d DestinationBigqueryUpdate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationBigqueryUpdate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationBigqueryUpdate) GetCdcDeletionMode() *DestinationBigqueryUpdateCDCDeletionMode {
	if d == nil {
		return nil
	}
	return d.CdcDeletionMode
}

func (d *DestinationBigqueryUpdate) GetCredentialsJSON() *string {
	if d == nil {
		return nil
	}
	return d.CredentialsJSON
}

func (d *DestinationBigqueryUpdate) GetDatasetID() *string {
	if d == nil {
		return nil
	}
	return d.DatasetID
}

func (d *DestinationBigqueryUpdate) GetDatasetLocation() *DestinationBigqueryUpdateDatasetLocation {
	if d == nil {
		return nil
	}
	return d.DatasetLocation
}

func (d *DestinationBigqueryUpdate) GetDisableTypeDedupe() *bool {
	if d == nil {
		return nil
	}
	return d.DisableTypeDedupe
}

func (d *DestinationBigqueryUpdate) GetLoadingMethod() *DestinationBigqueryUpdateLoadingMethod {
	if d == nil {
		return nil
	}
	return d.LoadingMethod
}

func (d *DestinationBigqueryUpdate) GetProjectID() *string {
	if d == nil {
		return nil
	}
	return d.ProjectID
}

func (d *DestinationBigqueryUpdate) GetRawDataDataset() *string {
	if d == nil {
		return nil
	}
	return d.RawDataDataset
}

func (d *DestinationBigqueryUpdate) GetDestinationType() *DestinationBigqueryUpdateDestinationType {
	return DestinationBigqueryUpdateDestinationTypeBigquery.ToPointer()
}

func (d *DestinationBigqueryUpdate) GetAdditionalProperties() any {
	if d == nil {
		return nil
	}
	return d.AdditionalProperties
}
