// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/internal/utils"
)

// DestinationAwsDatalakeCredentialsTitle - Name of the credentials
type DestinationAwsDatalakeCredentialsTitle string

const (
	DestinationAwsDatalakeCredentialsTitleIamUser DestinationAwsDatalakeCredentialsTitle = "IAM User"
)

func (e DestinationAwsDatalakeCredentialsTitle) ToPointer() *DestinationAwsDatalakeCredentialsTitle {
	return &e
}
func (e *DestinationAwsDatalakeCredentialsTitle) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "IAM User":
		*e = DestinationAwsDatalakeCredentialsTitle(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeCredentialsTitle: %v", v)
	}
}

type IAMUser struct {
	// AWS User Access Key Id
	AwsAccessKeyID string `json:"aws_access_key_id"`
	// Secret Access Key
	AwsSecretAccessKey string `json:"aws_secret_access_key"`
	// Name of the credentials
	credentialsTitle *DestinationAwsDatalakeCredentialsTitle `const:"IAM User" json:"credentials_title"`
}

func (i IAMUser) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *IAMUser) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *IAMUser) GetAwsAccessKeyID() string {
	if i == nil {
		return ""
	}
	return i.AwsAccessKeyID
}

func (i *IAMUser) GetAwsSecretAccessKey() string {
	if i == nil {
		return ""
	}
	return i.AwsSecretAccessKey
}

func (i *IAMUser) GetCredentialsTitle() *DestinationAwsDatalakeCredentialsTitle {
	return DestinationAwsDatalakeCredentialsTitleIamUser.ToPointer()
}

// CredentialsTitle - Name of the credentials
type CredentialsTitle string

const (
	CredentialsTitleIamRole CredentialsTitle = "IAM Role"
)

func (e CredentialsTitle) ToPointer() *CredentialsTitle {
	return &e
}
func (e *CredentialsTitle) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "IAM Role":
		*e = CredentialsTitle(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CredentialsTitle: %v", v)
	}
}

type IAMRole struct {
	// Name of the credentials
	credentialsTitle *CredentialsTitle `const:"IAM Role" json:"credentials_title"`
	// Will assume this role to write data to s3
	RoleArn string `json:"role_arn"`
}

func (i IAMRole) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *IAMRole) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *IAMRole) GetCredentialsTitle() *CredentialsTitle {
	return CredentialsTitleIamRole.ToPointer()
}

func (i *IAMRole) GetRoleArn() string {
	if i == nil {
		return ""
	}
	return i.RoleArn
}

type AuthenticationModeType string

const (
	AuthenticationModeTypeIAMRole AuthenticationModeType = "IAM Role"
	AuthenticationModeTypeIAMUser AuthenticationModeType = "IAM User"
)

// AuthenticationMode - Choose How to Authenticate to AWS.
type AuthenticationMode struct {
	IAMRole *IAMRole `queryParam:"inline" union:"member"`
	IAMUser *IAMUser `queryParam:"inline" union:"member"`

	Type AuthenticationModeType
}

func CreateAuthenticationModeIAMRole(iamRole IAMRole) AuthenticationMode {
	typ := AuthenticationModeTypeIAMRole

	return AuthenticationMode{
		IAMRole: &iamRole,
		Type:    typ,
	}
}

func CreateAuthenticationModeIAMUser(iamUser IAMUser) AuthenticationMode {
	typ := AuthenticationModeTypeIAMUser

	return AuthenticationMode{
		IAMUser: &iamUser,
		Type:    typ,
	}
}

func (u *AuthenticationMode) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var iamRole IAMRole = IAMRole{}
	if err := utils.UnmarshalJSON(data, &iamRole, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  AuthenticationModeTypeIAMRole,
			Value: &iamRole,
		})
	}

	var iamUser IAMUser = IAMUser{}
	if err := utils.UnmarshalJSON(data, &iamUser, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  AuthenticationModeTypeIAMUser,
			Value: &iamUser,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for AuthenticationMode", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for AuthenticationMode", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(AuthenticationModeType)
	switch best.Type {
	case AuthenticationModeTypeIAMRole:
		u.IAMRole = best.Value.(*IAMRole)
		return nil
	case AuthenticationModeTypeIAMUser:
		u.IAMUser = best.Value.(*IAMUser)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for AuthenticationMode", string(data))
}

func (u AuthenticationMode) MarshalJSON() ([]byte, error) {
	if u.IAMRole != nil {
		return utils.MarshalJSON(u.IAMRole, "", true)
	}

	if u.IAMUser != nil {
		return utils.MarshalJSON(u.IAMUser, "", true)
	}

	return nil, errors.New("could not marshal union type AuthenticationMode: all fields are null")
}

// DestinationAwsDatalakeCompressionCodecOptional - The compression algorithm used to compress data.
type DestinationAwsDatalakeCompressionCodecOptional string

const (
	DestinationAwsDatalakeCompressionCodecOptionalUncompressed DestinationAwsDatalakeCompressionCodecOptional = "UNCOMPRESSED"
	DestinationAwsDatalakeCompressionCodecOptionalSnappy       DestinationAwsDatalakeCompressionCodecOptional = "SNAPPY"
	DestinationAwsDatalakeCompressionCodecOptionalGzip         DestinationAwsDatalakeCompressionCodecOptional = "GZIP"
	DestinationAwsDatalakeCompressionCodecOptionalZstd         DestinationAwsDatalakeCompressionCodecOptional = "ZSTD"
)

func (e DestinationAwsDatalakeCompressionCodecOptional) ToPointer() *DestinationAwsDatalakeCompressionCodecOptional {
	return &e
}
func (e *DestinationAwsDatalakeCompressionCodecOptional) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "UNCOMPRESSED":
		fallthrough
	case "SNAPPY":
		fallthrough
	case "GZIP":
		fallthrough
	case "ZSTD":
		*e = DestinationAwsDatalakeCompressionCodecOptional(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeCompressionCodecOptional: %v", v)
	}
}

type DestinationAwsDatalakeFormatTypeWildcard string

const (
	DestinationAwsDatalakeFormatTypeWildcardParquet DestinationAwsDatalakeFormatTypeWildcard = "Parquet"
)

func (e DestinationAwsDatalakeFormatTypeWildcard) ToPointer() *DestinationAwsDatalakeFormatTypeWildcard {
	return &e
}
func (e *DestinationAwsDatalakeFormatTypeWildcard) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Parquet":
		*e = DestinationAwsDatalakeFormatTypeWildcard(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeFormatTypeWildcard: %v", v)
	}
}

type ParquetColumnarStorage struct {
	// The compression algorithm used to compress data.
	CompressionCodec *DestinationAwsDatalakeCompressionCodecOptional `default:"SNAPPY" json:"compression_codec"`
	FormatType       *DestinationAwsDatalakeFormatTypeWildcard       `default:"Parquet" json:"format_type"`
}

func (p ParquetColumnarStorage) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ParquetColumnarStorage) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *ParquetColumnarStorage) GetCompressionCodec() *DestinationAwsDatalakeCompressionCodecOptional {
	if p == nil {
		return nil
	}
	return p.CompressionCodec
}

func (p *ParquetColumnarStorage) GetFormatType() *DestinationAwsDatalakeFormatTypeWildcard {
	if p == nil {
		return nil
	}
	return p.FormatType
}

// CompressionCodecOptional - The compression algorithm used to compress data.
type CompressionCodecOptional string

const (
	CompressionCodecOptionalUncompressed CompressionCodecOptional = "UNCOMPRESSED"
	CompressionCodecOptionalGzip         CompressionCodecOptional = "GZIP"
)

func (e CompressionCodecOptional) ToPointer() *CompressionCodecOptional {
	return &e
}
func (e *CompressionCodecOptional) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "UNCOMPRESSED":
		fallthrough
	case "GZIP":
		*e = CompressionCodecOptional(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionCodecOptional: %v", v)
	}
}

type FormatTypeWildcard string

const (
	FormatTypeWildcardJsonl FormatTypeWildcard = "JSONL"
)

func (e FormatTypeWildcard) ToPointer() *FormatTypeWildcard {
	return &e
}
func (e *FormatTypeWildcard) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "JSONL":
		*e = FormatTypeWildcard(v)
		return nil
	default:
		return fmt.Errorf("invalid value for FormatTypeWildcard: %v", v)
	}
}

type JSONLinesNewlineDelimitedJSON struct {
	// The compression algorithm used to compress data.
	CompressionCodec *CompressionCodecOptional `default:"UNCOMPRESSED" json:"compression_codec"`
	FormatType       *FormatTypeWildcard       `default:"JSONL" json:"format_type"`
}

func (j JSONLinesNewlineDelimitedJSON) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(j, "", false)
}

func (j *JSONLinesNewlineDelimitedJSON) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &j, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (j *JSONLinesNewlineDelimitedJSON) GetCompressionCodec() *CompressionCodecOptional {
	if j == nil {
		return nil
	}
	return j.CompressionCodec
}

func (j *JSONLinesNewlineDelimitedJSON) GetFormatType() *FormatTypeWildcard {
	if j == nil {
		return nil
	}
	return j.FormatType
}

type OutputFormatWildcardType string

const (
	OutputFormatWildcardTypeJSONLinesNewlineDelimitedJSON OutputFormatWildcardType = "JSON Lines: Newline-delimited JSON"
	OutputFormatWildcardTypeParquetColumnarStorage        OutputFormatWildcardType = "Parquet: Columnar Storage"
)

// OutputFormatWildcard - Format of the data output.
type OutputFormatWildcard struct {
	JSONLinesNewlineDelimitedJSON *JSONLinesNewlineDelimitedJSON `queryParam:"inline" union:"member"`
	ParquetColumnarStorage        *ParquetColumnarStorage        `queryParam:"inline" union:"member"`

	Type OutputFormatWildcardType
}

func CreateOutputFormatWildcardJSONLinesNewlineDelimitedJSON(jsonLinesNewlineDelimitedJSON JSONLinesNewlineDelimitedJSON) OutputFormatWildcard {
	typ := OutputFormatWildcardTypeJSONLinesNewlineDelimitedJSON

	return OutputFormatWildcard{
		JSONLinesNewlineDelimitedJSON: &jsonLinesNewlineDelimitedJSON,
		Type:                          typ,
	}
}

func CreateOutputFormatWildcardParquetColumnarStorage(parquetColumnarStorage ParquetColumnarStorage) OutputFormatWildcard {
	typ := OutputFormatWildcardTypeParquetColumnarStorage

	return OutputFormatWildcard{
		ParquetColumnarStorage: &parquetColumnarStorage,
		Type:                   typ,
	}
}

func (u *OutputFormatWildcard) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var jsonLinesNewlineDelimitedJSON JSONLinesNewlineDelimitedJSON = JSONLinesNewlineDelimitedJSON{}
	if err := utils.UnmarshalJSON(data, &jsonLinesNewlineDelimitedJSON, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  OutputFormatWildcardTypeJSONLinesNewlineDelimitedJSON,
			Value: &jsonLinesNewlineDelimitedJSON,
		})
	}

	var parquetColumnarStorage ParquetColumnarStorage = ParquetColumnarStorage{}
	if err := utils.UnmarshalJSON(data, &parquetColumnarStorage, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  OutputFormatWildcardTypeParquetColumnarStorage,
			Value: &parquetColumnarStorage,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for OutputFormatWildcard", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for OutputFormatWildcard", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(OutputFormatWildcardType)
	switch best.Type {
	case OutputFormatWildcardTypeJSONLinesNewlineDelimitedJSON:
		u.JSONLinesNewlineDelimitedJSON = best.Value.(*JSONLinesNewlineDelimitedJSON)
		return nil
	case OutputFormatWildcardTypeParquetColumnarStorage:
		u.ParquetColumnarStorage = best.Value.(*ParquetColumnarStorage)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for OutputFormatWildcard", string(data))
}

func (u OutputFormatWildcard) MarshalJSON() ([]byte, error) {
	if u.JSONLinesNewlineDelimitedJSON != nil {
		return utils.MarshalJSON(u.JSONLinesNewlineDelimitedJSON, "", true)
	}

	if u.ParquetColumnarStorage != nil {
		return utils.MarshalJSON(u.ParquetColumnarStorage, "", true)
	}

	return nil, errors.New("could not marshal union type OutputFormatWildcard: all fields are null")
}

// ChooseHowToPartitionData - Partition data by cursor fields when a cursor field is a date
type ChooseHowToPartitionData string

const (
	ChooseHowToPartitionDataNoPartitioning ChooseHowToPartitionData = "NO PARTITIONING"
	ChooseHowToPartitionDataDate           ChooseHowToPartitionData = "DATE"
	ChooseHowToPartitionDataYear           ChooseHowToPartitionData = "YEAR"
	ChooseHowToPartitionDataMonth          ChooseHowToPartitionData = "MONTH"
	ChooseHowToPartitionDataDay            ChooseHowToPartitionData = "DAY"
	ChooseHowToPartitionDataYearMonth      ChooseHowToPartitionData = "YEAR/MONTH"
	ChooseHowToPartitionDataYearMonthDay   ChooseHowToPartitionData = "YEAR/MONTH/DAY"
)

func (e ChooseHowToPartitionData) ToPointer() *ChooseHowToPartitionData {
	return &e
}
func (e *ChooseHowToPartitionData) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "NO PARTITIONING":
		fallthrough
	case "DATE":
		fallthrough
	case "YEAR":
		fallthrough
	case "MONTH":
		fallthrough
	case "DAY":
		fallthrough
	case "YEAR/MONTH":
		fallthrough
	case "YEAR/MONTH/DAY":
		*e = ChooseHowToPartitionData(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ChooseHowToPartitionData: %v", v)
	}
}

// S3BucketRegion - The region of the S3 bucket. See <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">here</a> for all region codes.
type S3BucketRegion string

const (
	S3BucketRegionUnknown      S3BucketRegion = ""
	S3BucketRegionAfSouth1     S3BucketRegion = "af-south-1"
	S3BucketRegionApEast1      S3BucketRegion = "ap-east-1"
	S3BucketRegionApNortheast1 S3BucketRegion = "ap-northeast-1"
	S3BucketRegionApNortheast2 S3BucketRegion = "ap-northeast-2"
	S3BucketRegionApNortheast3 S3BucketRegion = "ap-northeast-3"
	S3BucketRegionApSouth1     S3BucketRegion = "ap-south-1"
	S3BucketRegionApSouth2     S3BucketRegion = "ap-south-2"
	S3BucketRegionApSoutheast1 S3BucketRegion = "ap-southeast-1"
	S3BucketRegionApSoutheast2 S3BucketRegion = "ap-southeast-2"
	S3BucketRegionApSoutheast3 S3BucketRegion = "ap-southeast-3"
	S3BucketRegionApSoutheast4 S3BucketRegion = "ap-southeast-4"
	S3BucketRegionCaCentral1   S3BucketRegion = "ca-central-1"
	S3BucketRegionCaWest1      S3BucketRegion = "ca-west-1"
	S3BucketRegionCnNorth1     S3BucketRegion = "cn-north-1"
	S3BucketRegionCnNorthwest1 S3BucketRegion = "cn-northwest-1"
	S3BucketRegionEuCentral1   S3BucketRegion = "eu-central-1"
	S3BucketRegionEuCentral2   S3BucketRegion = "eu-central-2"
	S3BucketRegionEuNorth1     S3BucketRegion = "eu-north-1"
	S3BucketRegionEuSouth1     S3BucketRegion = "eu-south-1"
	S3BucketRegionEuSouth2     S3BucketRegion = "eu-south-2"
	S3BucketRegionEuWest1      S3BucketRegion = "eu-west-1"
	S3BucketRegionEuWest2      S3BucketRegion = "eu-west-2"
	S3BucketRegionEuWest3      S3BucketRegion = "eu-west-3"
	S3BucketRegionIlCentral1   S3BucketRegion = "il-central-1"
	S3BucketRegionMeCentral1   S3BucketRegion = "me-central-1"
	S3BucketRegionMeSouth1     S3BucketRegion = "me-south-1"
	S3BucketRegionSaEast1      S3BucketRegion = "sa-east-1"
	S3BucketRegionUsEast1      S3BucketRegion = "us-east-1"
	S3BucketRegionUsEast2      S3BucketRegion = "us-east-2"
	S3BucketRegionUsGovEast1   S3BucketRegion = "us-gov-east-1"
	S3BucketRegionUsGovWest1   S3BucketRegion = "us-gov-west-1"
	S3BucketRegionUsWest1      S3BucketRegion = "us-west-1"
	S3BucketRegionUsWest2      S3BucketRegion = "us-west-2"
)

func (e S3BucketRegion) ToPointer() *S3BucketRegion {
	return &e
}
func (e *S3BucketRegion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "":
		fallthrough
	case "af-south-1":
		fallthrough
	case "ap-east-1":
		fallthrough
	case "ap-northeast-1":
		fallthrough
	case "ap-northeast-2":
		fallthrough
	case "ap-northeast-3":
		fallthrough
	case "ap-south-1":
		fallthrough
	case "ap-south-2":
		fallthrough
	case "ap-southeast-1":
		fallthrough
	case "ap-southeast-2":
		fallthrough
	case "ap-southeast-3":
		fallthrough
	case "ap-southeast-4":
		fallthrough
	case "ca-central-1":
		fallthrough
	case "ca-west-1":
		fallthrough
	case "cn-north-1":
		fallthrough
	case "cn-northwest-1":
		fallthrough
	case "eu-central-1":
		fallthrough
	case "eu-central-2":
		fallthrough
	case "eu-north-1":
		fallthrough
	case "eu-south-1":
		fallthrough
	case "eu-south-2":
		fallthrough
	case "eu-west-1":
		fallthrough
	case "eu-west-2":
		fallthrough
	case "eu-west-3":
		fallthrough
	case "il-central-1":
		fallthrough
	case "me-central-1":
		fallthrough
	case "me-south-1":
		fallthrough
	case "sa-east-1":
		fallthrough
	case "us-east-1":
		fallthrough
	case "us-east-2":
		fallthrough
	case "us-gov-east-1":
		fallthrough
	case "us-gov-west-1":
		fallthrough
	case "us-west-1":
		fallthrough
	case "us-west-2":
		*e = S3BucketRegion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for S3BucketRegion: %v", v)
	}
}

type DestinationAwsDatalakeDestinationType string

const (
	DestinationAwsDatalakeDestinationTypeAwsDatalake DestinationAwsDatalakeDestinationType = "aws-datalake"
)

func (e DestinationAwsDatalakeDestinationType) ToPointer() *DestinationAwsDatalakeDestinationType {
	return &e
}
func (e *DestinationAwsDatalakeDestinationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "aws-datalake":
		*e = DestinationAwsDatalakeDestinationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeDestinationType: %v", v)
	}
}

type DestinationAwsDatalake struct {
	// target aws account id
	AwsAccountID *string `json:"aws_account_id,omitempty"`
	// The name of the S3 bucket. Read more <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html">here</a>.
	BucketName string `json:"bucket_name"`
	// S3 prefix
	BucketPrefix *string `json:"bucket_prefix,omitempty"`
	// Choose How to Authenticate to AWS.
	Credentials AuthenticationMode `json:"credentials"`
	// Format of the data output.
	Format *OutputFormatWildcard `json:"format,omitempty"`
	// Cast float/double as decimal(38,18). This can help achieve higher accuracy and represent numbers correctly as received from the source.
	GlueCatalogFloatAsDecimal *bool `default:"false" json:"glue_catalog_float_as_decimal"`
	// Add a default tag key to databases created by this destination
	LakeformationDatabaseDefaultTagKey *string `json:"lakeformation_database_default_tag_key,omitempty"`
	// Add default values for the `Tag Key` to databases created by this destination. Comma separate for multiple values.
	LakeformationDatabaseDefaultTagValues *string `json:"lakeformation_database_default_tag_values,omitempty"`
	// The default database this destination will use to create tables in per stream. Can be changed per connection by customizing the namespace.
	LakeformationDatabaseName string `json:"lakeformation_database_name"`
	// Whether to create tables as LF governed tables.
	LakeformationGovernedTables *bool `default:"false" json:"lakeformation_governed_tables"`
	// Partition data by cursor fields when a cursor field is a date
	Partitioning *ChooseHowToPartitionData `default:"NO PARTITIONING" json:"partitioning"`
	// The region of the S3 bucket. See <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">here</a> for all region codes.
	Region          *S3BucketRegion                        `default:"" json:"region"`
	destinationType *DestinationAwsDatalakeDestinationType `const:"aws-datalake" json:"destinationType"`
}

func (d DestinationAwsDatalake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationAwsDatalake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationAwsDatalake) GetAwsAccountID() *string {
	if d == nil {
		return nil
	}
	return d.AwsAccountID
}

func (d *DestinationAwsDatalake) GetBucketName() string {
	if d == nil {
		return ""
	}
	return d.BucketName
}

func (d *DestinationAwsDatalake) GetBucketPrefix() *string {
	if d == nil {
		return nil
	}
	return d.BucketPrefix
}

func (d *DestinationAwsDatalake) GetCredentials() AuthenticationMode {
	if d == nil {
		return AuthenticationMode{}
	}
	return d.Credentials
}

func (d *DestinationAwsDatalake) GetFormat() *OutputFormatWildcard {
	if d == nil {
		return nil
	}
	return d.Format
}

func (d *DestinationAwsDatalake) GetGlueCatalogFloatAsDecimal() *bool {
	if d == nil {
		return nil
	}
	return d.GlueCatalogFloatAsDecimal
}

func (d *DestinationAwsDatalake) GetLakeformationDatabaseDefaultTagKey() *string {
	if d == nil {
		return nil
	}
	return d.LakeformationDatabaseDefaultTagKey
}

func (d *DestinationAwsDatalake) GetLakeformationDatabaseDefaultTagValues() *string {
	if d == nil {
		return nil
	}
	return d.LakeformationDatabaseDefaultTagValues
}

func (d *DestinationAwsDatalake) GetLakeformationDatabaseName() string {
	if d == nil {
		return ""
	}
	return d.LakeformationDatabaseName
}

func (d *DestinationAwsDatalake) GetLakeformationGovernedTables() *bool {
	if d == nil {
		return nil
	}
	return d.LakeformationGovernedTables
}

func (d *DestinationAwsDatalake) GetPartitioning() *ChooseHowToPartitionData {
	if d == nil {
		return nil
	}
	return d.Partitioning
}

func (d *DestinationAwsDatalake) GetRegion() *S3BucketRegion {
	if d == nil {
		return nil
	}
	return d.Region
}

func (d *DestinationAwsDatalake) GetDestinationType() *DestinationAwsDatalakeDestinationType {
	return DestinationAwsDatalakeDestinationTypeAwsDatalake.ToPointer()
}
