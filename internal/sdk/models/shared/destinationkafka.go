// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/internal/utils"
)

// ACKs - The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the  durability of records that are sent.
type ACKs string

const (
	ACKsZero ACKs = "0"
	ACKsOne  ACKs = "1"
	ACKsAll  ACKs = "all"
)

func (e ACKs) ToPointer() *ACKs {
	return &e
}
func (e *ACKs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "0":
		fallthrough
	case "1":
		fallthrough
	case "all":
		*e = ACKs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ACKs: %v", v)
	}
}

// DestinationKafkaClientDNSLookup - Controls how the client uses DNS lookups. If set to use_all_dns_ips, connect to each returned IP address in sequence until a successful connection is established. After a disconnection, the next IP is used. Once all IPs have been used once, the client resolves the IP(s) from the hostname again. If set to resolve_canonical_bootstrap_servers_only, resolve each bootstrap address into a list of canonical names. After the bootstrap phase, this behaves the same as use_all_dns_ips. If set to default (deprecated), attempt to connect to the first IP address returned by the lookup, even if the lookup returns multiple IP addresses.
type DestinationKafkaClientDNSLookup string

const (
	DestinationKafkaClientDNSLookupDefault                              DestinationKafkaClientDNSLookup = "default"
	DestinationKafkaClientDNSLookupUseAllDNSIps                         DestinationKafkaClientDNSLookup = "use_all_dns_ips"
	DestinationKafkaClientDNSLookupResolveCanonicalBootstrapServersOnly DestinationKafkaClientDNSLookup = "resolve_canonical_bootstrap_servers_only"
)

func (e DestinationKafkaClientDNSLookup) ToPointer() *DestinationKafkaClientDNSLookup {
	return &e
}
func (e *DestinationKafkaClientDNSLookup) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "default":
		fallthrough
	case "use_all_dns_ips":
		fallthrough
	case "resolve_canonical_bootstrap_servers_only":
		*e = DestinationKafkaClientDNSLookup(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationKafkaClientDNSLookup: %v", v)
	}
}

// CompressionType - The compression type for all data generated by the producer.
type CompressionType string

const (
	CompressionTypeNone   CompressionType = "none"
	CompressionTypeGzip   CompressionType = "gzip"
	CompressionTypeSnappy CompressionType = "snappy"
	CompressionTypeLz4    CompressionType = "lz4"
	CompressionTypeZstd   CompressionType = "zstd"
)

func (e CompressionType) ToPointer() *CompressionType {
	return &e
}
func (e *CompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		fallthrough
	case "snappy":
		fallthrough
	case "lz4":
		fallthrough
	case "zstd":
		*e = CompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionType: %v", v)
	}
}

// DestinationKafkaSchemasSASLMechanism - SASL mechanism used for client connections. This may be any mechanism for which a security provider is available.
type DestinationKafkaSchemasSASLMechanism string

const (
	DestinationKafkaSchemasSASLMechanismGssapi      DestinationKafkaSchemasSASLMechanism = "GSSAPI"
	DestinationKafkaSchemasSASLMechanismOauthbearer DestinationKafkaSchemasSASLMechanism = "OAUTHBEARER"
	DestinationKafkaSchemasSASLMechanismScramSha256 DestinationKafkaSchemasSASLMechanism = "SCRAM-SHA-256"
	DestinationKafkaSchemasSASLMechanismScramSha512 DestinationKafkaSchemasSASLMechanism = "SCRAM-SHA-512"
	DestinationKafkaSchemasSASLMechanismPlain       DestinationKafkaSchemasSASLMechanism = "PLAIN"
)

func (e DestinationKafkaSchemasSASLMechanism) ToPointer() *DestinationKafkaSchemasSASLMechanism {
	return &e
}
func (e *DestinationKafkaSchemasSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GSSAPI":
		fallthrough
	case "OAUTHBEARER":
		fallthrough
	case "SCRAM-SHA-256":
		fallthrough
	case "SCRAM-SHA-512":
		fallthrough
	case "PLAIN":
		*e = DestinationKafkaSchemasSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationKafkaSchemasSASLMechanism: %v", v)
	}
}

type DestinationKafkaSchemasSecurityProtocol string

const (
	DestinationKafkaSchemasSecurityProtocolSaslSsl DestinationKafkaSchemasSecurityProtocol = "SASL_SSL"
)

func (e DestinationKafkaSchemasSecurityProtocol) ToPointer() *DestinationKafkaSchemasSecurityProtocol {
	return &e
}
func (e *DestinationKafkaSchemasSecurityProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SASL_SSL":
		*e = DestinationKafkaSchemasSecurityProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationKafkaSchemasSecurityProtocol: %v", v)
	}
}

type DestinationKafkaSASLSSL struct {
	// JAAS login context parameters for SASL connections in the format used by JAAS configuration files.
	SaslJaasConfig *string `default:"" json:"sasl_jaas_config"`
	// SASL mechanism used for client connections. This may be any mechanism for which a security provider is available.
	SaslMechanism    *DestinationKafkaSchemasSASLMechanism    `default:"GSSAPI" json:"sasl_mechanism"`
	SecurityProtocol *DestinationKafkaSchemasSecurityProtocol `default:"SASL_SSL" json:"security_protocol"`
}

func (d DestinationKafkaSASLSSL) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationKafkaSASLSSL) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationKafkaSASLSSL) GetSaslJaasConfig() *string {
	if d == nil {
		return nil
	}
	return d.SaslJaasConfig
}

func (d *DestinationKafkaSASLSSL) GetSaslMechanism() *DestinationKafkaSchemasSASLMechanism {
	if d == nil {
		return nil
	}
	return d.SaslMechanism
}

func (d *DestinationKafkaSASLSSL) GetSecurityProtocol() *DestinationKafkaSchemasSecurityProtocol {
	if d == nil {
		return nil
	}
	return d.SecurityProtocol
}

// DestinationKafkaSASLMechanism - SASL mechanism used for client connections. This may be any mechanism for which a security provider is available.
type DestinationKafkaSASLMechanism string

const (
	DestinationKafkaSASLMechanismGssapi      DestinationKafkaSASLMechanism = "GSSAPI"
	DestinationKafkaSASLMechanismOauthbearer DestinationKafkaSASLMechanism = "OAUTHBEARER"
	DestinationKafkaSASLMechanismScramSha256 DestinationKafkaSASLMechanism = "SCRAM-SHA-256"
	DestinationKafkaSASLMechanismScramSha512 DestinationKafkaSASLMechanism = "SCRAM-SHA-512"
	DestinationKafkaSASLMechanismPlain       DestinationKafkaSASLMechanism = "PLAIN"
)

func (e DestinationKafkaSASLMechanism) ToPointer() *DestinationKafkaSASLMechanism {
	return &e
}
func (e *DestinationKafkaSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GSSAPI":
		fallthrough
	case "OAUTHBEARER":
		fallthrough
	case "SCRAM-SHA-256":
		fallthrough
	case "SCRAM-SHA-512":
		fallthrough
	case "PLAIN":
		*e = DestinationKafkaSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationKafkaSASLMechanism: %v", v)
	}
}

type DestinationKafkaSecurityProtocol string

const (
	DestinationKafkaSecurityProtocolSaslPlaintext DestinationKafkaSecurityProtocol = "SASL_PLAINTEXT"
)

func (e DestinationKafkaSecurityProtocol) ToPointer() *DestinationKafkaSecurityProtocol {
	return &e
}
func (e *DestinationKafkaSecurityProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SASL_PLAINTEXT":
		*e = DestinationKafkaSecurityProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationKafkaSecurityProtocol: %v", v)
	}
}

type DestinationKafkaSASLPLAINTEXT struct {
	// JAAS login context parameters for SASL connections in the format used by JAAS configuration files.
	SaslJaasConfig *string `default:"" json:"sasl_jaas_config"`
	// SASL mechanism used for client connections. This may be any mechanism for which a security provider is available.
	SaslMechanism    *DestinationKafkaSASLMechanism    `default:"PLAIN" json:"sasl_mechanism"`
	SecurityProtocol *DestinationKafkaSecurityProtocol `default:"SASL_PLAINTEXT" json:"security_protocol"`
}

func (d DestinationKafkaSASLPLAINTEXT) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationKafkaSASLPLAINTEXT) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationKafkaSASLPLAINTEXT) GetSaslJaasConfig() *string {
	if d == nil {
		return nil
	}
	return d.SaslJaasConfig
}

func (d *DestinationKafkaSASLPLAINTEXT) GetSaslMechanism() *DestinationKafkaSASLMechanism {
	if d == nil {
		return nil
	}
	return d.SaslMechanism
}

func (d *DestinationKafkaSASLPLAINTEXT) GetSecurityProtocol() *DestinationKafkaSecurityProtocol {
	if d == nil {
		return nil
	}
	return d.SecurityProtocol
}

type SecurityProtocol string

const (
	SecurityProtocolPlaintext SecurityProtocol = "PLAINTEXT"
)

func (e SecurityProtocol) ToPointer() *SecurityProtocol {
	return &e
}
func (e *SecurityProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PLAINTEXT":
		*e = SecurityProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SecurityProtocol: %v", v)
	}
}

type DestinationKafkaPLAINTEXT struct {
	SecurityProtocol *SecurityProtocol `default:"PLAINTEXT" json:"security_protocol"`
}

func (d DestinationKafkaPLAINTEXT) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationKafkaPLAINTEXT) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationKafkaPLAINTEXT) GetSecurityProtocol() *SecurityProtocol {
	if d == nil {
		return nil
	}
	return d.SecurityProtocol
}

type DestinationKafkaProtocolType string

const (
	DestinationKafkaProtocolTypeDestinationKafkaPLAINTEXT     DestinationKafkaProtocolType = "destination-kafka_PLAINTEXT"
	DestinationKafkaProtocolTypeDestinationKafkaSASLPLAINTEXT DestinationKafkaProtocolType = "destination-kafka_SASL PLAINTEXT"
	DestinationKafkaProtocolTypeDestinationKafkaSASLSSL       DestinationKafkaProtocolType = "destination-kafka_SASL SSL"
)

// DestinationKafkaProtocol - Protocol used to communicate with brokers.
type DestinationKafkaProtocol struct {
	DestinationKafkaPLAINTEXT     *DestinationKafkaPLAINTEXT     `queryParam:"inline" union:"member"`
	DestinationKafkaSASLPLAINTEXT *DestinationKafkaSASLPLAINTEXT `queryParam:"inline" union:"member"`
	DestinationKafkaSASLSSL       *DestinationKafkaSASLSSL       `queryParam:"inline" union:"member"`

	Type DestinationKafkaProtocolType
}

func CreateDestinationKafkaProtocolDestinationKafkaPLAINTEXT(destinationKafkaPLAINTEXT DestinationKafkaPLAINTEXT) DestinationKafkaProtocol {
	typ := DestinationKafkaProtocolTypeDestinationKafkaPLAINTEXT

	return DestinationKafkaProtocol{
		DestinationKafkaPLAINTEXT: &destinationKafkaPLAINTEXT,
		Type:                      typ,
	}
}

func CreateDestinationKafkaProtocolDestinationKafkaSASLPLAINTEXT(destinationKafkaSASLPLAINTEXT DestinationKafkaSASLPLAINTEXT) DestinationKafkaProtocol {
	typ := DestinationKafkaProtocolTypeDestinationKafkaSASLPLAINTEXT

	return DestinationKafkaProtocol{
		DestinationKafkaSASLPLAINTEXT: &destinationKafkaSASLPLAINTEXT,
		Type:                          typ,
	}
}

func CreateDestinationKafkaProtocolDestinationKafkaSASLSSL(destinationKafkaSASLSSL DestinationKafkaSASLSSL) DestinationKafkaProtocol {
	typ := DestinationKafkaProtocolTypeDestinationKafkaSASLSSL

	return DestinationKafkaProtocol{
		DestinationKafkaSASLSSL: &destinationKafkaSASLSSL,
		Type:                    typ,
	}
}

func (u *DestinationKafkaProtocol) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var destinationKafkaPLAINTEXT DestinationKafkaPLAINTEXT = DestinationKafkaPLAINTEXT{}
	if err := utils.UnmarshalJSON(data, &destinationKafkaPLAINTEXT, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationKafkaProtocolTypeDestinationKafkaPLAINTEXT,
			Value: &destinationKafkaPLAINTEXT,
		})
	}

	var destinationKafkaSASLPLAINTEXT DestinationKafkaSASLPLAINTEXT = DestinationKafkaSASLPLAINTEXT{}
	if err := utils.UnmarshalJSON(data, &destinationKafkaSASLPLAINTEXT, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationKafkaProtocolTypeDestinationKafkaSASLPLAINTEXT,
			Value: &destinationKafkaSASLPLAINTEXT,
		})
	}

	var destinationKafkaSASLSSL DestinationKafkaSASLSSL = DestinationKafkaSASLSSL{}
	if err := utils.UnmarshalJSON(data, &destinationKafkaSASLSSL, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  DestinationKafkaProtocolTypeDestinationKafkaSASLSSL,
			Value: &destinationKafkaSASLSSL,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationKafkaProtocol", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationKafkaProtocol", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(DestinationKafkaProtocolType)
	switch best.Type {
	case DestinationKafkaProtocolTypeDestinationKafkaPLAINTEXT:
		u.DestinationKafkaPLAINTEXT = best.Value.(*DestinationKafkaPLAINTEXT)
		return nil
	case DestinationKafkaProtocolTypeDestinationKafkaSASLPLAINTEXT:
		u.DestinationKafkaSASLPLAINTEXT = best.Value.(*DestinationKafkaSASLPLAINTEXT)
		return nil
	case DestinationKafkaProtocolTypeDestinationKafkaSASLSSL:
		u.DestinationKafkaSASLSSL = best.Value.(*DestinationKafkaSASLSSL)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for DestinationKafkaProtocol", string(data))
}

func (u DestinationKafkaProtocol) MarshalJSON() ([]byte, error) {
	if u.DestinationKafkaPLAINTEXT != nil {
		return utils.MarshalJSON(u.DestinationKafkaPLAINTEXT, "", true)
	}

	if u.DestinationKafkaSASLPLAINTEXT != nil {
		return utils.MarshalJSON(u.DestinationKafkaSASLPLAINTEXT, "", true)
	}

	if u.DestinationKafkaSASLSSL != nil {
		return utils.MarshalJSON(u.DestinationKafkaSASLSSL, "", true)
	}

	return nil, errors.New("could not marshal union type DestinationKafkaProtocol: all fields are null")
}

type DestinationKafkaDestinationType string

const (
	DestinationKafkaDestinationTypeKafka DestinationKafkaDestinationType = "kafka"
)

func (e DestinationKafkaDestinationType) ToPointer() *DestinationKafkaDestinationType {
	return &e
}
func (e *DestinationKafkaDestinationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = DestinationKafkaDestinationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationKafkaDestinationType: %v", v)
	}
}

type DestinationKafka struct {
	// The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the  durability of records that are sent.
	Acks *ACKs `default:"1" json:"acks"`
	// The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition.
	BatchSize int64 `json:"batch_size"`
	// A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. The client will make use of all servers irrespective of which servers are specified here for bootstrapping&mdash;this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form <code>host1:port1,host2:port2,...</code>. Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically), this list need not contain the full set of servers (you may want more than one, though, in case a server is down).
	BootstrapServers string `json:"bootstrap_servers"`
	// The total bytes of memory the producer can use to buffer records waiting to be sent to the server.
	BufferMemory string `json:"buffer_memory"`
	// Controls how the client uses DNS lookups. If set to use_all_dns_ips, connect to each returned IP address in sequence until a successful connection is established. After a disconnection, the next IP is used. Once all IPs have been used once, the client resolves the IP(s) from the hostname again. If set to resolve_canonical_bootstrap_servers_only, resolve each bootstrap address into a list of canonical names. After the bootstrap phase, this behaves the same as use_all_dns_ips. If set to default (deprecated), attempt to connect to the first IP address returned by the lookup, even if the lookup returns multiple IP addresses.
	ClientDNSLookup *DestinationKafkaClientDNSLookup `default:"use_all_dns_ips" json:"client_dns_lookup"`
	// An ID string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging.
	ClientID *string `json:"client_id,omitempty"`
	// The compression type for all data generated by the producer.
	CompressionType *CompressionType `default:"none" json:"compression_type"`
	// An upper bound on the time to report success or failure after a call to 'send()' returns.
	DeliveryTimeoutMs int64 `json:"delivery_timeout_ms"`
	// When set to 'true', the producer will ensure that exactly one copy of each message is written in the stream. If 'false', producer retries due to broker failures, etc., may write duplicates of the retried message in the stream.
	EnableIdempotence *bool `default:"false" json:"enable_idempotence"`
	// The producer groups together any records that arrive in between request transmissions into a single batched request.
	LingerMs string `json:"linger_ms"`
	// The configuration controls how long the KafkaProducer's send(), partitionsFor(), initTransactions(), sendOffsetsToTransaction(), commitTransaction() and abortTransaction() methods will block.
	MaxBlockMs string `json:"max_block_ms"`
	// The maximum number of unacknowledged requests the client will send on a single connection before blocking. Can be greater than 1, and the maximum value supported with idempotency is 5.
	MaxInFlightRequestsPerConnection int64 `json:"max_in_flight_requests_per_connection"`
	// The maximum size of a request in bytes.
	MaxRequestSize int64 `json:"max_request_size"`
	// Protocol used to communicate with brokers.
	Protocol DestinationKafkaProtocol `json:"protocol"`
	// The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.
	ReceiveBufferBytes int64 `json:"receive_buffer_bytes"`
	// The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.
	RequestTimeoutMs int64 `json:"request_timeout_ms"`
	// Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error.
	Retries int64 `json:"retries"`
	// The size of the TCP send buffer (SO_SNDBUF) to use when sending data. If the value is -1, the OS default will be used.
	SendBufferBytes int64 `json:"send_buffer_bytes"`
	// The maximum amount of time the client will wait for the socket connection to be established. The connection setup timeout will increase exponentially for each consecutive connection failure up to this maximum.
	SocketConnectionSetupTimeoutMaxMs string `json:"socket_connection_setup_timeout_max_ms"`
	// The amount of time the client will wait for the socket connection to be established.
	SocketConnectionSetupTimeoutMs string `json:"socket_connection_setup_timeout_ms"`
	// Wait synchronously until the record has been sent to Kafka.
	SyncProducer *bool `default:"false" json:"sync_producer"`
	// Topic to test if Airbyte can produce messages.
	TestTopic *string `json:"test_topic,omitempty"`
	// Topic pattern in which the records will be sent. You can use patterns like '{namespace}' and/or '{stream}' to send the message to a specific topic based on these values. Notice that the topic name will be transformed to a standard naming convention.
	TopicPattern         string                           `json:"topic_pattern"`
	destinationType      *DestinationKafkaDestinationType `const:"kafka" json:"destinationType"`
	AdditionalProperties any                              `additionalProperties:"true" json:"-"`
}

func (d DestinationKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DestinationKafka) GetAcks() *ACKs {
	if d == nil {
		return nil
	}
	return d.Acks
}

func (d *DestinationKafka) GetBatchSize() int64 {
	if d == nil {
		return 0
	}
	return d.BatchSize
}

func (d *DestinationKafka) GetBootstrapServers() string {
	if d == nil {
		return ""
	}
	return d.BootstrapServers
}

func (d *DestinationKafka) GetBufferMemory() string {
	if d == nil {
		return ""
	}
	return d.BufferMemory
}

func (d *DestinationKafka) GetClientDNSLookup() *DestinationKafkaClientDNSLookup {
	if d == nil {
		return nil
	}
	return d.ClientDNSLookup
}

func (d *DestinationKafka) GetClientID() *string {
	if d == nil {
		return nil
	}
	return d.ClientID
}

func (d *DestinationKafka) GetCompressionType() *CompressionType {
	if d == nil {
		return nil
	}
	return d.CompressionType
}

func (d *DestinationKafka) GetDeliveryTimeoutMs() int64 {
	if d == nil {
		return 0
	}
	return d.DeliveryTimeoutMs
}

func (d *DestinationKafka) GetEnableIdempotence() *bool {
	if d == nil {
		return nil
	}
	return d.EnableIdempotence
}

func (d *DestinationKafka) GetLingerMs() string {
	if d == nil {
		return ""
	}
	return d.LingerMs
}

func (d *DestinationKafka) GetMaxBlockMs() string {
	if d == nil {
		return ""
	}
	return d.MaxBlockMs
}

func (d *DestinationKafka) GetMaxInFlightRequestsPerConnection() int64 {
	if d == nil {
		return 0
	}
	return d.MaxInFlightRequestsPerConnection
}

func (d *DestinationKafka) GetMaxRequestSize() int64 {
	if d == nil {
		return 0
	}
	return d.MaxRequestSize
}

func (d *DestinationKafka) GetProtocol() DestinationKafkaProtocol {
	if d == nil {
		return DestinationKafkaProtocol{}
	}
	return d.Protocol
}

func (d *DestinationKafka) GetReceiveBufferBytes() int64 {
	if d == nil {
		return 0
	}
	return d.ReceiveBufferBytes
}

func (d *DestinationKafka) GetRequestTimeoutMs() int64 {
	if d == nil {
		return 0
	}
	return d.RequestTimeoutMs
}

func (d *DestinationKafka) GetRetries() int64 {
	if d == nil {
		return 0
	}
	return d.Retries
}

func (d *DestinationKafka) GetSendBufferBytes() int64 {
	if d == nil {
		return 0
	}
	return d.SendBufferBytes
}

func (d *DestinationKafka) GetSocketConnectionSetupTimeoutMaxMs() string {
	if d == nil {
		return ""
	}
	return d.SocketConnectionSetupTimeoutMaxMs
}

func (d *DestinationKafka) GetSocketConnectionSetupTimeoutMs() string {
	if d == nil {
		return ""
	}
	return d.SocketConnectionSetupTimeoutMs
}

func (d *DestinationKafka) GetSyncProducer() *bool {
	if d == nil {
		return nil
	}
	return d.SyncProducer
}

func (d *DestinationKafka) GetTestTopic() *string {
	if d == nil {
		return nil
	}
	return d.TestTopic
}

func (d *DestinationKafka) GetTopicPattern() string {
	if d == nil {
		return ""
	}
	return d.TopicPattern
}

func (d *DestinationKafka) GetDestinationType() *DestinationKafkaDestinationType {
	return DestinationKafkaDestinationTypeKafka.ToPointer()
}

func (d *DestinationKafka) GetAdditionalProperties() any {
	if d == nil {
		return nil
	}
	return d.AdditionalProperties
}
