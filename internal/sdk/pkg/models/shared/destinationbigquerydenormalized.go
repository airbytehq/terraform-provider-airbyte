// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/pkg/utils"
)

// DestinationBigqueryDenormalizedDatasetLocation - The location of the dataset. Warning: Changes made after creation will not be applied. The default "US" value is used if not set explicitly. Read more <a href="https://cloud.google.com/bigquery/docs/locations">here</a>.
type DestinationBigqueryDenormalizedDatasetLocation string

const (
	DestinationBigqueryDenormalizedDatasetLocationUs                     DestinationBigqueryDenormalizedDatasetLocation = "US"
	DestinationBigqueryDenormalizedDatasetLocationEu                     DestinationBigqueryDenormalizedDatasetLocation = "EU"
	DestinationBigqueryDenormalizedDatasetLocationAsiaEast1              DestinationBigqueryDenormalizedDatasetLocation = "asia-east1"
	DestinationBigqueryDenormalizedDatasetLocationAsiaEast2              DestinationBigqueryDenormalizedDatasetLocation = "asia-east2"
	DestinationBigqueryDenormalizedDatasetLocationAsiaNortheast1         DestinationBigqueryDenormalizedDatasetLocation = "asia-northeast1"
	DestinationBigqueryDenormalizedDatasetLocationAsiaNortheast2         DestinationBigqueryDenormalizedDatasetLocation = "asia-northeast2"
	DestinationBigqueryDenormalizedDatasetLocationAsiaNortheast3         DestinationBigqueryDenormalizedDatasetLocation = "asia-northeast3"
	DestinationBigqueryDenormalizedDatasetLocationAsiaSouth1             DestinationBigqueryDenormalizedDatasetLocation = "asia-south1"
	DestinationBigqueryDenormalizedDatasetLocationAsiaSouth2             DestinationBigqueryDenormalizedDatasetLocation = "asia-south2"
	DestinationBigqueryDenormalizedDatasetLocationAsiaSoutheast1         DestinationBigqueryDenormalizedDatasetLocation = "asia-southeast1"
	DestinationBigqueryDenormalizedDatasetLocationAsiaSoutheast2         DestinationBigqueryDenormalizedDatasetLocation = "asia-southeast2"
	DestinationBigqueryDenormalizedDatasetLocationAustraliaSoutheast1    DestinationBigqueryDenormalizedDatasetLocation = "australia-southeast1"
	DestinationBigqueryDenormalizedDatasetLocationAustraliaSoutheast2    DestinationBigqueryDenormalizedDatasetLocation = "australia-southeast2"
	DestinationBigqueryDenormalizedDatasetLocationEuropeCentral1         DestinationBigqueryDenormalizedDatasetLocation = "europe-central1"
	DestinationBigqueryDenormalizedDatasetLocationEuropeCentral2         DestinationBigqueryDenormalizedDatasetLocation = "europe-central2"
	DestinationBigqueryDenormalizedDatasetLocationEuropeNorth1           DestinationBigqueryDenormalizedDatasetLocation = "europe-north1"
	DestinationBigqueryDenormalizedDatasetLocationEuropeSouthwest1       DestinationBigqueryDenormalizedDatasetLocation = "europe-southwest1"
	DestinationBigqueryDenormalizedDatasetLocationEuropeWest1            DestinationBigqueryDenormalizedDatasetLocation = "europe-west1"
	DestinationBigqueryDenormalizedDatasetLocationEuropeWest2            DestinationBigqueryDenormalizedDatasetLocation = "europe-west2"
	DestinationBigqueryDenormalizedDatasetLocationEuropeWest3            DestinationBigqueryDenormalizedDatasetLocation = "europe-west3"
	DestinationBigqueryDenormalizedDatasetLocationEuropeWest4            DestinationBigqueryDenormalizedDatasetLocation = "europe-west4"
	DestinationBigqueryDenormalizedDatasetLocationEuropeWest6            DestinationBigqueryDenormalizedDatasetLocation = "europe-west6"
	DestinationBigqueryDenormalizedDatasetLocationEuropeWest7            DestinationBigqueryDenormalizedDatasetLocation = "europe-west7"
	DestinationBigqueryDenormalizedDatasetLocationEuropeWest8            DestinationBigqueryDenormalizedDatasetLocation = "europe-west8"
	DestinationBigqueryDenormalizedDatasetLocationEuropeWest9            DestinationBigqueryDenormalizedDatasetLocation = "europe-west9"
	DestinationBigqueryDenormalizedDatasetLocationMeWest1                DestinationBigqueryDenormalizedDatasetLocation = "me-west1"
	DestinationBigqueryDenormalizedDatasetLocationNorthamericaNortheast1 DestinationBigqueryDenormalizedDatasetLocation = "northamerica-northeast1"
	DestinationBigqueryDenormalizedDatasetLocationNorthamericaNortheast2 DestinationBigqueryDenormalizedDatasetLocation = "northamerica-northeast2"
	DestinationBigqueryDenormalizedDatasetLocationSouthamericaEast1      DestinationBigqueryDenormalizedDatasetLocation = "southamerica-east1"
	DestinationBigqueryDenormalizedDatasetLocationSouthamericaWest1      DestinationBigqueryDenormalizedDatasetLocation = "southamerica-west1"
	DestinationBigqueryDenormalizedDatasetLocationUsCentral1             DestinationBigqueryDenormalizedDatasetLocation = "us-central1"
	DestinationBigqueryDenormalizedDatasetLocationUsEast1                DestinationBigqueryDenormalizedDatasetLocation = "us-east1"
	DestinationBigqueryDenormalizedDatasetLocationUsEast2                DestinationBigqueryDenormalizedDatasetLocation = "us-east2"
	DestinationBigqueryDenormalizedDatasetLocationUsEast3                DestinationBigqueryDenormalizedDatasetLocation = "us-east3"
	DestinationBigqueryDenormalizedDatasetLocationUsEast4                DestinationBigqueryDenormalizedDatasetLocation = "us-east4"
	DestinationBigqueryDenormalizedDatasetLocationUsEast5                DestinationBigqueryDenormalizedDatasetLocation = "us-east5"
	DestinationBigqueryDenormalizedDatasetLocationUsWest1                DestinationBigqueryDenormalizedDatasetLocation = "us-west1"
	DestinationBigqueryDenormalizedDatasetLocationUsWest2                DestinationBigqueryDenormalizedDatasetLocation = "us-west2"
	DestinationBigqueryDenormalizedDatasetLocationUsWest3                DestinationBigqueryDenormalizedDatasetLocation = "us-west3"
	DestinationBigqueryDenormalizedDatasetLocationUsWest4                DestinationBigqueryDenormalizedDatasetLocation = "us-west4"
)

func (e DestinationBigqueryDenormalizedDatasetLocation) ToPointer() *DestinationBigqueryDenormalizedDatasetLocation {
	return &e
}

func (e *DestinationBigqueryDenormalizedDatasetLocation) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "US":
		fallthrough
	case "EU":
		fallthrough
	case "asia-east1":
		fallthrough
	case "asia-east2":
		fallthrough
	case "asia-northeast1":
		fallthrough
	case "asia-northeast2":
		fallthrough
	case "asia-northeast3":
		fallthrough
	case "asia-south1":
		fallthrough
	case "asia-south2":
		fallthrough
	case "asia-southeast1":
		fallthrough
	case "asia-southeast2":
		fallthrough
	case "australia-southeast1":
		fallthrough
	case "australia-southeast2":
		fallthrough
	case "europe-central1":
		fallthrough
	case "europe-central2":
		fallthrough
	case "europe-north1":
		fallthrough
	case "europe-southwest1":
		fallthrough
	case "europe-west1":
		fallthrough
	case "europe-west2":
		fallthrough
	case "europe-west3":
		fallthrough
	case "europe-west4":
		fallthrough
	case "europe-west6":
		fallthrough
	case "europe-west7":
		fallthrough
	case "europe-west8":
		fallthrough
	case "europe-west9":
		fallthrough
	case "me-west1":
		fallthrough
	case "northamerica-northeast1":
		fallthrough
	case "northamerica-northeast2":
		fallthrough
	case "southamerica-east1":
		fallthrough
	case "southamerica-west1":
		fallthrough
	case "us-central1":
		fallthrough
	case "us-east1":
		fallthrough
	case "us-east2":
		fallthrough
	case "us-east3":
		fallthrough
	case "us-east4":
		fallthrough
	case "us-east5":
		fallthrough
	case "us-west1":
		fallthrough
	case "us-west2":
		fallthrough
	case "us-west3":
		fallthrough
	case "us-west4":
		*e = DestinationBigqueryDenormalizedDatasetLocation(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryDenormalizedDatasetLocation: %v", v)
	}
}

type BigqueryDenormalized string

const (
	BigqueryDenormalizedBigqueryDenormalized BigqueryDenormalized = "bigquery-denormalized"
)

func (e BigqueryDenormalized) ToPointer() *BigqueryDenormalized {
	return &e
}

func (e *BigqueryDenormalized) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "bigquery-denormalized":
		*e = BigqueryDenormalized(v)
		return nil
	default:
		return fmt.Errorf("invalid value for BigqueryDenormalized: %v", v)
	}
}

type DestinationBigqueryDenormalizedCredentialType string

const (
	DestinationBigqueryDenormalizedCredentialTypeHmacKey DestinationBigqueryDenormalizedCredentialType = "HMAC_KEY"
)

func (e DestinationBigqueryDenormalizedCredentialType) ToPointer() *DestinationBigqueryDenormalizedCredentialType {
	return &e
}

func (e *DestinationBigqueryDenormalizedCredentialType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "HMAC_KEY":
		*e = DestinationBigqueryDenormalizedCredentialType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryDenormalizedCredentialType: %v", v)
	}
}

// DestinationBigqueryDenormalizedHMACKey - An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys">here</a>.
type DestinationBigqueryDenormalizedHMACKey struct {
	credentialType DestinationBigqueryDenormalizedCredentialType `const:"HMAC_KEY" json:"credential_type"`
	// HMAC key access ID. When linked to a service account, this ID is 61 characters long; when linked to a user account, it is 24 characters long.
	HmacKeyAccessID string `json:"hmac_key_access_id"`
	// The corresponding secret for the access ID. It is a 40-character base-64 encoded string.
	HmacKeySecret string `json:"hmac_key_secret"`
}

func (d DestinationBigqueryDenormalizedHMACKey) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationBigqueryDenormalizedHMACKey) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationBigqueryDenormalizedHMACKey) GetCredentialType() DestinationBigqueryDenormalizedCredentialType {
	return DestinationBigqueryDenormalizedCredentialTypeHmacKey
}

func (o *DestinationBigqueryDenormalizedHMACKey) GetHmacKeyAccessID() string {
	if o == nil {
		return ""
	}
	return o.HmacKeyAccessID
}

func (o *DestinationBigqueryDenormalizedHMACKey) GetHmacKeySecret() string {
	if o == nil {
		return ""
	}
	return o.HmacKeySecret
}

type DestinationBigqueryDenormalizedCredentialUnionType string

const (
	DestinationBigqueryDenormalizedCredentialUnionTypeDestinationBigqueryDenormalizedHMACKey DestinationBigqueryDenormalizedCredentialUnionType = "destination-bigquery-denormalized_HMAC key"
)

type DestinationBigqueryDenormalizedCredential struct {
	DestinationBigqueryDenormalizedHMACKey *DestinationBigqueryDenormalizedHMACKey

	Type DestinationBigqueryDenormalizedCredentialUnionType
}

func CreateDestinationBigqueryDenormalizedCredentialDestinationBigqueryDenormalizedHMACKey(destinationBigqueryDenormalizedHMACKey DestinationBigqueryDenormalizedHMACKey) DestinationBigqueryDenormalizedCredential {
	typ := DestinationBigqueryDenormalizedCredentialUnionTypeDestinationBigqueryDenormalizedHMACKey

	return DestinationBigqueryDenormalizedCredential{
		DestinationBigqueryDenormalizedHMACKey: &destinationBigqueryDenormalizedHMACKey,
		Type:                                   typ,
	}
}

func (u *DestinationBigqueryDenormalizedCredential) UnmarshalJSON(data []byte) error {

	destinationBigqueryDenormalizedHMACKey := new(DestinationBigqueryDenormalizedHMACKey)
	if err := utils.UnmarshalJSON(data, &destinationBigqueryDenormalizedHMACKey, "", true, true); err == nil {
		u.DestinationBigqueryDenormalizedHMACKey = destinationBigqueryDenormalizedHMACKey
		u.Type = DestinationBigqueryDenormalizedCredentialUnionTypeDestinationBigqueryDenormalizedHMACKey
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationBigqueryDenormalizedCredential) MarshalJSON() ([]byte, error) {
	if u.DestinationBigqueryDenormalizedHMACKey != nil {
		return utils.MarshalJSON(u.DestinationBigqueryDenormalizedHMACKey, "", true)
	}

	return nil, errors.New("could not marshal union type: all fields are null")
}

// DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing - This upload method is supposed to temporary store records in GCS bucket. By this select you can chose if these records should be removed from GCS when migration has finished. The default "Delete all tmp files from GCS" value is used if not set explicitly.
type DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing string

const (
	DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessingDeleteAllTmpFilesFromGcs DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing = "Delete all tmp files from GCS"
	DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessingKeepAllTmpFilesInGcs     DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing = "Keep all tmp files in GCS"
)

func (e DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing) ToPointer() *DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing {
	return &e
}

func (e *DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Delete all tmp files from GCS":
		fallthrough
	case "Keep all tmp files in GCS":
		*e = DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing: %v", v)
	}
}

type DestinationBigqueryDenormalizedSchemasMethod string

const (
	DestinationBigqueryDenormalizedSchemasMethodGcsStaging DestinationBigqueryDenormalizedSchemasMethod = "GCS Staging"
)

func (e DestinationBigqueryDenormalizedSchemasMethod) ToPointer() *DestinationBigqueryDenormalizedSchemasMethod {
	return &e
}

func (e *DestinationBigqueryDenormalizedSchemasMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GCS Staging":
		*e = DestinationBigqueryDenormalizedSchemasMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryDenormalizedSchemasMethod: %v", v)
	}
}

// DestinationBigqueryDenormalizedGCSStaging - Loading method used to send select the way data will be uploaded to BigQuery. <br/><b>Standard Inserts</b> - Direct uploading using SQL INSERT statements. This method is extremely inefficient and provided only for quick testing. In almost all cases, you should use staging. <br/><b>GCS Staging</b> - Writes large batches of records to a file, uploads the file to GCS, then uses <b>COPY INTO table</b> to upload the file. Recommended for most workloads for better speed and scalability. Read more about GCS Staging <a href="https://docs.airbyte.com/integrations/destinations/bigquery#gcs-staging">here</a>.
type DestinationBigqueryDenormalizedGCSStaging struct {
	// An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href="https://cloud.google.com/storage/docs/authentication/hmackeys">here</a>.
	Credential DestinationBigqueryDenormalizedCredential `json:"credential"`
	// Number of file buffers allocated for writing data. Increasing this number is beneficial for connections using Change Data Capture (CDC) and up to the number of streams within a connection. Increasing the number of file buffers past the maximum number of streams has deteriorating effects
	FileBufferCount *int64 `default:"10" json:"file_buffer_count"`
	// The name of the GCS bucket. Read more <a href="https://cloud.google.com/storage/docs/naming-buckets">here</a>.
	GcsBucketName string `json:"gcs_bucket_name"`
	// Directory under the GCS bucket where data will be written. Read more <a href="https://cloud.google.com/storage/docs/locations">here</a>.
	GcsBucketPath string `json:"gcs_bucket_path"`
	// This upload method is supposed to temporary store records in GCS bucket. By this select you can chose if these records should be removed from GCS when migration has finished. The default "Delete all tmp files from GCS" value is used if not set explicitly.
	KeepFilesInGcsBucket *DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing `default:"Delete all tmp files from GCS" json:"keep_files_in_gcs-bucket"`
	method               DestinationBigqueryDenormalizedSchemasMethod                   `const:"GCS Staging" json:"method"`
}

func (d DestinationBigqueryDenormalizedGCSStaging) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationBigqueryDenormalizedGCSStaging) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationBigqueryDenormalizedGCSStaging) GetCredential() DestinationBigqueryDenormalizedCredential {
	if o == nil {
		return DestinationBigqueryDenormalizedCredential{}
	}
	return o.Credential
}

func (o *DestinationBigqueryDenormalizedGCSStaging) GetFileBufferCount() *int64 {
	if o == nil {
		return nil
	}
	return o.FileBufferCount
}

func (o *DestinationBigqueryDenormalizedGCSStaging) GetGcsBucketName() string {
	if o == nil {
		return ""
	}
	return o.GcsBucketName
}

func (o *DestinationBigqueryDenormalizedGCSStaging) GetGcsBucketPath() string {
	if o == nil {
		return ""
	}
	return o.GcsBucketPath
}

func (o *DestinationBigqueryDenormalizedGCSStaging) GetKeepFilesInGcsBucket() *DestinationBigqueryDenormalizedGCSTmpFilesAfterwardProcessing {
	if o == nil {
		return nil
	}
	return o.KeepFilesInGcsBucket
}

func (o *DestinationBigqueryDenormalizedGCSStaging) GetMethod() DestinationBigqueryDenormalizedSchemasMethod {
	return DestinationBigqueryDenormalizedSchemasMethodGcsStaging
}

type DestinationBigqueryDenormalizedMethod string

const (
	DestinationBigqueryDenormalizedMethodStandard DestinationBigqueryDenormalizedMethod = "Standard"
)

func (e DestinationBigqueryDenormalizedMethod) ToPointer() *DestinationBigqueryDenormalizedMethod {
	return &e
}

func (e *DestinationBigqueryDenormalizedMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Standard":
		*e = DestinationBigqueryDenormalizedMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationBigqueryDenormalizedMethod: %v", v)
	}
}

// DestinationBigqueryDenormalizedStandardInserts - Loading method used to send select the way data will be uploaded to BigQuery. <br/><b>Standard Inserts</b> - Direct uploading using SQL INSERT statements. This method is extremely inefficient and provided only for quick testing. In almost all cases, you should use staging. <br/><b>GCS Staging</b> - Writes large batches of records to a file, uploads the file to GCS, then uses <b>COPY INTO table</b> to upload the file. Recommended for most workloads for better speed and scalability. Read more about GCS Staging <a href="https://docs.airbyte.com/integrations/destinations/bigquery#gcs-staging">here</a>.
type DestinationBigqueryDenormalizedStandardInserts struct {
	method DestinationBigqueryDenormalizedMethod `const:"Standard" json:"method"`
}

func (d DestinationBigqueryDenormalizedStandardInserts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationBigqueryDenormalizedStandardInserts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationBigqueryDenormalizedStandardInserts) GetMethod() DestinationBigqueryDenormalizedMethod {
	return DestinationBigqueryDenormalizedMethodStandard
}

type DestinationBigqueryDenormalizedLoadingMethodType string

const (
	DestinationBigqueryDenormalizedLoadingMethodTypeDestinationBigqueryDenormalizedStandardInserts DestinationBigqueryDenormalizedLoadingMethodType = "destination-bigquery-denormalized_Standard Inserts"
	DestinationBigqueryDenormalizedLoadingMethodTypeDestinationBigqueryDenormalizedGCSStaging      DestinationBigqueryDenormalizedLoadingMethodType = "destination-bigquery-denormalized_GCS Staging"
)

type DestinationBigqueryDenormalizedLoadingMethod struct {
	DestinationBigqueryDenormalizedStandardInserts *DestinationBigqueryDenormalizedStandardInserts
	DestinationBigqueryDenormalizedGCSStaging      *DestinationBigqueryDenormalizedGCSStaging

	Type DestinationBigqueryDenormalizedLoadingMethodType
}

func CreateDestinationBigqueryDenormalizedLoadingMethodDestinationBigqueryDenormalizedStandardInserts(destinationBigqueryDenormalizedStandardInserts DestinationBigqueryDenormalizedStandardInserts) DestinationBigqueryDenormalizedLoadingMethod {
	typ := DestinationBigqueryDenormalizedLoadingMethodTypeDestinationBigqueryDenormalizedStandardInserts

	return DestinationBigqueryDenormalizedLoadingMethod{
		DestinationBigqueryDenormalizedStandardInserts: &destinationBigqueryDenormalizedStandardInserts,
		Type: typ,
	}
}

func CreateDestinationBigqueryDenormalizedLoadingMethodDestinationBigqueryDenormalizedGCSStaging(destinationBigqueryDenormalizedGCSStaging DestinationBigqueryDenormalizedGCSStaging) DestinationBigqueryDenormalizedLoadingMethod {
	typ := DestinationBigqueryDenormalizedLoadingMethodTypeDestinationBigqueryDenormalizedGCSStaging

	return DestinationBigqueryDenormalizedLoadingMethod{
		DestinationBigqueryDenormalizedGCSStaging: &destinationBigqueryDenormalizedGCSStaging,
		Type: typ,
	}
}

func (u *DestinationBigqueryDenormalizedLoadingMethod) UnmarshalJSON(data []byte) error {

	destinationBigqueryDenormalizedStandardInserts := new(DestinationBigqueryDenormalizedStandardInserts)
	if err := utils.UnmarshalJSON(data, &destinationBigqueryDenormalizedStandardInserts, "", true, true); err == nil {
		u.DestinationBigqueryDenormalizedStandardInserts = destinationBigqueryDenormalizedStandardInserts
		u.Type = DestinationBigqueryDenormalizedLoadingMethodTypeDestinationBigqueryDenormalizedStandardInserts
		return nil
	}

	destinationBigqueryDenormalizedGCSStaging := new(DestinationBigqueryDenormalizedGCSStaging)
	if err := utils.UnmarshalJSON(data, &destinationBigqueryDenormalizedGCSStaging, "", true, true); err == nil {
		u.DestinationBigqueryDenormalizedGCSStaging = destinationBigqueryDenormalizedGCSStaging
		u.Type = DestinationBigqueryDenormalizedLoadingMethodTypeDestinationBigqueryDenormalizedGCSStaging
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationBigqueryDenormalizedLoadingMethod) MarshalJSON() ([]byte, error) {
	if u.DestinationBigqueryDenormalizedStandardInserts != nil {
		return utils.MarshalJSON(u.DestinationBigqueryDenormalizedStandardInserts, "", true)
	}

	if u.DestinationBigqueryDenormalizedGCSStaging != nil {
		return utils.MarshalJSON(u.DestinationBigqueryDenormalizedGCSStaging, "", true)
	}

	return nil, errors.New("could not marshal union type: all fields are null")
}

type DestinationBigqueryDenormalized struct {
	// Google BigQuery client's chunk (buffer) size (MIN=1, MAX = 15) for each table. The size that will be written by a single RPC. Written data will be buffered and only flushed upon reaching this size or closing the channel. The default 15MB value is used if not set explicitly. Read more <a href="https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.client.Client.html">here</a>.
	BigQueryClientBufferSizeMb *int64 `default:"15" json:"big_query_client_buffer_size_mb"`
	// The contents of the JSON service account key. Check out the <a href="https://docs.airbyte.com/integrations/destinations/bigquery#service-account-key">docs</a> if you need help generating this key. Default credentials will be used if this field is left empty.
	CredentialsJSON *string `json:"credentials_json,omitempty"`
	// The default BigQuery Dataset ID that tables are replicated to if the source does not specify a namespace. Read more <a href="https://cloud.google.com/bigquery/docs/datasets#create-dataset">here</a>.
	DatasetID string `json:"dataset_id"`
	// The location of the dataset. Warning: Changes made after creation will not be applied. The default "US" value is used if not set explicitly. Read more <a href="https://cloud.google.com/bigquery/docs/locations">here</a>.
	DatasetLocation *DestinationBigqueryDenormalizedDatasetLocation `default:"US" json:"dataset_location"`
	destinationType BigqueryDenormalized                            `const:"bigquery-denormalized" json:"destinationType"`
	// Loading method used to send select the way data will be uploaded to BigQuery. <br/><b>Standard Inserts</b> - Direct uploading using SQL INSERT statements. This method is extremely inefficient and provided only for quick testing. In almost all cases, you should use staging. <br/><b>GCS Staging</b> - Writes large batches of records to a file, uploads the file to GCS, then uses <b>COPY INTO table</b> to upload the file. Recommended for most workloads for better speed and scalability. Read more about GCS Staging <a href="https://docs.airbyte.com/integrations/destinations/bigquery#gcs-staging">here</a>.
	LoadingMethod *DestinationBigqueryDenormalizedLoadingMethod `json:"loading_method,omitempty"`
	// The GCP project ID for the project containing the target BigQuery dataset. Read more <a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects">here</a>.
	ProjectID string `json:"project_id"`
}

func (d DestinationBigqueryDenormalized) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationBigqueryDenormalized) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DestinationBigqueryDenormalized) GetBigQueryClientBufferSizeMb() *int64 {
	if o == nil {
		return nil
	}
	return o.BigQueryClientBufferSizeMb
}

func (o *DestinationBigqueryDenormalized) GetCredentialsJSON() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsJSON
}

func (o *DestinationBigqueryDenormalized) GetDatasetID() string {
	if o == nil {
		return ""
	}
	return o.DatasetID
}

func (o *DestinationBigqueryDenormalized) GetDatasetLocation() *DestinationBigqueryDenormalizedDatasetLocation {
	if o == nil {
		return nil
	}
	return o.DatasetLocation
}

func (o *DestinationBigqueryDenormalized) GetDestinationType() BigqueryDenormalized {
	return BigqueryDenormalizedBigqueryDenormalized
}

func (o *DestinationBigqueryDenormalized) GetLoadingMethod() *DestinationBigqueryDenormalizedLoadingMethod {
	if o == nil {
		return nil
	}
	return o.LoadingMethod
}

func (o *DestinationBigqueryDenormalized) GetProjectID() string {
	if o == nil {
		return ""
	}
	return o.ProjectID
}
