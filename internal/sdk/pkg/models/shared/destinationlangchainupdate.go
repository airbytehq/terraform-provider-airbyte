// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/airbytehq/terraform-provider-airbyte/internal/sdk/pkg/utils"
)

type DestinationLangchainUpdateSchemasMode string

const (
	DestinationLangchainUpdateSchemasModeFake DestinationLangchainUpdateSchemasMode = "fake"
)

func (e DestinationLangchainUpdateSchemasMode) ToPointer() *DestinationLangchainUpdateSchemasMode {
	return &e
}

func (e *DestinationLangchainUpdateSchemasMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "fake":
		*e = DestinationLangchainUpdateSchemasMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationLangchainUpdateSchemasMode: %v", v)
	}
}

// DestinationLangchainUpdateFake - Use a fake embedding made out of random vectors with 1536 embedding dimensions. This is useful for testing the data pipeline without incurring any costs.
type DestinationLangchainUpdateFake struct {
	mode *DestinationLangchainUpdateSchemasMode `const:"fake" json:"mode"`
}

func (d DestinationLangchainUpdateFake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationLangchainUpdateFake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationLangchainUpdateFake) GetMode() *DestinationLangchainUpdateSchemasMode {
	return DestinationLangchainUpdateSchemasModeFake.ToPointer()
}

type DestinationLangchainUpdateMode string

const (
	DestinationLangchainUpdateModeOpenai DestinationLangchainUpdateMode = "openai"
)

func (e DestinationLangchainUpdateMode) ToPointer() *DestinationLangchainUpdateMode {
	return &e
}

func (e *DestinationLangchainUpdateMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "openai":
		*e = DestinationLangchainUpdateMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationLangchainUpdateMode: %v", v)
	}
}

// DestinationLangchainUpdateOpenAI - Use the OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.
type DestinationLangchainUpdateOpenAI struct {
	mode      *DestinationLangchainUpdateMode `const:"openai" json:"mode"`
	OpenaiKey string                          `json:"openai_key"`
}

func (d DestinationLangchainUpdateOpenAI) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationLangchainUpdateOpenAI) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationLangchainUpdateOpenAI) GetMode() *DestinationLangchainUpdateMode {
	return DestinationLangchainUpdateModeOpenai.ToPointer()
}

func (o *DestinationLangchainUpdateOpenAI) GetOpenaiKey() string {
	if o == nil {
		return ""
	}
	return o.OpenaiKey
}

type DestinationLangchainUpdateEmbeddingType string

const (
	DestinationLangchainUpdateEmbeddingTypeDestinationLangchainUpdateOpenAI DestinationLangchainUpdateEmbeddingType = "destination-langchain-update_OpenAI"
	DestinationLangchainUpdateEmbeddingTypeDestinationLangchainUpdateFake   DestinationLangchainUpdateEmbeddingType = "destination-langchain-update_Fake"
)

// DestinationLangchainUpdateEmbedding - Embedding configuration
type DestinationLangchainUpdateEmbedding struct {
	DestinationLangchainUpdateOpenAI *DestinationLangchainUpdateOpenAI
	DestinationLangchainUpdateFake   *DestinationLangchainUpdateFake

	Type DestinationLangchainUpdateEmbeddingType
}

func CreateDestinationLangchainUpdateEmbeddingDestinationLangchainUpdateOpenAI(destinationLangchainUpdateOpenAI DestinationLangchainUpdateOpenAI) DestinationLangchainUpdateEmbedding {
	typ := DestinationLangchainUpdateEmbeddingTypeDestinationLangchainUpdateOpenAI

	return DestinationLangchainUpdateEmbedding{
		DestinationLangchainUpdateOpenAI: &destinationLangchainUpdateOpenAI,
		Type:                             typ,
	}
}

func CreateDestinationLangchainUpdateEmbeddingDestinationLangchainUpdateFake(destinationLangchainUpdateFake DestinationLangchainUpdateFake) DestinationLangchainUpdateEmbedding {
	typ := DestinationLangchainUpdateEmbeddingTypeDestinationLangchainUpdateFake

	return DestinationLangchainUpdateEmbedding{
		DestinationLangchainUpdateFake: &destinationLangchainUpdateFake,
		Type:                           typ,
	}
}

func (u *DestinationLangchainUpdateEmbedding) UnmarshalJSON(data []byte) error {

	destinationLangchainUpdateFake := new(DestinationLangchainUpdateFake)
	if err := utils.UnmarshalJSON(data, &destinationLangchainUpdateFake, "", true, true); err == nil {
		u.DestinationLangchainUpdateFake = destinationLangchainUpdateFake
		u.Type = DestinationLangchainUpdateEmbeddingTypeDestinationLangchainUpdateFake
		return nil
	}

	destinationLangchainUpdateOpenAI := new(DestinationLangchainUpdateOpenAI)
	if err := utils.UnmarshalJSON(data, &destinationLangchainUpdateOpenAI, "", true, true); err == nil {
		u.DestinationLangchainUpdateOpenAI = destinationLangchainUpdateOpenAI
		u.Type = DestinationLangchainUpdateEmbeddingTypeDestinationLangchainUpdateOpenAI
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationLangchainUpdateEmbedding) MarshalJSON() ([]byte, error) {
	if u.DestinationLangchainUpdateOpenAI != nil {
		return utils.MarshalJSON(u.DestinationLangchainUpdateOpenAI, "", true)
	}

	if u.DestinationLangchainUpdateFake != nil {
		return utils.MarshalJSON(u.DestinationLangchainUpdateFake, "", true)
	}

	return nil, errors.New("could not marshal union type: all fields are null")
}

type DestinationLangchainUpdateSchemasIndexingIndexing3Mode string

const (
	DestinationLangchainUpdateSchemasIndexingIndexing3ModeChromaLocal DestinationLangchainUpdateSchemasIndexingIndexing3Mode = "chroma_local"
)

func (e DestinationLangchainUpdateSchemasIndexingIndexing3Mode) ToPointer() *DestinationLangchainUpdateSchemasIndexingIndexing3Mode {
	return &e
}

func (e *DestinationLangchainUpdateSchemasIndexingIndexing3Mode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "chroma_local":
		*e = DestinationLangchainUpdateSchemasIndexingIndexing3Mode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationLangchainUpdateSchemasIndexingIndexing3Mode: %v", v)
	}
}

// ChromaLocalPersistance - Chroma is a popular vector store that can be used to store and retrieve embeddings. It will build its index in memory and persist it to disk by the end of the sync.
type ChromaLocalPersistance struct {
	// Name of the collection to use.
	CollectionName *string `default:"langchain" json:"collection_name"`
	// Path to the directory where chroma files will be written. The files will be placed inside that local mount.
	DestinationPath string                                                  `json:"destination_path"`
	mode            *DestinationLangchainUpdateSchemasIndexingIndexing3Mode `const:"chroma_local" json:"mode"`
}

func (c ChromaLocalPersistance) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ChromaLocalPersistance) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *ChromaLocalPersistance) GetCollectionName() *string {
	if o == nil {
		return nil
	}
	return o.CollectionName
}

func (o *ChromaLocalPersistance) GetDestinationPath() string {
	if o == nil {
		return ""
	}
	return o.DestinationPath
}

func (o *ChromaLocalPersistance) GetMode() *DestinationLangchainUpdateSchemasIndexingIndexing3Mode {
	return DestinationLangchainUpdateSchemasIndexingIndexing3ModeChromaLocal.ToPointer()
}

type DestinationLangchainUpdateSchemasIndexingIndexingMode string

const (
	DestinationLangchainUpdateSchemasIndexingIndexingModeDocArrayHnswSearch DestinationLangchainUpdateSchemasIndexingIndexingMode = "DocArrayHnswSearch"
)

func (e DestinationLangchainUpdateSchemasIndexingIndexingMode) ToPointer() *DestinationLangchainUpdateSchemasIndexingIndexingMode {
	return &e
}

func (e *DestinationLangchainUpdateSchemasIndexingIndexingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DocArrayHnswSearch":
		*e = DestinationLangchainUpdateSchemasIndexingIndexingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationLangchainUpdateSchemasIndexingIndexingMode: %v", v)
	}
}

// DocArrayHnswSearch is a lightweight Document Index implementation provided by Docarray that runs fully locally and is best suited for small- to medium-sized datasets. It stores vectors on disk in hnswlib, and stores all other data in SQLite.
type DocArrayHnswSearch struct {
	// Path to the directory where hnswlib and meta data files will be written. The files will be placed inside that local mount. All files in the specified destination directory will be deleted on each run.
	DestinationPath string                                                 `json:"destination_path"`
	mode            *DestinationLangchainUpdateSchemasIndexingIndexingMode `const:"DocArrayHnswSearch" json:"mode"`
}

func (d DocArrayHnswSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DocArrayHnswSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DocArrayHnswSearch) GetDestinationPath() string {
	if o == nil {
		return ""
	}
	return o.DestinationPath
}

func (o *DocArrayHnswSearch) GetMode() *DestinationLangchainUpdateSchemasIndexingIndexingMode {
	return DestinationLangchainUpdateSchemasIndexingIndexingModeDocArrayHnswSearch.ToPointer()
}

type DestinationLangchainUpdateSchemasIndexingMode string

const (
	DestinationLangchainUpdateSchemasIndexingModePinecone DestinationLangchainUpdateSchemasIndexingMode = "pinecone"
)

func (e DestinationLangchainUpdateSchemasIndexingMode) ToPointer() *DestinationLangchainUpdateSchemasIndexingMode {
	return &e
}

func (e *DestinationLangchainUpdateSchemasIndexingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "pinecone":
		*e = DestinationLangchainUpdateSchemasIndexingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationLangchainUpdateSchemasIndexingMode: %v", v)
	}
}

// DestinationLangchainUpdatePinecone - Pinecone is a popular vector store that can be used to store and retrieve embeddings. It is a managed service and can also be queried from outside of langchain.
type DestinationLangchainUpdatePinecone struct {
	// Pinecone index to use
	Index string                                         `json:"index"`
	mode  *DestinationLangchainUpdateSchemasIndexingMode `const:"pinecone" json:"mode"`
	// Pinecone environment to use
	PineconeEnvironment string `json:"pinecone_environment"`
	PineconeKey         string `json:"pinecone_key"`
}

func (d DestinationLangchainUpdatePinecone) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationLangchainUpdatePinecone) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *DestinationLangchainUpdatePinecone) GetIndex() string {
	if o == nil {
		return ""
	}
	return o.Index
}

func (o *DestinationLangchainUpdatePinecone) GetMode() *DestinationLangchainUpdateSchemasIndexingMode {
	return DestinationLangchainUpdateSchemasIndexingModePinecone.ToPointer()
}

func (o *DestinationLangchainUpdatePinecone) GetPineconeEnvironment() string {
	if o == nil {
		return ""
	}
	return o.PineconeEnvironment
}

func (o *DestinationLangchainUpdatePinecone) GetPineconeKey() string {
	if o == nil {
		return ""
	}
	return o.PineconeKey
}

type DestinationLangchainUpdateIndexingType string

const (
	DestinationLangchainUpdateIndexingTypeDestinationLangchainUpdatePinecone DestinationLangchainUpdateIndexingType = "destination-langchain-update_Pinecone"
	DestinationLangchainUpdateIndexingTypeDocArrayHnswSearch                 DestinationLangchainUpdateIndexingType = "DocArrayHnswSearch"
	DestinationLangchainUpdateIndexingTypeChromaLocalPersistance             DestinationLangchainUpdateIndexingType = "Chroma (local persistance)"
)

// DestinationLangchainUpdateIndexing - Indexing configuration
type DestinationLangchainUpdateIndexing struct {
	DestinationLangchainUpdatePinecone *DestinationLangchainUpdatePinecone
	DocArrayHnswSearch                 *DocArrayHnswSearch
	ChromaLocalPersistance             *ChromaLocalPersistance

	Type DestinationLangchainUpdateIndexingType
}

func CreateDestinationLangchainUpdateIndexingDestinationLangchainUpdatePinecone(destinationLangchainUpdatePinecone DestinationLangchainUpdatePinecone) DestinationLangchainUpdateIndexing {
	typ := DestinationLangchainUpdateIndexingTypeDestinationLangchainUpdatePinecone

	return DestinationLangchainUpdateIndexing{
		DestinationLangchainUpdatePinecone: &destinationLangchainUpdatePinecone,
		Type:                               typ,
	}
}

func CreateDestinationLangchainUpdateIndexingDocArrayHnswSearch(docArrayHnswSearch DocArrayHnswSearch) DestinationLangchainUpdateIndexing {
	typ := DestinationLangchainUpdateIndexingTypeDocArrayHnswSearch

	return DestinationLangchainUpdateIndexing{
		DocArrayHnswSearch: &docArrayHnswSearch,
		Type:               typ,
	}
}

func CreateDestinationLangchainUpdateIndexingChromaLocalPersistance(chromaLocalPersistance ChromaLocalPersistance) DestinationLangchainUpdateIndexing {
	typ := DestinationLangchainUpdateIndexingTypeChromaLocalPersistance

	return DestinationLangchainUpdateIndexing{
		ChromaLocalPersistance: &chromaLocalPersistance,
		Type:                   typ,
	}
}

func (u *DestinationLangchainUpdateIndexing) UnmarshalJSON(data []byte) error {

	docArrayHnswSearch := new(DocArrayHnswSearch)
	if err := utils.UnmarshalJSON(data, &docArrayHnswSearch, "", true, true); err == nil {
		u.DocArrayHnswSearch = docArrayHnswSearch
		u.Type = DestinationLangchainUpdateIndexingTypeDocArrayHnswSearch
		return nil
	}

	chromaLocalPersistance := new(ChromaLocalPersistance)
	if err := utils.UnmarshalJSON(data, &chromaLocalPersistance, "", true, true); err == nil {
		u.ChromaLocalPersistance = chromaLocalPersistance
		u.Type = DestinationLangchainUpdateIndexingTypeChromaLocalPersistance
		return nil
	}

	destinationLangchainUpdatePinecone := new(DestinationLangchainUpdatePinecone)
	if err := utils.UnmarshalJSON(data, &destinationLangchainUpdatePinecone, "", true, true); err == nil {
		u.DestinationLangchainUpdatePinecone = destinationLangchainUpdatePinecone
		u.Type = DestinationLangchainUpdateIndexingTypeDestinationLangchainUpdatePinecone
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationLangchainUpdateIndexing) MarshalJSON() ([]byte, error) {
	if u.DestinationLangchainUpdatePinecone != nil {
		return utils.MarshalJSON(u.DestinationLangchainUpdatePinecone, "", true)
	}

	if u.DocArrayHnswSearch != nil {
		return utils.MarshalJSON(u.DocArrayHnswSearch, "", true)
	}

	if u.ChromaLocalPersistance != nil {
		return utils.MarshalJSON(u.ChromaLocalPersistance, "", true)
	}

	return nil, errors.New("could not marshal union type: all fields are null")
}

type DestinationLangchainUpdateProcessingConfigModel struct {
	// Size of overlap between chunks in tokens to store in vector store to better capture relevant context
	ChunkOverlap *int64 `default:"0" json:"chunk_overlap"`
	// Size of chunks in tokens to store in vector store (make sure it is not too big for the context if your LLM)
	ChunkSize int64 `json:"chunk_size"`
	// List of fields in the record that should be used to calculate the embedding. All other fields are passed along as meta fields. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered text fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array.
	TextFields []string `json:"text_fields"`
}

func (d DestinationLangchainUpdateProcessingConfigModel) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DestinationLangchainUpdateProcessingConfigModel) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DestinationLangchainUpdateProcessingConfigModel) GetChunkOverlap() *int64 {
	if o == nil {
		return nil
	}
	return o.ChunkOverlap
}

func (o *DestinationLangchainUpdateProcessingConfigModel) GetChunkSize() int64 {
	if o == nil {
		return 0
	}
	return o.ChunkSize
}

func (o *DestinationLangchainUpdateProcessingConfigModel) GetTextFields() []string {
	if o == nil {
		return []string{}
	}
	return o.TextFields
}

type DestinationLangchainUpdate struct {
	// Embedding configuration
	Embedding DestinationLangchainUpdateEmbedding `json:"embedding"`
	// Indexing configuration
	Indexing   DestinationLangchainUpdateIndexing              `json:"indexing"`
	Processing DestinationLangchainUpdateProcessingConfigModel `json:"processing"`
}

func (o *DestinationLangchainUpdate) GetEmbedding() DestinationLangchainUpdateEmbedding {
	if o == nil {
		return DestinationLangchainUpdateEmbedding{}
	}
	return o.Embedding
}

func (o *DestinationLangchainUpdate) GetIndexing() DestinationLangchainUpdateIndexing {
	if o == nil {
		return DestinationLangchainUpdateIndexing{}
	}
	return o.Indexing
}

func (o *DestinationLangchainUpdate) GetProcessing() DestinationLangchainUpdateProcessingConfigModel {
	if o == nil {
		return DestinationLangchainUpdateProcessingConfigModel{}
	}
	return o.Processing
}
