// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"bytes"
	"encoding/json"
	"errors"
	"fmt"
)

// DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec - The compression algorithm used to compress data pages.
type DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec string

const (
	DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodecUncompressed DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec = "UNCOMPRESSED"
	DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodecSnappy       DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec = "SNAPPY"
	DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodecGzip         DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec = "GZIP"
	DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodecLzo          DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec = "LZO"
	DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodecBrotli       DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec = "BROTLI"
	DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodecLz4          DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec = "LZ4"
	DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodecZstd         DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec = "ZSTD"
)

func (e DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec) ToPointer() *DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec {
	return &e
}

func (e *DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "UNCOMPRESSED":
		fallthrough
	case "SNAPPY":
		fallthrough
	case "GZIP":
		fallthrough
	case "LZO":
		fallthrough
	case "BROTLI":
		fallthrough
	case "LZ4":
		fallthrough
	case "ZSTD":
		*e = DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec: %v", v)
	}
}

type DestinationS3UpdateOutputFormatParquetColumnarStorageFormatType string

const (
	DestinationS3UpdateOutputFormatParquetColumnarStorageFormatTypeParquet DestinationS3UpdateOutputFormatParquetColumnarStorageFormatType = "Parquet"
)

func (e DestinationS3UpdateOutputFormatParquetColumnarStorageFormatType) ToPointer() *DestinationS3UpdateOutputFormatParquetColumnarStorageFormatType {
	return &e
}

func (e *DestinationS3UpdateOutputFormatParquetColumnarStorageFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Parquet":
		*e = DestinationS3UpdateOutputFormatParquetColumnarStorageFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatParquetColumnarStorageFormatType: %v", v)
	}
}

// DestinationS3UpdateOutputFormatParquetColumnarStorage - Format of the data output. See <a href="https://docs.airbyte.com/integrations/destinations/s3/#supported-output-schema">here</a> for more details
type DestinationS3UpdateOutputFormatParquetColumnarStorage struct {
	// This is the size of a row group being buffered in memory. It limits the memory usage when writing. Larger values will improve the IO when reading, but consume more memory when writing. Default: 128 MB.
	BlockSizeMb *int64 `json:"block_size_mb,omitempty"`
	// The compression algorithm used to compress data pages.
	CompressionCodec *DestinationS3UpdateOutputFormatParquetColumnarStorageCompressionCodec `json:"compression_codec,omitempty"`
	// Default: true.
	DictionaryEncoding *bool `json:"dictionary_encoding,omitempty"`
	// There is one dictionary page per column per row group when dictionary encoding is used. The dictionary page size works like the page size but for dictionary. Default: 1024 KB.
	DictionaryPageSizeKb *int64                                                          `json:"dictionary_page_size_kb,omitempty"`
	FormatType           DestinationS3UpdateOutputFormatParquetColumnarStorageFormatType `json:"format_type"`
	// Maximum size allowed as padding to align row groups. This is also the minimum size of a row group. Default: 8 MB.
	MaxPaddingSizeMb *int64 `json:"max_padding_size_mb,omitempty"`
	// The page size is for compression. A block is composed of pages. A page is the smallest unit that must be read fully to access a single record. If this value is too small, the compression will deteriorate. Default: 1024 KB.
	PageSizeKb *int64 `json:"page_size_kb,omitempty"`
}

type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIPCompressionType string

const (
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIPCompressionTypeGzip DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIPCompressionType = "GZIP"
)

func (e DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIPCompressionType) ToPointer() *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIPCompressionType {
	return &e
}

func (e *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIPCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GZIP":
		*e = DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIPCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIPCompressionType: %v", v)
	}
}

// DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP - Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".jsonl.gz").
type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP struct {
	CompressionType *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIPCompressionType `json:"compression_type,omitempty"`
}

type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompressionCompressionType string

const (
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompressionCompressionTypeNoCompression DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompressionCompressionType = "No Compression"
)

func (e DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompressionCompressionType) ToPointer() *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompressionCompressionType {
	return &e
}

func (e *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompressionCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No Compression":
		*e = DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompressionCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompressionCompressionType: %v", v)
	}
}

// DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression - Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".jsonl.gz").
type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression struct {
	CompressionType *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompressionCompressionType `json:"compression_type,omitempty"`
}

type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionType string

const (
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionTypeDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionType = "destination-s3-update_Output Format_JSON Lines: Newline-delimited JSON_Compression_No Compression"
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionTypeDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP          DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionType = "destination-s3-update_Output Format_JSON Lines: Newline-delimited JSON_Compression_GZIP"
)

type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompression struct {
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP          *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP

	Type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionType
}

func CreateDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression(destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression) DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompression {
	typ := DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionTypeDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression

	return DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompression{
		DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression: &destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP(destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP) DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompression {
	typ := DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionTypeDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP

	return DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompression{
		DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP: &destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP,
		Type: typ,
	}
}

func (u *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompression) UnmarshalJSON(data []byte) error {
	var d *json.Decoder

	destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression := new(DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression); err == nil {
		u.DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression = destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression
		u.Type = DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionTypeDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression
		return nil
	}

	destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP := new(DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP); err == nil {
		u.DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP = destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP
		u.Type = DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionTypeDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompression) MarshalJSON() ([]byte, error) {
	if u.DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionNoCompression)
	}

	if u.DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompressionGZIP)
	}

	return nil, nil
}

// DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening - Whether the input json data should be normalized (flattened) in the output JSON Lines. Please refer to docs for details.
type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening string

const (
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlatteningNoFlattening        DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening = "No flattening"
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlatteningRootLevelFlattening DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening = "Root level flattening"
)

func (e DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening) ToPointer() *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening {
	return &e
}

func (e *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No flattening":
		fallthrough
	case "Root level flattening":
		*e = DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening: %v", v)
	}
}

type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFormatType string

const (
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFormatTypeJsonl DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFormatType = "JSONL"
)

func (e DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFormatType) ToPointer() *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFormatType {
	return &e
}

func (e *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "JSONL":
		*e = DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFormatType: %v", v)
	}
}

// DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON - Format of the data output. See <a href="https://docs.airbyte.com/integrations/destinations/s3/#supported-output-schema">here</a> for more details
type DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON struct {
	// Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".jsonl.gz").
	Compression *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONCompression `json:"compression,omitempty"`
	// Whether the input json data should be normalized (flattened) in the output JSON Lines. Please refer to docs for details.
	Flattening *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFlattening `json:"flattening,omitempty"`
	FormatType DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSONFormatType  `json:"format_type"`
}

type DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIPCompressionType string

const (
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIPCompressionTypeGzip DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIPCompressionType = "GZIP"
)

func (e DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIPCompressionType) ToPointer() *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIPCompressionType {
	return &e
}

func (e *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIPCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "GZIP":
		*e = DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIPCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIPCompressionType: %v", v)
	}
}

// DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP - Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".csv.gz").
type DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP struct {
	CompressionType *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIPCompressionType `json:"compression_type,omitempty"`
}

type DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompressionCompressionType string

const (
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompressionCompressionTypeNoCompression DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompressionCompressionType = "No Compression"
)

func (e DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompressionCompressionType) ToPointer() *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompressionCompressionType {
	return &e
}

func (e *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompressionCompressionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No Compression":
		*e = DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompressionCompressionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompressionCompressionType: %v", v)
	}
}

// DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression - Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".csv.gz").
type DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression struct {
	CompressionType *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompressionCompressionType `json:"compression_type,omitempty"`
}

type DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionType string

const (
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionTypeDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionType = "destination-s3-update_Output Format_CSV: Comma-Separated Values_Compression_No Compression"
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionTypeDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP          DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionType = "destination-s3-update_Output Format_CSV: Comma-Separated Values_Compression_GZIP"
)

type DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompression struct {
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP          *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP

	Type DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionType
}

func CreateDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression(destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression) DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompression {
	typ := DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionTypeDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression

	return DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompression{
		DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression: &destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP(destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP) DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompression {
	typ := DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionTypeDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP

	return DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompression{
		DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP: &destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP,
		Type: typ,
	}
}

func (u *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompression) UnmarshalJSON(data []byte) error {
	var d *json.Decoder

	destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression := new(DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression); err == nil {
		u.DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression = destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression
		u.Type = DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionTypeDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression
		return nil
	}

	destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP := new(DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP); err == nil {
		u.DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP = destinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP
		u.Type = DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionTypeDestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompression) MarshalJSON() ([]byte, error) {
	if u.DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionNoCompression)
	}

	if u.DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompressionGZIP)
	}

	return nil, nil
}

// DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening - Whether the input json data should be normalized (flattened) in the output CSV. Please refer to docs for details.
type DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening string

const (
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlatteningNoFlattening        DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening = "No flattening"
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlatteningRootLevelFlattening DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening = "Root level flattening"
)

func (e DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening) ToPointer() *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening {
	return &e
}

func (e *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "No flattening":
		fallthrough
	case "Root level flattening":
		*e = DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening: %v", v)
	}
}

type DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFormatType string

const (
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFormatTypeCsv DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFormatType = "CSV"
)

func (e DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFormatType) ToPointer() *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFormatType {
	return &e
}

func (e *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "CSV":
		*e = DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFormatType: %v", v)
	}
}

// DestinationS3UpdateOutputFormatCSVCommaSeparatedValues - Format of the data output. See <a href="https://docs.airbyte.com/integrations/destinations/s3/#supported-output-schema">here</a> for more details
type DestinationS3UpdateOutputFormatCSVCommaSeparatedValues struct {
	// Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: ".csv.gz").
	Compression *DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesCompression `json:"compression,omitempty"`
	// Whether the input json data should be normalized (flattened) in the output CSV. Please refer to docs for details.
	Flattening DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFlattening `json:"flattening"`
	FormatType DestinationS3UpdateOutputFormatCSVCommaSeparatedValuesFormatType `json:"format_type"`
}

type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappyCodec string

const (
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappyCodecSnappy DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappyCodec = "snappy"
)

func (e DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappyCodec) ToPointer() *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappyCodec {
	return &e
}

func (e *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappyCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snappy":
		*e = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappyCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappyCodec: %v", v)
	}
}

// DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy - The compression algorithm used to compress data. Default to no compression.
type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy struct {
	Codec DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappyCodec `json:"codec"`
}

type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandardCodec string

const (
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandardCodecZstandard DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandardCodec = "zstandard"
)

func (e DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandardCodec) ToPointer() *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandardCodec {
	return &e
}

func (e *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandardCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "zstandard":
		*e = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandardCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandardCodec: %v", v)
	}
}

// DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard - The compression algorithm used to compress data. Default to no compression.
type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard struct {
	Codec DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandardCodec `json:"codec"`
	// Negative levels are 'fast' modes akin to lz4 or snappy, levels above 9 are generally for archival purposes, and levels above 18 use a lot of memory.
	CompressionLevel int64 `json:"compression_level"`
	// If true, include a checksum with each data block.
	IncludeChecksum *bool `json:"include_checksum,omitempty"`
}

type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXzCodec string

const (
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXzCodecXz DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXzCodec = "xz"
)

func (e DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXzCodec) ToPointer() *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXzCodec {
	return &e
}

func (e *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXzCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "xz":
		*e = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXzCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXzCodec: %v", v)
	}
}

// DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz - The compression algorithm used to compress data. Default to no compression.
type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz struct {
	Codec DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXzCodec `json:"codec"`
	// See <a href="https://commons.apache.org/proper/commons-compress/apidocs/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.html#XZCompressorOutputStream-java.io.OutputStream-int-">here</a> for details.
	CompressionLevel int64 `json:"compression_level"`
}

type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2Codec string

const (
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2CodecBzip2 DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2Codec = "bzip2"
)

func (e DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2Codec) ToPointer() *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2Codec {
	return &e
}

func (e *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2Codec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "bzip2":
		*e = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2Codec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2Codec: %v", v)
	}
}

// DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2 - The compression algorithm used to compress data. Default to no compression.
type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2 struct {
	Codec DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2Codec `json:"codec"`
}

type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflateCodec string

const (
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflateCodecDeflate DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflateCodec = "Deflate"
)

func (e DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflateCodec) ToPointer() *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflateCodec {
	return &e
}

func (e *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflateCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Deflate":
		*e = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflateCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflateCodec: %v", v)
	}
}

// DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate - The compression algorithm used to compress data. Default to no compression.
type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate struct {
	Codec DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflateCodec `json:"codec"`
	// 0: no compression & fastest, 9: best compression & slowest.
	CompressionLevel int64 `json:"compression_level"`
}

type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompressionCodec string

const (
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompressionCodecNoCompression DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompressionCodec = "no compression"
)

func (e DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompressionCodec) ToPointer() *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompressionCodec {
	return &e
}

func (e *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompressionCodec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "no compression":
		*e = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompressionCodec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompressionCodec: %v", v)
	}
}

// DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression - The compression algorithm used to compress data. Default to no compression.
type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression struct {
	Codec DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompressionCodec `json:"codec"`
}

type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecType string

const (
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecType = "destination-s3-update_Output Format_Avro: Apache Avro_Compression Codec_No Compression"
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate       DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecType = "destination-s3-update_Output Format_Avro: Apache Avro_Compression Codec_Deflate"
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2         DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecType = "destination-s3-update_Output Format_Avro: Apache Avro_Compression Codec_bzip2"
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz            DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecType = "destination-s3-update_Output Format_Avro: Apache Avro_Compression Codec_xz"
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard     DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecType = "destination-s3-update_Output Format_Avro: Apache Avro_Compression Codec_zstandard"
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy        DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecType = "destination-s3-update_Output Format_Avro: Apache Avro_Compression Codec_snappy"
)

type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec struct {
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate       *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2         *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz            *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard     *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard
	DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy        *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy

	Type DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecType
}

func CreateDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression(destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression) DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec {
	typ := DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression

	return DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec{
		DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression: &destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate(destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate) DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec {
	typ := DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate

	return DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec{
		DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate: &destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2(destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2 DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2) DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec {
	typ := DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2

	return DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec{
		DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2: &destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz(destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz) DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec {
	typ := DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz

	return DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec{
		DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz: &destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard(destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard) DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec {
	typ := DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard

	return DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec{
		DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard: &destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy(destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy) DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec {
	typ := DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy

	return DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec{
		DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy: &destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy,
		Type: typ,
	}
}

func (u *DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec) UnmarshalJSON(data []byte) error {
	var d *json.Decoder

	destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression := new(DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression); err == nil {
		u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression = destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression
		u.Type = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression
		return nil
	}

	destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2 := new(DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2); err == nil {
		u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2 = destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2
		u.Type = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2
		return nil
	}

	destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy := new(DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy); err == nil {
		u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy = destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy
		u.Type = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy
		return nil
	}

	destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate := new(DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate); err == nil {
		u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate = destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate
		u.Type = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate
		return nil
	}

	destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz := new(DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz); err == nil {
		u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz = destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz
		u.Type = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz
		return nil
	}

	destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard := new(DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard); err == nil {
		u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard = destinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard
		u.Type = DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecTypeDestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec) MarshalJSON() ([]byte, error) {
	if u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecNoCompression)
	}

	if u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2 != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecBzip2)
	}

	if u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecSnappy)
	}

	if u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecDeflate)
	}

	if u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecXz)
	}

	if u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodecZstandard)
	}

	return nil, nil
}

type DestinationS3UpdateOutputFormatAvroApacheAvroFormatType string

const (
	DestinationS3UpdateOutputFormatAvroApacheAvroFormatTypeAvro DestinationS3UpdateOutputFormatAvroApacheAvroFormatType = "Avro"
)

func (e DestinationS3UpdateOutputFormatAvroApacheAvroFormatType) ToPointer() *DestinationS3UpdateOutputFormatAvroApacheAvroFormatType {
	return &e
}

func (e *DestinationS3UpdateOutputFormatAvroApacheAvroFormatType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Avro":
		*e = DestinationS3UpdateOutputFormatAvroApacheAvroFormatType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateOutputFormatAvroApacheAvroFormatType: %v", v)
	}
}

// DestinationS3UpdateOutputFormatAvroApacheAvro - Format of the data output. See <a href="https://docs.airbyte.com/integrations/destinations/s3/#supported-output-schema">here</a> for more details
type DestinationS3UpdateOutputFormatAvroApacheAvro struct {
	// The compression algorithm used to compress data. Default to no compression.
	CompressionCodec DestinationS3UpdateOutputFormatAvroApacheAvroCompressionCodec `json:"compression_codec"`
	FormatType       DestinationS3UpdateOutputFormatAvroApacheAvroFormatType       `json:"format_type"`
}

type DestinationS3UpdateOutputFormatType string

const (
	DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatAvroApacheAvro                DestinationS3UpdateOutputFormatType = "destination-s3-update_Output Format_Avro: Apache Avro"
	DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatCSVCommaSeparatedValues       DestinationS3UpdateOutputFormatType = "destination-s3-update_Output Format_CSV: Comma-Separated Values"
	DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON DestinationS3UpdateOutputFormatType = "destination-s3-update_Output Format_JSON Lines: Newline-delimited JSON"
	DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatParquetColumnarStorage        DestinationS3UpdateOutputFormatType = "destination-s3-update_Output Format_Parquet: Columnar Storage"
)

type DestinationS3UpdateOutputFormat struct {
	DestinationS3UpdateOutputFormatAvroApacheAvro                *DestinationS3UpdateOutputFormatAvroApacheAvro
	DestinationS3UpdateOutputFormatCSVCommaSeparatedValues       *DestinationS3UpdateOutputFormatCSVCommaSeparatedValues
	DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON *DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON
	DestinationS3UpdateOutputFormatParquetColumnarStorage        *DestinationS3UpdateOutputFormatParquetColumnarStorage

	Type DestinationS3UpdateOutputFormatType
}

func CreateDestinationS3UpdateOutputFormatDestinationS3UpdateOutputFormatAvroApacheAvro(destinationS3UpdateOutputFormatAvroApacheAvro DestinationS3UpdateOutputFormatAvroApacheAvro) DestinationS3UpdateOutputFormat {
	typ := DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatAvroApacheAvro

	return DestinationS3UpdateOutputFormat{
		DestinationS3UpdateOutputFormatAvroApacheAvro: &destinationS3UpdateOutputFormatAvroApacheAvro,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatDestinationS3UpdateOutputFormatCSVCommaSeparatedValues(destinationS3UpdateOutputFormatCSVCommaSeparatedValues DestinationS3UpdateOutputFormatCSVCommaSeparatedValues) DestinationS3UpdateOutputFormat {
	typ := DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatCSVCommaSeparatedValues

	return DestinationS3UpdateOutputFormat{
		DestinationS3UpdateOutputFormatCSVCommaSeparatedValues: &destinationS3UpdateOutputFormatCSVCommaSeparatedValues,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON(destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON) DestinationS3UpdateOutputFormat {
	typ := DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON

	return DestinationS3UpdateOutputFormat{
		DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON: &destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON,
		Type: typ,
	}
}

func CreateDestinationS3UpdateOutputFormatDestinationS3UpdateOutputFormatParquetColumnarStorage(destinationS3UpdateOutputFormatParquetColumnarStorage DestinationS3UpdateOutputFormatParquetColumnarStorage) DestinationS3UpdateOutputFormat {
	typ := DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatParquetColumnarStorage

	return DestinationS3UpdateOutputFormat{
		DestinationS3UpdateOutputFormatParquetColumnarStorage: &destinationS3UpdateOutputFormatParquetColumnarStorage,
		Type: typ,
	}
}

func (u *DestinationS3UpdateOutputFormat) UnmarshalJSON(data []byte) error {
	var d *json.Decoder

	destinationS3UpdateOutputFormatAvroApacheAvro := new(DestinationS3UpdateOutputFormatAvroApacheAvro)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatAvroApacheAvro); err == nil {
		u.DestinationS3UpdateOutputFormatAvroApacheAvro = destinationS3UpdateOutputFormatAvroApacheAvro
		u.Type = DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatAvroApacheAvro
		return nil
	}

	destinationS3UpdateOutputFormatCSVCommaSeparatedValues := new(DestinationS3UpdateOutputFormatCSVCommaSeparatedValues)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatCSVCommaSeparatedValues); err == nil {
		u.DestinationS3UpdateOutputFormatCSVCommaSeparatedValues = destinationS3UpdateOutputFormatCSVCommaSeparatedValues
		u.Type = DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatCSVCommaSeparatedValues
		return nil
	}

	destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON := new(DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON); err == nil {
		u.DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON = destinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON
		u.Type = DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON
		return nil
	}

	destinationS3UpdateOutputFormatParquetColumnarStorage := new(DestinationS3UpdateOutputFormatParquetColumnarStorage)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationS3UpdateOutputFormatParquetColumnarStorage); err == nil {
		u.DestinationS3UpdateOutputFormatParquetColumnarStorage = destinationS3UpdateOutputFormatParquetColumnarStorage
		u.Type = DestinationS3UpdateOutputFormatTypeDestinationS3UpdateOutputFormatParquetColumnarStorage
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationS3UpdateOutputFormat) MarshalJSON() ([]byte, error) {
	if u.DestinationS3UpdateOutputFormatAvroApacheAvro != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatAvroApacheAvro)
	}

	if u.DestinationS3UpdateOutputFormatCSVCommaSeparatedValues != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatCSVCommaSeparatedValues)
	}

	if u.DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatJSONLinesNewlineDelimitedJSON)
	}

	if u.DestinationS3UpdateOutputFormatParquetColumnarStorage != nil {
		return json.Marshal(u.DestinationS3UpdateOutputFormatParquetColumnarStorage)
	}

	return nil, nil
}

// DestinationS3UpdateS3BucketRegion - The region of the S3 bucket. See <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">here</a> for all region codes.
type DestinationS3UpdateS3BucketRegion string

const (
	DestinationS3UpdateS3BucketRegionUnknown      DestinationS3UpdateS3BucketRegion = ""
	DestinationS3UpdateS3BucketRegionUsEast1      DestinationS3UpdateS3BucketRegion = "us-east-1"
	DestinationS3UpdateS3BucketRegionUsEast2      DestinationS3UpdateS3BucketRegion = "us-east-2"
	DestinationS3UpdateS3BucketRegionUsWest1      DestinationS3UpdateS3BucketRegion = "us-west-1"
	DestinationS3UpdateS3BucketRegionUsWest2      DestinationS3UpdateS3BucketRegion = "us-west-2"
	DestinationS3UpdateS3BucketRegionAfSouth1     DestinationS3UpdateS3BucketRegion = "af-south-1"
	DestinationS3UpdateS3BucketRegionApEast1      DestinationS3UpdateS3BucketRegion = "ap-east-1"
	DestinationS3UpdateS3BucketRegionApSouth1     DestinationS3UpdateS3BucketRegion = "ap-south-1"
	DestinationS3UpdateS3BucketRegionApNortheast1 DestinationS3UpdateS3BucketRegion = "ap-northeast-1"
	DestinationS3UpdateS3BucketRegionApNortheast2 DestinationS3UpdateS3BucketRegion = "ap-northeast-2"
	DestinationS3UpdateS3BucketRegionApNortheast3 DestinationS3UpdateS3BucketRegion = "ap-northeast-3"
	DestinationS3UpdateS3BucketRegionApSoutheast1 DestinationS3UpdateS3BucketRegion = "ap-southeast-1"
	DestinationS3UpdateS3BucketRegionApSoutheast2 DestinationS3UpdateS3BucketRegion = "ap-southeast-2"
	DestinationS3UpdateS3BucketRegionCaCentral1   DestinationS3UpdateS3BucketRegion = "ca-central-1"
	DestinationS3UpdateS3BucketRegionCnNorth1     DestinationS3UpdateS3BucketRegion = "cn-north-1"
	DestinationS3UpdateS3BucketRegionCnNorthwest1 DestinationS3UpdateS3BucketRegion = "cn-northwest-1"
	DestinationS3UpdateS3BucketRegionEuCentral1   DestinationS3UpdateS3BucketRegion = "eu-central-1"
	DestinationS3UpdateS3BucketRegionEuNorth1     DestinationS3UpdateS3BucketRegion = "eu-north-1"
	DestinationS3UpdateS3BucketRegionEuSouth1     DestinationS3UpdateS3BucketRegion = "eu-south-1"
	DestinationS3UpdateS3BucketRegionEuWest1      DestinationS3UpdateS3BucketRegion = "eu-west-1"
	DestinationS3UpdateS3BucketRegionEuWest2      DestinationS3UpdateS3BucketRegion = "eu-west-2"
	DestinationS3UpdateS3BucketRegionEuWest3      DestinationS3UpdateS3BucketRegion = "eu-west-3"
	DestinationS3UpdateS3BucketRegionSaEast1      DestinationS3UpdateS3BucketRegion = "sa-east-1"
	DestinationS3UpdateS3BucketRegionMeSouth1     DestinationS3UpdateS3BucketRegion = "me-south-1"
	DestinationS3UpdateS3BucketRegionUsGovEast1   DestinationS3UpdateS3BucketRegion = "us-gov-east-1"
	DestinationS3UpdateS3BucketRegionUsGovWest1   DestinationS3UpdateS3BucketRegion = "us-gov-west-1"
)

func (e DestinationS3UpdateS3BucketRegion) ToPointer() *DestinationS3UpdateS3BucketRegion {
	return &e
}

func (e *DestinationS3UpdateS3BucketRegion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "":
		fallthrough
	case "us-east-1":
		fallthrough
	case "us-east-2":
		fallthrough
	case "us-west-1":
		fallthrough
	case "us-west-2":
		fallthrough
	case "af-south-1":
		fallthrough
	case "ap-east-1":
		fallthrough
	case "ap-south-1":
		fallthrough
	case "ap-northeast-1":
		fallthrough
	case "ap-northeast-2":
		fallthrough
	case "ap-northeast-3":
		fallthrough
	case "ap-southeast-1":
		fallthrough
	case "ap-southeast-2":
		fallthrough
	case "ca-central-1":
		fallthrough
	case "cn-north-1":
		fallthrough
	case "cn-northwest-1":
		fallthrough
	case "eu-central-1":
		fallthrough
	case "eu-north-1":
		fallthrough
	case "eu-south-1":
		fallthrough
	case "eu-west-1":
		fallthrough
	case "eu-west-2":
		fallthrough
	case "eu-west-3":
		fallthrough
	case "sa-east-1":
		fallthrough
	case "me-south-1":
		fallthrough
	case "us-gov-east-1":
		fallthrough
	case "us-gov-west-1":
		*e = DestinationS3UpdateS3BucketRegion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationS3UpdateS3BucketRegion: %v", v)
	}
}

type DestinationS3Update struct {
	// The access key ID to access the S3 bucket. Airbyte requires Read and Write permissions to the given bucket. Read more <a href="https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys">here</a>.
	AccessKeyID *string `json:"access_key_id,omitempty"`
	// The pattern allows you to set the file-name format for the S3 staging file(s)
	FileNamePattern *string `json:"file_name_pattern,omitempty"`
	// Format of the data output. See <a href="https://docs.airbyte.com/integrations/destinations/s3/#supported-output-schema">here</a> for more details
	Format DestinationS3UpdateOutputFormat `json:"format"`
	// The name of the S3 bucket. Read more <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html">here</a>.
	S3BucketName string `json:"s3_bucket_name"`
	// Directory under the S3 bucket where data will be written. Read more <a href="https://docs.airbyte.com/integrations/destinations/s3#:~:text=to%20format%20the-,bucket%20path,-%3A">here</a>
	S3BucketPath string `json:"s3_bucket_path"`
	// The region of the S3 bucket. See <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">here</a> for all region codes.
	S3BucketRegion DestinationS3UpdateS3BucketRegion `json:"s3_bucket_region"`
	// Your S3 endpoint url. Read more <a href="https://docs.aws.amazon.com/general/latest/gr/s3.html#:~:text=Service%20endpoints-,Amazon%20S3%20endpoints,-When%20you%20use">here</a>
	S3Endpoint *string `json:"s3_endpoint,omitempty"`
	// Format string on how data will be organized inside the S3 bucket directory. Read more <a href="https://docs.airbyte.com/integrations/destinations/s3#:~:text=The%20full%20path%20of%20the%20output%20data%20with%20the%20default%20S3%20path%20format">here</a>
	S3PathFormat *string `json:"s3_path_format,omitempty"`
	// The corresponding secret to the access key ID. Read more <a href="https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys">here</a>
	SecretAccessKey *string `json:"secret_access_key,omitempty"`
}
