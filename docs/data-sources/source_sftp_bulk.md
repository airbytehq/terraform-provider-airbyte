---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "airbyte_source_sftp_bulk Data Source - terraform-provider-airbyte"
subcategory: ""
description: |-
  SourceSftpBulk DataSource
---

# airbyte_source_sftp_bulk (Data Source)

SourceSftpBulk DataSource

## Example Usage

```terraform
data "airbyte_source_sftp_bulk" "my_source_sftpbulk" {
  secret_id = "...my_secret_id..."
  source_id = "...my_source_id..."
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `source_id` (String)

### Optional

- `secret_id` (String) Optional secretID obtained through the public API OAuth redirect flow.

### Read-Only

- `configuration` (Attributes) (see [below for nested schema](#nestedatt--configuration))
- `name` (String)
- `workspace_id` (String)

<a id="nestedatt--configuration"></a>
### Nested Schema for `configuration`

Read-Only:

- `file_most_recent` (Boolean) Default: false
Sync only the most recent file for the configured folder path and file pattern
- `file_pattern` (String) Default: ""
The regular expression to specify files for sync in a chosen Folder Path
- `file_type` (String) must be one of ["csv", "json"]; Default: "csv"
The file type you want to sync. Currently only 'csv' and 'json' files are supported.
- `folder_path` (String) Default: ""
The directory to search files for sync
- `host` (String) The server host address
- `password` (String) OS-level password for logging into the jump server host
- `port` (Number) Default: 22
The server port
- `private_key` (String) The private key
- `separator` (String) Default: ","
The separator used in the CSV files. Define None if you want to use the Sniffer functionality
- `start_date` (String) The date from which you'd like to replicate data for all incremental streams, in the format YYYY-MM-DDT00:00:00Z. All data generated after this date will be replicated.
- `stream_name` (String) The name of the stream or table you want to create
- `username` (String) The server user


