---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "airbyte_source_sftp_bulk Data Source - terraform-provider-airbyte"
subcategory: ""
description: |-
  SourceSftpBulk DataSource
---

# airbyte_source_sftp_bulk (Data Source)

SourceSftpBulk DataSource

## Example Usage

```terraform
data "airbyte_source_sftp_bulk" "my_source_sftpbulk" {
  secret_id = "...my_secret_id..."
  source_id = "...my_source_id..."
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `source_id` (String)

### Optional

- `secret_id` (String) Optional secretID obtained through the public API OAuth redirect flow.

### Read-Only

- `configuration` (Attributes) (see [below for nested schema](#nestedatt--configuration))
- `name` (String)
- `workspace_id` (String)

<a id="nestedatt--configuration"></a>
### Nested Schema for `configuration`

Read-Only:

- `file_most_recent` (Boolean) Sync only the most recent file for the configured folder path and file pattern
- `file_pattern` (String) The regular expression to specify files for sync in a chosen Folder Path
- `file_type` (String) must be one of ["csv", "json"]
The file type you want to sync. Currently only 'csv' and 'json' files are supported.
- `folder_path` (String) The directory to search files for sync
- `host` (String) The server host address
- `password` (String) OS-level password for logging into the jump server host
- `port` (Number) The server port
- `private_key` (String) The private key
- `separator` (String) The separator used in the CSV files. Define None if you want to use the Sniffer functionality
- `source_type` (String) must be one of ["sftp-bulk"]
- `start_date` (String) The date from which you'd like to replicate data for all incremental streams, in the format YYYY-MM-DDT00:00:00Z. All data generated after this date will be replicated.
- `stream_name` (String) The name of the stream or table you want to create
- `username` (String) The server user


