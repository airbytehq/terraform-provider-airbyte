---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "airbyte_connection Resource - terraform-provider-airbyte"
subcategory: ""
description: |-
  Connection Resource
---

# airbyte_connection (Resource)

Connection Resource

## Example Usage

```terraform
resource "airbyte_connection" "my_connection" {
  configurations = {
    streams = [
      {
        cursor_field = [
          "...",
        ]
        name = "Terrence Rau"
        primary_key = [
          [
            "...",
          ],
        ]
        sync_mode = "incremental_deduped_history"
      },
    ]
  }
  data_residency                       = "us"
  destination_id                       = "d69a674e-0f46-47cc-8796-ed151a05dfc2"
  name                                 = "Wilfred Wolff"
  namespace_definition                 = "custom_format"
  namespace_format                     = SOURCE_NAMESPACE
  non_breaking_schema_updates_behavior = "disable_connection"
  prefix                               = "...my_prefix..."
  schedule = {
    basic_timing    = "...my_basic_timing..."
    cron_expression = "...my_cron_expression..."
    schedule_type   = "cron"
  }
  source_id = "ca1ba928-fc81-4674-acb7-39205929396f"
  status    = "deprecated"
}
```

With Stream Module 

```terraform

module "source_postgres_streams" {
  source = "airbytehq/stream-discovery/airbyte"
  airbyte_api_token = var.airbyte_api_token
  source_id = airbyte_source_postgres.my_source_postgres.source_id
  destination_id = airbyte_destination_bigquery.my_destination_bigquery.destination_id
}

locals {
  full_refresh_streams = [for stream in module.source_postgres_streams.streams : 
    { 
      name = stream.streamName
      sync_mode = "full_refresh_overwrite"
    }
  ]
}


resource "airbyte_connection" "postgres_to_bigquery_full_refresh" {
  name           = "Postgres to BigQuery Full Refresh"
  source_id = airbyte_source_postgres.my_source_postgres.source_id
  destination_id = airbyte_destination_bigquery.my_destination_bigquery.destination_id
  schedule = {
    schedule_type = "manual"
  }
  configurations = {
    streams = local.full_refresh_streams
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `destination_id` (String)
- `source_id` (String)

### Optional

- `configurations` (Attributes) A list of configured stream options for a connection. (see [below for nested schema](#nestedatt--configurations))
- `data_residency` (String) must be one of ["auto", "us", "eu"]
- `name` (String) Optional name of the connection
- `namespace_definition` (String) must be one of ["source", "destination", "custom_format"]
Define the location where the data will be stored in the destination
- `namespace_format` (String) Used when namespaceDefinition is 'custom_format'. If blank then behaves like namespaceDefinition = 'destination'. If "${SOURCE_NAMESPACE}" then behaves like namespaceDefinition = 'source'.
- `non_breaking_schema_updates_behavior` (String) must be one of ["ignore", "disable_connection", "propagate_columns", "propagate_fully"]
Set how Airbyte handles syncs when it detects a non-breaking schema change in the source
- `prefix` (String) Prefix that will be prepended to the name of each stream when it is written to the destination (ex. “airbyte_” causes “projects” => “airbyte_projects”).
- `schedule` (Attributes) schedule for when the the connection should run, per the schedule type (see [below for nested schema](#nestedatt--schedule))
- `status` (String) must be one of ["active", "inactive", "deprecated"]

### Read-Only

- `connection_id` (String)
- `workspace_id` (String)

<a id="nestedatt--configurations"></a>
### Nested Schema for `configurations`

Optional:

- `streams` (Attributes List) (see [below for nested schema](#nestedatt--configurations--streams))

<a id="nestedatt--configurations--streams"></a>
### Nested Schema for `configurations.streams`

Required:

- `name` (String)

Optional:

- `cursor_field` (List of String) Path to the field that will be used to determine if a record is new or modified since the last sync. This field is REQUIRED if `sync_mode` is `incremental` unless there is a default.
- `primary_key` (List of List of String) Paths to the fields that will be used as primary key. This field is REQUIRED if `destination_sync_mode` is `*_dedup` unless it is already supplied by the source schema.
- `sync_mode` (String) must be one of ["full_refresh_overwrite", "full_refresh_append", "incremental_append", "incremental_deduped_history"]

## Stream Module
If you want to discover the available streams programmatically with terraform, we have released a [Stream Discovery Module](https://registry.terraform.io/modules/airbytehq/stream-discovery/airbyte/latest) which fetches the available streams and sync modes between a source and destination.


<a id="nestedatt--schedule"></a>
### Nested Schema for `schedule`

Required:

- `schedule_type` (String) must be one of ["manual", "cron"]

Optional:

- `cron_expression` (String)

Read-Only:

- `basic_timing` (String)


