---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "airbyte_destination_gcs_data_lake Resource - terraform-provider-airbyte"
subcategory: ""
description: |-
  DestinationGcsDataLake Resource
---

# airbyte_destination_gcs_data_lake (Resource)

DestinationGcsDataLake Resource

## Example Usage

```terraform
resource "airbyte_destination_gcs_data_lake" "my_destination_gcsdatalake" {
  configuration = {
    additional_properties = "{ \"see\": \"documentation\" }"
    catalog_type = {
      polaris_catalog = {
        additional_properties = "{ \"see\": \"documentation\" }"
        catalog_name          = "...my_catalog_name..."
        catalog_type          = "POLARIS"
        client_id             = "abc123clientid"
        client_secret         = "secretkey123"
        server_uri            = "...my_server_uri..."
      }
    }
    gcp_location         = "us"
    gcp_project_id       = "...my_gcp_project_id..."
    gcs_bucket_name      = "...my_gcs_bucket_name..."
    gcs_endpoint         = "...my_gcs_endpoint..."
    main_branch_name     = "...my_main_branch_name..."
    namespace            = "default"
    service_account_json = "...my_service_account_json..."
    warehouse_location   = "gs://your-bucket/path/to/warehouse"
  }
  definition_id = "44550b48-b11d-48e6-8375-1a0c6c8333ab"
  name          = "...my_name..."
  workspace_id  = "bec00b73-1444-4110-9897-31198f7f8847"
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `configuration` (Attributes) Configuration for GCS Data Lake destination using Apache Iceberg format (see [below for nested schema](#nestedatt--configuration))
- `name` (String) Name of the destination e.g. dev-mysql-instance.
- `workspace_id` (String)

### Optional

- `definition_id` (String) The UUID of the connector definition. One of configuration.destinationType or definitionId must be provided. Requires replacement if changed.

### Read-Only

- `created_at` (Number)
- `destination_id` (String)
- `destination_type` (String)
- `resource_allocation` (Attributes) actor or actor definition specific resource requirements. if default is set, these are the requirements that should be set for ALL jobs run for this actor definition. it is overriden by the job type specific configurations. if not set, the platform will use defaults. these values will be overriden by configuration at the connection level. (see [below for nested schema](#nestedatt--resource_allocation))

<a id="nestedatt--configuration"></a>
### Nested Schema for `configuration`

Required:

- `catalog_type` (Attributes) Specifies the type of Iceberg catalog (BigLake or Polaris). (see [below for nested schema](#nestedatt--configuration--catalog_type))
- `gcp_location` (String) The GCP location (region) for BigLake metastore resources. For example: "us-central1" or "us". See <a href="https://cloud.google.com/biglake/docs/locations">BigLake locations</a> for available regions.
- `gcs_bucket_name` (String) The name of the GCS bucket that will host the Iceberg data.
- `main_branch_name` (String) The primary or default branch name in the catalog. Most query engines will use "main" by default. See <a href="https://iceberg.apache.org/docs/latest/branching/">Iceberg documentation</a> for more information.
- `namespace` (String) The default namespace to use for tables. This will ONLY be used if the `Destination Namespace` setting is set to `Destination-defined` or `Source-defined`
- `service_account_json` (String) The contents of the JSON service account key file. See the <a href="https://cloud.google.com/iam/docs/creating-managing-service-account-keys">Google Cloud documentation</a> for more information on how to obtain this.
- `warehouse_location` (String) The root location of the data warehouse used by the Iceberg catalog. Must include the storage protocol "gs://" for Google Cloud Storage. For example: "gs://your-bucket/path/to/warehouse/

Optional:

- `additional_properties` (String) Parsed as JSON.
- `gcp_project_id` (String) The GCP project ID where resources are located. If not specified, it will be extracted from the service account credentials.
- `gcs_endpoint` (String) Optional custom GCS endpoint URL. Use this for testing with local GCS emulators.

<a id="nestedatt--configuration--catalog_type"></a>
### Nested Schema for `configuration.catalog_type`

Optional:

- `big_lake_catalog` (Attributes) Configuration for Google Cloud BigLake Iceberg catalog. (see [below for nested schema](#nestedatt--configuration--catalog_type--big_lake_catalog))
- `polaris_catalog` (Attributes) Configuration for Apache Polaris Iceberg catalog. (see [below for nested schema](#nestedatt--configuration--catalog_type--polaris_catalog))

<a id="nestedatt--configuration--catalog_type--big_lake_catalog"></a>
### Nested Schema for `configuration.catalog_type.big_lake_catalog`

Required:

- `catalog_name` (String) The name of the BigLake catalog. This should match the catalog you created in BigLake metastore.

Optional:

- `additional_properties` (String) Parsed as JSON.
- `catalog_type` (String) Default: "BIGLAKE"; must be "BIGLAKE"


<a id="nestedatt--configuration--catalog_type--polaris_catalog"></a>
### Nested Schema for `configuration.catalog_type.polaris_catalog`

Required:

- `catalog_name` (String) The name of the catalog in Polaris. This corresponds to the catalog name created via the Polaris Management API.
- `client_id` (String) The OAuth Client ID for authenticating with the Polaris server.
- `client_secret` (String) The OAuth Client Secret for authenticating with the Polaris server.
- `server_uri` (String) The base URL of the Polaris server. For example: http://localhost:8181/api/catalog

Optional:

- `additional_properties` (String) Parsed as JSON.
- `catalog_type` (String) Default: "POLARIS"; must be "POLARIS"




<a id="nestedatt--resource_allocation"></a>
### Nested Schema for `resource_allocation`

Read-Only:

- `default` (Attributes) optional resource requirements to run workers (blank for unbounded allocations) (see [below for nested schema](#nestedatt--resource_allocation--default))
- `job_specific` (Attributes List) (see [below for nested schema](#nestedatt--resource_allocation--job_specific))

<a id="nestedatt--resource_allocation--default"></a>
### Nested Schema for `resource_allocation.default`

Read-Only:

- `cpu_limit` (String)
- `cpu_request` (String)
- `ephemeral_storage_limit` (String)
- `ephemeral_storage_request` (String)
- `memory_limit` (String)
- `memory_request` (String)


<a id="nestedatt--resource_allocation--job_specific"></a>
### Nested Schema for `resource_allocation.job_specific`

Read-Only:

- `job_type` (String) enum that describes the different types of jobs that the platform runs.
- `resource_requirements` (Attributes) optional resource requirements to run workers (blank for unbounded allocations) (see [below for nested schema](#nestedatt--resource_allocation--job_specific--resource_requirements))

<a id="nestedatt--resource_allocation--job_specific--resource_requirements"></a>
### Nested Schema for `resource_allocation.job_specific.resource_requirements`

Read-Only:

- `cpu_limit` (String)
- `cpu_request` (String)
- `ephemeral_storage_limit` (String)
- `ephemeral_storage_request` (String)
- `memory_limit` (String)
- `memory_request` (String)

## Import

Import is supported using the following syntax:

In Terraform v1.5.0 and later, the [`import` block](https://developer.hashicorp.com/terraform/language/import) can be used with the `id` attribute, for example:

```terraform
import {
  to = airbyte_destination_gcs_data_lake.my_airbyte_destination_gcs_data_lake
  id = "..."
}
```

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
terraform import airbyte_destination_gcs_data_lake.my_airbyte_destination_gcs_data_lake "..."
```
