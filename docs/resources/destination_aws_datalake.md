---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "airbyte_destination_aws_datalake Resource - terraform-provider-airbyte"
subcategory: ""
description: |-
  DestinationAwsDatalake Resource
---

# airbyte_destination_aws_datalake (Resource)

DestinationAwsDatalake Resource

## Example Usage

```terraform
resource "airbyte_destination_aws_datalake" "my_destination_awsdatalake" {
  configuration = {
    aws_account_id = "111111111111"
    bucket_name    = "...my_bucket_name..."
    bucket_prefix  = "...my_bucket_prefix..."
    credentials = {
      iam_role = {
        role_arn = "...my_role_arn..."
      }
    }
    format = {
      json_lines_newline_delimited_json = {
        compression_codec = "GZIP"
        format_type       = "JSONL"
      }
    }
    glue_catalog_float_as_decimal             = false
    lakeformation_database_default_tag_key    = "pii_level"
    lakeformation_database_default_tag_values = "private,public"
    lakeformation_database_name               = "...my_lakeformation_database_name..."
    lakeformation_governed_tables             = false
    partitioning                              = "DAY"
    region                                    = "ap-southeast-3"
  }
  definition_id = "c3f592b3-8acf-43b2-bea4-e36bf4ba0e7a"
  name          = "Charlie Fisher"
  workspace_id  = "aaebb5cd-76c9-4fd0-bc96-8decb9cb44c8"
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `configuration` (Attributes) (see [below for nested schema](#nestedatt--configuration))
- `name` (String) Name of the destination e.g. dev-mysql-instance.
- `workspace_id` (String)

### Optional

- `definition_id` (String) The UUID of the connector definition. One of configuration.destinationType or definitionId must be provided. Requires replacement if changed.

### Read-Only

- `destination_id` (String)
- `destination_type` (String)

<a id="nestedatt--configuration"></a>
### Nested Schema for `configuration`

Required:

- `bucket_name` (String) The name of the S3 bucket. Read more <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html">here</a>.
- `credentials` (Attributes) Choose How to Authenticate to AWS. (see [below for nested schema](#nestedatt--configuration--credentials))
- `lakeformation_database_name` (String) The default database this destination will use to create tables in per stream. Can be changed per connection by customizing the namespace.

Optional:

- `aws_account_id` (String) target aws account id
- `bucket_prefix` (String) S3 prefix
- `format` (Attributes) Format of the data output. (see [below for nested schema](#nestedatt--configuration--format))
- `glue_catalog_float_as_decimal` (Boolean) Cast float/double as decimal(38,18). This can help achieve higher accuracy and represent numbers correctly as received from the source. Default: false
- `lakeformation_database_default_tag_key` (String) Add a default tag key to databases created by this destination
- `lakeformation_database_default_tag_values` (String) Add default values for the `Tag Key` to databases created by this destination. Comma separate for multiple values.
- `lakeformation_governed_tables` (Boolean) Whether to create tables as LF governed tables. Default: false
- `partitioning` (String) Partition data by cursor fields when a cursor field is a date. must be one of ["NO PARTITIONING", "DATE", "YEAR", "MONTH", "DAY", "YEAR/MONTH", "YEAR/MONTH/DAY"]; Default: "NO PARTITIONING"
- `region` (String) The region of the S3 bucket. See <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">here</a> for all region codes. must be one of ["", "af-south-1", "ap-east-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-south-1", "ap-south-2", "ap-southeast-1", "ap-southeast-2", "ap-southeast-3", "ap-southeast-4", "ca-central-1", "ca-west-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-central-2", "eu-north-1", "eu-south-1", "eu-south-2", "eu-west-1", "eu-west-2", "eu-west-3", "il-central-1", "me-central-1", "me-south-1", "sa-east-1", "us-east-1", "us-east-2", "us-gov-east-1", "us-gov-west-1", "us-west-1", "us-west-2"]; Default: ""

<a id="nestedatt--configuration--credentials"></a>
### Nested Schema for `configuration.credentials`

Optional:

- `iam_role` (Attributes) (see [below for nested schema](#nestedatt--configuration--credentials--iam_role))
- `iam_user` (Attributes) (see [below for nested schema](#nestedatt--configuration--credentials--iam_user))

<a id="nestedatt--configuration--credentials--iam_role"></a>
### Nested Schema for `configuration.credentials.iam_role`

Required:

- `role_arn` (String, Sensitive) Will assume this role to write data to s3


<a id="nestedatt--configuration--credentials--iam_user"></a>
### Nested Schema for `configuration.credentials.iam_user`

Required:

- `aws_access_key_id` (String, Sensitive) AWS User Access Key Id
- `aws_secret_access_key` (String, Sensitive) Secret Access Key



<a id="nestedatt--configuration--format"></a>
### Nested Schema for `configuration.format`

Optional:

- `json_lines_newline_delimited_json` (Attributes) (see [below for nested schema](#nestedatt--configuration--format--json_lines_newline_delimited_json))
- `parquet_columnar_storage` (Attributes) (see [below for nested schema](#nestedatt--configuration--format--parquet_columnar_storage))

<a id="nestedatt--configuration--format--json_lines_newline_delimited_json"></a>
### Nested Schema for `configuration.format.json_lines_newline_delimited_json`

Optional:

- `compression_codec` (String) The compression algorithm used to compress data. must be one of ["UNCOMPRESSED", "GZIP"]; Default: "UNCOMPRESSED"
- `format_type` (String) must be one of ["JSONL"]; Default: "JSONL"


<a id="nestedatt--configuration--format--parquet_columnar_storage"></a>
### Nested Schema for `configuration.format.parquet_columnar_storage`

Optional:

- `compression_codec` (String) The compression algorithm used to compress data. must be one of ["UNCOMPRESSED", "SNAPPY", "GZIP", "ZSTD"]; Default: "SNAPPY"
- `format_type` (String) must be one of ["Parquet"]; Default: "Parquet"

## Import

Import is supported using the following syntax:

```shell
terraform import airbyte_destination_aws_datalake.my_airbyte_destination_aws_datalake ""
```
